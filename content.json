{"meta":{"title":"Essviv","subtitle":"Dare to be different","description":null,"author":"Essviv","url":"http://yoursite.com"},"pages":[{"title":"","date":"2017-05-01T16:11:17.000Z","updated":"2017-05-01T16:11:16.000Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"孙义威 名称 信息 学历 研究生/中国科学院大学 工作年限 3年 手机号码 18867102100 Email patrick_sun@qq.com 技术博客 这里 Github 这里 工作经历1. 流量自营平台(2014.08 - 2017.04)项目简介流量自营平台主要是为了解决运营商的流量分发而开发的平台，我从项目立项之初就参与其中，经历了项目从单体应用到按功能细分成各个服务的演变过程, 目前该项目包含有多个独立部署的服务： 流量分发服务: 该模块负责与上游boss交互，隐藏了上游接口实现的不一致性，并通过RESTful接口对外提供统一的流量分发接口. 本人负责的内容包括RESTful API接口的设计、上游接口的对接、性能优化等内容 短信服务: 该模块基于netty框架实现了cmpp2.0/cmpp3.0/smpp等常见的运营商短信协议，根据业务场景的需要增加了断线重连、敏感词过滤、流量控制以及短信模板等功能, 本人独立完成了该模块的方案设计及编码工作，包括基于netty框架完整地实现运营商协议、接口封装等工作 营销模板服务: 营销模板服务是为了简化企业客户进行营销活动而创建的服务，它对外提供了丰富的营销活动模板，包括大转盘、砸金蛋、抢红包、流量券、二维码等形式的营销活动，企业用户可以根据自身的业务场景选择活动. 我的工作内容是完成营销活动的开发工作，并针对营销活动普通存在的一些问题提出了相应的实施方案 号段服务: 该服务用于对外提供手机号码归属地查询服务，由于号段归属地等信息不会经常变化，该服务使用redis作用内存数据库，以提高查询效率. 其它: 除此之外，项目中还包括了文件存储服务、充值服务、运营管理服务(正在进行) 我的贡献从项目之初的单体应用，逐渐演变成当前的多服务独立部署的方案，我的贡献包括: 根据实际的业务场景，适时地引入合理的解决方案，包括但不限于： 在接口的并发性能无法满足客户需求，引入RabbitMQ消息中间体及Redis缓存，实施异步化改造及热点数据的缓存 单体应用过于庞大，导致开发及运维效率低下时，结合消息中间体，实施多服务独立开发和部署的方案 针对营销活动中出现的恶意刷奖、”秒杀”、实时排名等问题，基于NoSQL提出了完整的解决方案. 根据项目需求完成代码开发、测试及优化工作, 主要包括： 流量分发服务以及营销活动服务的开发及性能优化 基于netty框架完成短信服务的开发 管理后台的开发 外部系统的接口对接 在团队内部建立良好的沟通机制，包括建立内部wiki、不定期分享、代码审查等方案，与团队成员一同成长. （这里可以加一张架构演变示意图） 2. 省公司流量平台（2015.07 - 2017.04)项目简介省公司流量平台主要是为了服务各省公司日常的流量运营活动，目前已累计支撑12个省公司. 我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。 我的贡献流量平台主要是为了服务各省公司日常的流量运营活动，我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。 技术细节流量平台主要是为了服务各省公司日常的流量运营活动，我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。 3. 其它项目 营销卡管理平台: 该平台是为了方便省公司管理流量卡而开发的，包括制卡、入库、激活、绑定及使用等所有状态的变更及其跟踪，基于SpringMVC + myBatis + FreeMarker实现，通过Spring Security实现基于角色的权限控制. 企业管理平台: 为方便对接入的企业进行统一管理，开发了企业管理平台，实现了企业注册、账户管理、营销活动创建、流程审批、风险控制以及运营数据查看等功能，我的工作包括项目框架的搭建、模块细分、账户实现、数据库分表方案的实施以及基础服务的对接. 以下为在校期间的项目经历： 嫦娥三号制图与仿真系统: 基于C#和ArcEngine完成嫦娥三号落月后月球表面影像的实时生成及导航路线的实时规划. 高分辨率遥感卫星影像几何精校正: 基于CPU与GPU异构编程模型，完成高分辨率遥感影像的准实时校正. 影像和IMU组合精密导航定位系统: 基于计算机视觉与卡尔曼滤波算法，结合IMU传感器数据，实现无GPS环境下的导航 SAR影像目标解译: 通过支持微量机(SVM)算法及图像解析算法，完成SAR影像不同地形的自动提取，并完成军事目标的自动搜索及标记. 4. 技术文章完整的技术文章可在GitHub上找到，这里仅列出一些例子 AQS框架源码解析 代理模式 Netty服务端的启动 CountDownLatch, Semaphore, CyclicBarrier源码解析 Java的类加载机制 5. 技能清单 JAVA基础扎实，熟悉io, 多线程, 集合等基础框架, 熟悉常见的设计模式 理解缓存、消息队列的原理，并掌握常见框架的使用(redis,memcached, RabbitMQ) 深入了解spring框架，阅读过框架源码，对IoC, AOP及相应的实现机制有深刻的理解 注重团队合作，能够快速地适应团队要求，对代码质量有很高的追求"}],"posts":[{"title":"spring IoC源码解析(3)","slug":"spring/spring-ioc-source-code(3)","date":"2017-04-13T01:38:00.000Z","updated":"2017-04-14T06:08:56.000Z","comments":true,"path":"2017/04/13/spring/spring-ioc-source-code(3)/","link":"","permalink":"http://yoursite.com/2017/04/13/spring/spring-ioc-source-code(3)/","excerpt":"","text":"2.4 createBean()方法的实现在上面的解读中，我们知道getBean()方法的实现过程，首先尝试从缓存中获取，缓存获取失败后则尝试创建对象，在创建对象时首先检查依赖关系，在满足了依赖关系后就会调用createBean()对象获取实例. 那createBean()方法又是如何实现的呢？createBean()底层调用了doCreateBean()方法, 后者的实现大体上可以分成几个步骤: 调用createBeanInstance创建对象实例 调用populateBean()方法填充对象 调用initilizingBean()方法初始化对象 接下来就来看看这三个步骤的实现细节. 2.4.1 createBeanInstance()方法调用createBeanInstance()方法创建实例的实现可分为两种，一种是通过工厂对象来创建，一种是直接调用对象的构造方法来创建. 2.4.1.1 使用工厂对象创建实例首先先来看看使用工厂对象来实例化对象的代码, 这个部分主要是调用了instantiateUsingFactoryMethod()方法来实现的，这个方法的实现代码非常复杂，总得来讲，可分为几个步骤： 确定工厂对象的工厂方法factoryMethod及其参数 根据第1步中确定的工厂方法和参数实例化对象 容器首先会尝试从bean定义的消息中获取定义的工厂方法factoryMethodToUse和方法参数argToUse，这里首先会查看mbd中是否已经能解析过的构造函数和方法，如果有则继续搜索是否有解析过的构造参数，如果没有则调用resolvePreparedArguments()方法进行解析. 12345678910111213141516171819if (explicitArgs != null) &#123; argsToUse = explicitArgs;&#125;else &#123; Object[] argsToResolve = null; synchronized (mbd.constructorArgumentLock) &#123; factoryMethodToUse = (Method) mbd.resolvedConstructorOrFactoryMethod; if (factoryMethodToUse != null &amp;&amp; mbd.constructorArgumentsResolved) &#123; // Found a cached factory method... argsToUse = mbd.resolvedConstructorArguments; if (argsToUse == null) &#123; argsToResolve = mbd.preparedConstructorArguments; &#125; &#125; &#125; if (argsToResolve != null) &#123; argsToUse = resolvePreparedArguments(beanName, mbd, bw, factoryMethodToUse, argsToResolve); &#125;&#125; resolvePreparedArguments()方法的作用就是mbd中定义的工厂方法的参数信息，它通过遍历每个参数并判断参数的类型完成解析操作，其中最重要的是当参数是AutowiredArgumentMarker类型时，它会调用resolveAutowireArgument()方法完成参数的注入操作，关于这个方法会在后续的解读中进行详述，这里只需要知道它是用来解析参数并完成自动注入的即可. 12345678910111213141516171819202122232425262728293031323334353637private Object[] resolvePreparedArguments( String beanName, RootBeanDefinition mbd, BeanWrapper bw, Member methodOrCtor, Object[] argsToResolve) &#123; Class&lt;?&gt;[] paramTypes = (methodOrCtor instanceof Method ? ((Method) methodOrCtor).getParameterTypes() : ((Constructor&lt;?&gt;) methodOrCtor).getParameterTypes()); TypeConverter converter = (this.beanFactory.getCustomTypeConverter() != null ? this.beanFactory.getCustomTypeConverter() : bw); BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this.beanFactory, beanName, mbd, converter); Object[] resolvedArgs = new Object[argsToResolve.length]; for (int argIndex = 0; argIndex &lt; argsToResolve.length; argIndex++) &#123; Object argValue = argsToResolve[argIndex]; MethodParameter methodParam = MethodParameter.forMethodOrConstructor(methodOrCtor, argIndex); GenericTypeResolver.resolveParameterType(methodParam, methodOrCtor.getDeclaringClass()); if (argValue instanceof AutowiredArgumentMarker) &#123; //这里完成了自动注入参数的解析 argValue = resolveAutowiredArgument(methodParam, beanName, null, converter); &#125; else if (argValue instanceof BeanMetadataElement) &#123; argValue = valueResolver.resolveValueIfNecessary(\"constructor argument\", argValue); &#125; else if (argValue instanceof String) &#123; argValue = this.beanFactory.evaluateBeanDefinitionString((String) argValue, mbd); &#125; Class&lt;?&gt; paramType = paramTypes[argIndex]; try &#123; resolvedArgs[argIndex] = converter.convertIfNecessary(argValue, paramType, methodParam); &#125; catch (TypeMismatchException ex) &#123; throw new UnsatisfiedDependencyException( mbd.getResourceDescription(), beanName, new InjectionPoint(methodParam), \"Could not convert argument value of type [\" + ObjectUtils.nullSafeClassName(argValue) + \"] to required type [\" + paramType.getName() + \"]: \" + ex.getMessage()); &#125; &#125; return resolvedArgs;&#125; 在经过上述的解析操作后，只要factoryMethodToUse和areToUse参数中有一个是缺失的，那么容器就需要遍历所有可能的方法来寻找相应的工厂方法和参数，寻找候选方法的过程是获取工厂对象中声明的所有方法，然后找到其中名称与工厂方法factoryMethod属性一致的候选方法， 1234567Method[] rawCandidates = getCandidateMethods(factoryClass, mbd);List&lt;Method&gt; candidateSet = new ArrayList&lt;Method&gt;();for (Method candidate : rawCandidates) &#123; if (Modifier.isStatic(candidate.getModifiers()) == isStatic &amp;&amp; mbd.isFactoryMethod(candidate)) &#123; candidateSet.add(candidate); &#125;&#125; 在得到候选方法之后，就需要对这些候选方法进行排序，排序的规则是public方法先于其它类型方法，参数个数多的优先. 12345678910111213141516171819Method[] candidates = candidateSet.toArray(new Method[candidateSet.size()]);AutowireUtils.sortFactoryMethods(candidates);//候选方法排序public static void sortFactoryMethods(Method[] factoryMethods) &#123; Arrays.sort(factoryMethods, new Comparator&lt;Method&gt;() &#123; @Override public int compare(Method fm1, Method fm2) &#123; boolean p1 = Modifier.isPublic(fm1.getModifiers()); boolean p2 = Modifier.isPublic(fm2.getModifiers()); if (p1 != p2) &#123; return (p1 ? -1 : 1); &#125; int c1pl = fm1.getParameterTypes().length; int c2pl = fm2.getParameterTypes().length; return (c1pl &lt; c2pl ? 1 : (c1pl &gt; c2pl ? -1 : 0)); &#125; &#125;);&#125; 排序完后，就需要得到这些方法中匹配度最高的那个方法，匹配度的规则为类型匹配，具体规则可以参阅这里. 如果存在两个匹配度完全一样的候选方法，那么会抛出异常. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253for (Method candidate : candidates) &#123; Class&lt;?&gt;[] paramTypes = candidate.getParameterTypes(); //参数个数不能少于指定的参数个数 if (paramTypes.length &gt;= minNrOfArgs) &#123; ArgumentsHolder argsHolder; //没有指定explictArgs的场景，需要通过类型转换及自动注入等机制获取方法的参数 if (resolvedValues != null) &#123; String[] paramNames = null; ParameterNameDiscoverer pnd = this.beanFactory.getParameterNameDiscoverer(); if (pnd != null) &#123; paramNames = pnd.getParameterNames(candidate); &#125; argsHolder = createArgumentArray( beanName, mbd, resolvedValues, bw, paramTypes, paramNames, candidate, autowiring); &#125; else &#123; //显式给定了参数，则直接比较参数个数，并包装相应的参数 // Explicit arguments given -&gt; arguments length must match exactly. if (paramTypes.length != explicitArgs.length) &#123; continue; &#125; argsHolder = new ArgumentsHolder(explicitArgs); &#125; //比较权重, 找到权重值最小的那个候选方法 int typeDiffWeight = (mbd.isLenientConstructorResolution() ? argsHolder.getTypeDifferenceWeight(paramTypes) : argsHolder.getAssignabilityWeight(paramTypes)); // Choose this factory method if it represents the closest match. if (typeDiffWeight &lt; minTypeDiffWeight) &#123; factoryMethodToUse = candidate; argsHolderToUse = argsHolder; argsToUse = argsHolder.arguments; minTypeDiffWeight = typeDiffWeight; ambiguousFactoryMethods = null; &#125; // Find out about ambiguity: In case of the same type difference weight // for methods with the same number of parameters, collect such candidates // and eventually raise an ambiguity exception. // However, only perform that check in non-lenient constructor resolution mode, // and explicitly ignore overridden methods (with the same parameter signature). else if (factoryMethodToUse != null &amp;&amp; typeDiffWeight == minTypeDiffWeight &amp;&amp; !mbd.isLenientConstructorResolution() &amp;&amp; paramTypes.length == factoryMethodToUse.getParameterTypes().length &amp;&amp; !Arrays.equals(paramTypes, factoryMethodToUse.getParameterTypes())) &#123; if (ambiguousFactoryMethods == null) &#123; ambiguousFactoryMethods = new LinkedHashSet&lt;Method&gt;(); ambiguousFactoryMethods.add(factoryMethodToUse); &#125; ambiguousFactoryMethods.add(candidate); &#125; &#125;&#125; 在遍历完所有的候选方法后，正常情况下就应该能获取到唯一的工厂方法factoryMethodToUse，但也不排除可能会有多个方法同时满足条件，因此这里需要再对遍历后的结果进行判断. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//工厂方法仍然为空，这时候容器类无法继续实例化对象，开始收集对象信息，并抛出异常if (factoryMethodToUse == null) &#123; if (causes != null) &#123; UnsatisfiedDependencyException ex = causes.removeLast(); for (Exception cause : causes) &#123; this.beanFactory.onSuppressedException(cause); &#125; throw ex; &#125; List&lt;String&gt; argTypes = new ArrayList&lt;String&gt;(minNrOfArgs); if (explicitArgs != null) &#123; for (Object arg : explicitArgs) &#123; argTypes.add(arg != null ? arg.getClass().getSimpleName() : \"null\"); &#125; &#125; else &#123; Set&lt;ValueHolder&gt; valueHolders = new LinkedHashSet&lt;ValueHolder&gt;(resolvedValues.getArgumentCount()); valueHolders.addAll(resolvedValues.getIndexedArgumentValues().values()); valueHolders.addAll(resolvedValues.getGenericArgumentValues()); for (ValueHolder value : valueHolders) &#123; String argType = (value.getType() != null ? ClassUtils.getShortName(value.getType()) : (value.getValue() != null ? value.getValue().getClass().getSimpleName() : \"null\")); argTypes.add(argType); &#125; &#125; String argDesc = StringUtils.collectionToCommaDelimitedString(argTypes); throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"No matching factory method found: \" + (mbd.getFactoryBeanName() != null ? \"factory bean '\" + mbd.getFactoryBeanName() + \"'; \" : \"\") + \"factory method '\" + mbd.getFactoryMethodName() + \"(\" + argDesc + \")'. \" + \"Check that a method with the specified name \" + (minNrOfArgs &gt; 0 ? \"and arguments \" : \"\") + \"exists and that it is \" + (isStatic ? \"static\" : \"non-static\") + \".\");&#125;//工厂方法不能返回void值else if (void.class == factoryMethodToUse.getReturnType()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Invalid factory method '\" + mbd.getFactoryMethodName() + \"': needs to have a non-void return type!\");&#125;//不止有一个工厂方法满足条件else if (ambiguousFactoryMethods != null) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Ambiguous factory method matches found in bean '\" + beanName + \"' \" + \"(hint: specify index/type/name arguments for simple parameters to avoid type ambiguities): \" + ambiguousFactoryMethods);&#125;//缓存mdb与factoryMethodToUse的关系，后续就可以直接从缓存中获取if (explicitArgs == null &amp;&amp; argsHolderToUse != null) &#123; argsHolderToUse.storeCache(mbd, factoryMethodToUse); 如果以上的检查没有抛出任何异常，那么说明容器已经找到当前对象的工厂方法及相应的参数，可以开始创建实例的操作了. 这里需要注意的是beanFactory容器并不是自行实例化对象，而是通过InstantiationStrategy接口来完成的，默认的实现是CglibSubclassInstantiateStrategy, 也就是通过Cglib继承子类的方式来创建对象，这也是Spring框架中非常值得学习的一点，面向接口编程，提供最大限度地灵活性. 到此为止，容器通过工厂对象创建实例的操作就算全部完成了. 12345678910111213141516171819202122232425262728293031try &#123; Object beanInstance; if (System.getSecurityManager() != null) &#123; final Object fb = factoryBean; final Method factoryMethod = factoryMethodToUse; final Object[] args = argsToUse; beanInstance = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; return beanFactory.getInstantiationStrategy().instantiate( mbd, beanName, beanFactory, fb, factoryMethod, args); &#125; &#125;, beanFactory.getAccessControlContext()); &#125; else &#123; //通过InstantiateStrategy接口来完成实例化工作 beanInstance = this.beanFactory.getInstantiationStrategy().instantiate( mbd, beanName, this.beanFactory, factoryBean, factoryMethodToUse, argsToUse); &#125; if (beanInstance == null) &#123; return null; &#125; bw.setBeanInstance(beanInstance); return bw;&#125;catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Bean instantiation via factory method failed\", ex);&#125; 2.4.1.2 直接实例化对象创建实例对象的另一种方式就是直接通过bean对象的构造函数. 可以看到，Spring框架在尝试通过构造函数实例化对象时会根据传入的参数是否为空，是否有解析过的构造函数，是否有已经解析过的构造函数参数来决定具体调用的实例化方法. 当传入的构造方法参数不为空时，容器会先调用detemineConstructorsFromBeanPostProcessors方法来获取可用的构造函数, 并最终调用autowireConstructor()方法来实例化对象 当传入的参数为空时，会判断是否已经有解析过的构造方法，如果有，则继续判断是否有解析过的方法参数，并根据情况选择autowireConstructor()方法还是instantiateBean()方法 如果所有的判断条件都不满足，则直接调用instantiateBean()方法来实例化对象 123456789101112131415161718192021222324252627282930// Shortcut when re-creating the same bean...boolean resolved = false;boolean autowireNecessary = false;if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125;&#125;if (resolved) &#123; if (autowireNecessary) &#123; return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; return instantiateBean(beanName, mbd); &#125;&#125;// Need to determine the constructor...Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; return autowireConstructor(beanName, mbd, ctors, args);&#125;// No special handling: simply use no-arg constructor.return instantiateBean(beanName, mbd); 通过以上的分析可以知道，Spring框架是通过instantiateBean()方法和autowireConstructor()方法来进行实例化操作. 现在就来具体看看这两个方法的作用与实现. autowireConstrutor()方法根据autowireConstrutor文档的说明，这个方法是用来解决”构造函数自动注入”的地方, 它能够自动完成构造函数参数的自动注入. 查看这个方法的源码会发现，它的实现与上一小节“使用工厂对象创建实例”基本一样，都是先确定使用的构造方法及参数，选择候选的构造方法、排序、匹配等规则也完全一样，这里就不再做详述，有兴趣的读者可以参阅这部分源码或参考上一小节的解读. instantiateBean()方法这个方法的实现相对简单，通过InstantiateStrategy接口完成实例创建即可. 1234567891011121314151617181920212223protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) &#123; try &#123; Object beanInstance; final BeanFactory parent = this; if (System.getSecurityManager() != null) &#123; beanInstance = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; return getInstantiationStrategy().instantiate(mbd, beanName, parent); &#125; &#125;, getAccessControlContext()); &#125; else &#123; beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent); &#125; BeanWrapper bw = new BeanWrapperImpl(beanInstance); initBeanWrapper(bw); return bw; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Instantiation of bean failed\", ex); &#125;&#125; 到此为止，不管是通过工厂对象创建，还是直接通过构造函数创建，Spring容器已经完成了createBean()方法中的第一步，创建BeanWrapper的操作. 有了实例对象后，就需要对实例的属性进行填充及初始化操作. 这部分内容将会在下一篇文章中进行详细阐述. 2.4.2 populateBean()方法在创建完bean对象之后，就需要填充对象的属性，这个操作由populateBean()方法完成. populateBean()方法可以分成四个步骤： 调用InstantiationAwareBeanPostProcessor接口的afterInstantiation()方法，这个接口定义了三个方法beforeInstantiazion, afterInstantiation以及postProcessorPropertyValues()， 分别用于在实例化对象前后以及在设置对象的属性值之前进行处理. beforeInstantiation()方法在调用createBean()方法之前就已经被调用过了，这里是在实例化对象之后，所以调用的是afterInstantiation()方法，而postProcessorPropertyValues()方法会在解析完属性值之后，填充到对象之前被调用，在populateBean()方法的第三步会碰到. 根据bean对象的定义，选择合适的自动注入模式(byName或byType), 并解析相应的参数 调用InstantiationAwareBeanPostProcessor接口的postProcessorPropertyValues()方法，并检查当前对象的所有属性值是否已经解析完成 填充属性值 2.4.2.1 调用postProcessAfterInstantiation()方法可以看到，这里的实现就是获取容器中定义的所有InstantiationAwareBeanPostProcessor接口，并依次调用它们的postProcessAfterInstantiation()方法即可，没有太多复杂的逻辑，不作赘述. 1234567891011if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125;&#125; 2.4.2.2 根据自动注入模式获取属性值bean对象的自动注入模式是在定义bean时通过autowire属性来设置的，可选的值包括byName, byType以及constructor, 其中constructor的情况已经在创建对象实例时处理过了，因此这里只需要考虑byName和byType两种情况. 顾名思义，byName就是通过属性的名称与容器中定义的bean名称进行自动注入，而byType则是根据类型注入. 12345678910111213141516if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // Add property values based on autowire by type if applicable. if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs;&#125; 根据bean名称自动注入从autowireByName()的实现可以看出，这个模式的自动注入过程比较简单，首先获取当前bean对象中还没有被设置过的非简单类型的属性(Spring框架不允许简单类型的自动注入), 然后遍历这些属性，根据属性的名称尝试从容器中获取相应的bean对象，得到依赖的对象后，记录该属性对应的值，并设置相应的依赖关系表即可. 123456789101112protected void autowireByName( String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) &#123; String[] propertyNames = unsatisfiedNonSimpleProperties(mbd, bw); for (String propertyName : propertyNames) &#123; if (containsBean(propertyName)) &#123; Object bean = getBean(propertyName); pvs.add(propertyName, bean); registerDependentBean(propertyName, beanName); &#125; &#125;&#125; 根据类型自动注入autowireByType()方法的实现思路和byName()的思路是一样的，也是先获取当前bean对象中没有被设置过的非简单类型的属性，然后遍历这些属性，只不过这里不是根据bean对象的名称完成注入，而是调用了resolveDependency()方法来获取与属性匹配的对象，并将该对象注入到属性中，设置相应的依赖关系. resolveDependency()方法的实现稍微有些复杂，这里暂时略过，本文最后会对这个方法进行详述. 1234567891011121314151617181920212223242526272829303132333435protected void autowireByType( String beanName, AbstractBeanDefinition mbd, BeanWrapper bw, MutablePropertyValues pvs) &#123; TypeConverter converter = getCustomTypeConverter(); if (converter == null) &#123; converter = bw; &#125; Set&lt;String&gt; autowiredBeanNames = new LinkedHashSet&lt;String&gt;(4); String[] propertyNames = unsatisfiedNonSimpleProperties(mbd, bw); for (String propertyName : propertyNames) &#123; try &#123; PropertyDescriptor pd = bw.getPropertyDescriptor(propertyName); // Don't try autowiring by type for type Object: never makes sense, // even if it technically is a unsatisfied, non-simple property. if (Object.class != pd.getPropertyType()) &#123; MethodParameter methodParam = BeanUtils.getWriteMethodParameter(pd); // Do not allow eager init for type matching in case of a prioritized post-processor. boolean eager = !PriorityOrdered.class.isAssignableFrom(bw.getWrappedClass()); DependencyDescriptor desc = new AutowireByTypeDependencyDescriptor(methodParam, eager); Object autowiredArgument = resolveDependency(desc, beanName, autowiredBeanNames, converter); if (autowiredArgument != null) &#123; pvs.add(propertyName, autowiredArgument); &#125; for (String autowiredBeanName : autowiredBeanNames) &#123; registerDependentBean(autowiredBeanName, beanName); &#125; autowiredBeanNames.clear(); &#125; &#125; catch (BeansException ex) &#123; throw new UnsatisfiedDependencyException(mbd.getResourceDescription(), beanName, propertyName, ex); &#125; &#125;&#125; 2.4.2.3 调用postProcessPropertyValues()并检查依赖根据配置的注入模式获取到相应的值之后，就可以调用InstantiationAwareBeanPostProcessor接口的postProcessPropertyValue了，另外，考虑到在解析属性值的过程中，有些属性值可能会解析不到相应的对象，因此在赋值之前还需要校验是否所有的属性值都已经解析完成了. 1234567891011121314151617181920boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors();boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE);if (hasInstAwareBpps || needsDepCheck) &#123; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; checkDependencies(beanName, mbd, filteredPds, pvs); &#125;&#125; 2.4.2.4 设置属性值在经过前面三步之后，Spring容器已经获取到所有属性的值，并且已经完成了相应的BeanPostProcessor接口的调用及依赖关系的校验，最后一步就是将这些属性值赋给对象的相应属性即可. 2.4.3 initilizeBean()方法在调用populateBean()方法填充完bean对象后，对象的创建工作就基本完成了. Spring容器中定义了定义了生命周期方法，用于在构造完对象之后和析构对象之前执行定制化的操作，其中包括InitializingBean接口，Aware接口以及配置文件中的init-method属性. 这些属性的处理都是在initializeBean()方法中进行处理的. 可以看到， initializeBean()方法主要是四个步骤： 调用Aware相关的接口，其中包括BeanNameAware接口，BeanClassLoaderAware接口以及BeanFactoryAware接口 调用BeanPostProcessor的postProcessorBeforeInitialization()方法 调用initMethod方法，包括InitializingBean接口以及init-method属性定义的方法, 其中InitializingBean接口先于init-method方法执行 调用BeanPostProcessor的postProcessorAfterInitialization()方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123; //执行Aware接口方法 invokeAwareMethods(beanName, bean); //执行BeanPostProcessor的beforeIntialization()方法 Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; //执行init()方法 try &#123; invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, \"Invocation of init method failed\", ex); &#125; //执行BeanPostProcessor接口的afterBeanInitialization方法 if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean;&#125;//invokeAwareMethodprivate void invokeAwareMethods(final String beanName, final Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if (bean instanceof BeanClassLoaderAware) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(getBeanClassLoader()); &#125; if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); &#125; &#125;&#125;//invokeInitMethodprotected void invokeInitMethods(String beanName, final Object bean, RootBeanDefinition mbd) throws Throwable &#123; //执行InitializaingBean接口 boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(\"afterPropertiesSet\"))) &#123; ((InitializingBean) bean).afterPropertiesSet(); &#125; //执行init-method方法 if (mbd != null) &#123; String initMethodName = mbd.getInitMethodName(); if (initMethodName != null &amp;&amp; !(isInitializingBean &amp;&amp; \"afterPropertiesSet\".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) &#123; invokeCustomInitMethod(beanName, bean, mbd); &#125; &#125;&#125; 2. 5 resolveDependency()方法在前面提到的populateBean()方法中，如果bean对象注入的模式是byType, 那么Spring容器会调用resolveDependency()方法来解析属性的注入值，现在就来详细地看下这个方法的实现. resolveDependency()方法的实现主要是由doResolveDependency()方法来完成，这个方法的实现可以分成三个步骤： 首先尝试从autowireCandidateResolver接口尝试获取请求的类型是否有建议值，如果有则直接返回这个值即可，当然在返回前，可能还需要使用容器的类型转换. 123456789101112Object value = getAutowireCandidateResolver().getSuggestedValue(descriptor);if (value != null) &#123; if (value instanceof String) &#123; String strVal = resolveEmbeddedValue((String) value); BeanDefinition bd = (beanName != null &amp;&amp; containsBean(beanName) ? getMergedBeanDefinition(beanName) : null); value = evaluateBeanDefinitionString(strVal, bd); &#125; TypeConverter converter = (typeConverter != null ? typeConverter : getTypeConverter()); return (descriptor.getField() != null ? converter.convertIfNecessary(value, type, descriptor.getField()) : converter.convertIfNecessary(value, type, descriptor.getMethodParameter()));&#125; 判断当前的属性类型是否为Array, Collection以及Map类型 这种情况下，框架首先会分别获取Array数组元素类型，Collection元素类型以及Map中的Value类型, 然后再以这些元素类型为请求类型，调用findAutowireCandidates()方法查找候选的注入对象，返回所有的匹配对象. 尝试从容器中找到所有与请求类型匹配的对象 这步主要是通过findAutowireCandidates()方法来完成的. findAutowireCandidates()方法首先从resolvableDependencies表中查找请求类型的值，然后遍历所有与请求类型匹配的对象，依次检查它们是否有可能是候选的对象，这步是通过isAutowireCandidate()方法来完成的，这个方法会在后续进行说明. 遍历结束后如果没有候选的对象，那么Spring容器还会尝试备选的描述符再次进行匹配，如果匹配结果还是为空，Spring框架会把”自我引用”的情况也考虑在内，最终返回可能的候选对象. 12345678910111213141516171819202122232425262728293031323334353637383940protected Map&lt;String, Object&gt; findAutowireCandidates( String beanName, Class&lt;?&gt; requiredType, DependencyDescriptor descriptor) &#123; String[] candidateNames = BeanFactoryUtils.beanNamesForTypeIncludingAncestors( this, requiredType, true, descriptor.isEager()); Map&lt;String, Object&gt; result = new LinkedHashMap&lt;String, Object&gt;(candidateNames.length); for (Class&lt;?&gt; autowiringType : this.resolvableDependencies.keySet()) &#123; if (autowiringType.isAssignableFrom(requiredType)) &#123; Object autowiringValue = this.resolvableDependencies.get(autowiringType); autowiringValue = AutowireUtils.resolveAutowiringValue(autowiringValue, requiredType); if (requiredType.isInstance(autowiringValue)) &#123; result.put(ObjectUtils.identityToString(autowiringValue), autowiringValue); break; &#125; &#125; &#125; for (String candidateName : candidateNames) &#123; if (!isSelfReference(beanName, candidateName) &amp;&amp; isAutowireCandidate(candidateName, descriptor)) &#123; result.put(candidateName, descriptor.resolveCandidate(candidateName, this)); &#125; &#125; if (result.isEmpty() &amp;&amp; !indicatesMultipleBeans(requiredType)) &#123; // Consider fallback matches if the first pass failed to find anything... DependencyDescriptor fallbackDescriptor = descriptor.forFallbackMatch(); for (String candidateName : candidateNames) &#123; if (!isSelfReference(beanName, candidateName) &amp;&amp; isAutowireCandidate(candidateName, fallbackDescriptor)) &#123; result.put(candidateName, descriptor.resolveCandidate(candidateName, this)); &#125; &#125; if (result.isEmpty()) &#123; // Consider self references before as a final pass for (String candidateName : candidateNames) &#123; if (isSelfReference(beanName, candidateName) &amp;&amp; isAutowireCandidate(candidateName, fallbackDescriptor)) &#123; result.put(candidateName, descriptor.resolveCandidate(candidateName, this)); &#125; &#125; &#125; &#125; return result;&#125; 在找到备选对象后，如果存在多个备选对象的情况，Spring容器还会调用determineAutowireCandidate()方法来决定最终注入哪个对象. 选择的依据就是bean的配置信息中是否设置了primary属性，或者设置了Priority注解. 对于primary属性，必须有且只有一个对象配置了这个属性，否则会抛出异常；而对于Priority注解，则不能存在两个优先级相同的最高优先级对象，否则也会抛出异常. 如果所有的候选对象中都没有设置这些属性值，Spring框架会尝试根据候选对象的别名进行匹配，直到找到匹配对象为止. 123456789101112131415161718192021protected String determineAutowireCandidate(Map&lt;String, Object&gt; candidateBeans, DependencyDescriptor descriptor) &#123; Class&lt;?&gt; requiredType = descriptor.getDependencyType(); String primaryCandidate = determinePrimaryCandidate(candidateBeans, requiredType); if (primaryCandidate != null) &#123; return primaryCandidate; &#125; String priorityCandidate = determineHighestPriorityCandidate(candidateBeans, requiredType); if (priorityCandidate != null) &#123; return priorityCandidate; &#125; // Fallback for (Map.Entry&lt;String, Object&gt; entry : candidateBeans.entrySet()) &#123; String candidateBeanName = entry.getKey(); Object beanInstance = entry.getValue(); if ((beanInstance != null &amp;&amp; this.resolvableDependencies.containsValue(beanInstance)) || matchesBeanName(candidateBeanName, descriptor.getDependencyName())) &#123; return candidateBeanName; &#125; &#125; return null;&#125; 2.6 isAutowireCandidate()方法在上面解读resolveDependency()方法的过程中，我们路过了isAutowireCandidate()方法的说明，这里就来看看它的实现. 可以看到，这个方法的最后是调用了AutowireCandidateResolver接口来完成判断，这里可以认为是“策略模式”的实现. 以当前的例子来讲，DefaultListableBeanFactory类中默认使用的是SimpleAutowireCandidateResolver实现，这个实现在判断某个对象能否成为候选的注入对象时，以bean定义中的autowire-candidate属性为准. 1234567891011121314151617protected boolean isAutowireCandidate(String beanName, RootBeanDefinition mbd, DependencyDescriptor descriptor, AutowireCandidateResolver resolver) &#123; String beanDefinitionName = BeanFactoryUtils.transformedBeanName(beanName); resolveBeanClass(mbd, beanDefinitionName); if (mbd.isFactoryMethodUnique) &#123; boolean resolve; synchronized (mbd.constructorArgumentLock) &#123; resolve = (mbd.resolvedConstructorOrFactoryMethod == null); &#125; if (resolve) &#123; new ConstructorResolver(this).resolveFactoryMethodIfPossible(mbd); &#125; &#125; return resolver.isAutowireCandidate( new BeanDefinitionHolder(mbd, beanName, getAliases(beanDefinitionName)), descriptor);&#125; 总结到此为止，我们已经把Spring框架中提供的IoC模块的实现源码做了比较简单的解读，这里做个总结，Spring框架提供的IoC机制可以通过读取配置文件及注解的方式，自动管理应用程序的对象以及它们之间的依赖关系，整个实现过程可以分成两个大的步骤： 调用refresh()方法加载bean定义，并配置相应的BeanFactoryPostProcessor, BeanPostProcessor, MessageSource以及事件监听器等设置. 加载bean定义主要是通过读取配置文件的方式进行，对于默认的beans命名空间有默认的读取方式，而对于自定义的命名空间，则是通过NamespaceHandlerResolver来获取相应的NamespaceHandler对象，并交由它来读取相应的配置 当读取完对象的定义后，应用程序就可以调用getBean()方法来获取容器中管理的对象，这个方法的实现可大体分成三个步骤： 根据类型解析名称 如果存在多个满足条件的名称，则按一定的规则进行过滤，获取匹配度最高的那个bean名称 根据bean名称获取对象实例，获取的过程可简单概括为： 先确保它依赖的所有对象都已经完成创建，然后调用createBean()方法创建对象，在createBean()方法的实现中包括createBeanInstance()，populateBean()以及InitializeBean()三个步骤. 通过解读Spring IoC模块的源码，我们对Spring框架有了基本的了解，后续还需要继续深入理解AOP, MVC模块，才能够形成更加全面的认识. 参考文献 官方文档 Spring JavaDoc]","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"IoC","slug":"IoC","permalink":"http://yoursite.com/tags/IoC/"},{"name":"createBean","slug":"createBean","permalink":"http://yoursite.com/tags/createBean/"}]},{"title":"spring IoC源码分析(2)","slug":"spring/spring-ioc-source-code(2)","date":"2017-04-11T11:42:00.000Z","updated":"2017-04-13T06:00:11.000Z","comments":true,"path":"2017/04/11/spring/spring-ioc-source-code(2)/","link":"","permalink":"http://yoursite.com/2017/04/11/spring/spring-ioc-source-code(2)/","excerpt":"","text":"2. 使用容器在本文的第一部分中，我们对容器的初始化操作refresh()方法做了全面的解读，了解了容器构造的整个过程，包括读取bean对象的定义，配置BeanFactoyPostProcessor&amp;BeanPostProcessor接口，以及其它的属性. 在第一部分的解读过程中，还遗留了一个方法，就是getBean()方法. getBean()方法的使用场景有以下几个，从字面上看，这个方法就是从容器中获取相应的实例对象，那它具体的实现过程又是怎么样的呢? 容器初始化结束后，会调用preInstantiateSingleton()方法来实例化lazyInit属性为false的”单例”对象 应用程序调用getBean()方法获取对象 123456public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); TestController testController = applicationContext.getBean(TestController.class); testController.test(); &#125; 查看ClassPathXmlApplicationContext类的getBean()方法，可以看到它调用的是AbstractApplicationContext类的相应实现，而AbstractApplicationContext方法中是将这个方法的实现委托给内部的BeanFactory对象来实现，从本文第一部分的解读中我们知道，ClassPathXmlApplicationContext内部的BeanFactory对象是在refresh()方法中调用obtainFreshBeanFactory()方法时生成的，默认是DefaultListableBeanFactory的实例，因此我们直接查看DefaultListableBeanFactory类的相应实现即可. 12345@Overridepublic &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException &#123; assertBeanFactoryActive(); return getBeanFactory().getBean(requiredType);&#125; 从DefaultListableBeanFactory类的实现源码可以看到，获取bean实例对象可以分成以下几个步骤： 获取容器中指定类型的bean名称 如果获取的bean名称超过1个，则对名称进行过滤 判断过滤后的bean名称个数，并根据相应的个数获取实例对象 接下来我们来详细地看下这些步骤的执行过程. 2.1 获取指定类型的bean名称这个步骤是通过getBeanNamesForType()方法来完成的，它是获取容器中符合指定类型的bean对象的名称. 首先来看下这个方法的实现, 可以看到，方法首先会判断当前容器是否处于“冻结配置”的阶段(在容器完成refresh()操作后，配置就会处于“冻结”状态), 如果处于冻结状态，容器就会尝试从缓存中获取相应的名称. 当从缓存中无法获取相应的名称时，才会调用doGetBeanNamesForType()方法进行解析，解析完后会将结果放入缓存. 12345678910111213141516public String[] getBeanNamesForType(Class&lt;?&gt; type, boolean includeNonSingletons, boolean allowEagerInit) &#123; if (!isConfigurationFrozen() || type == null || !allowEagerInit) &#123; return doGetBeanNamesForType(ResolvableType.forRawClass(type), includeNonSingletons, allowEagerInit); &#125; Map&lt;Class&lt;?&gt;, String[]&gt; cache = (includeNonSingletons ? this.allBeanNamesByType : this.singletonBeanNamesByType); String[] resolvedBeanNames = cache.get(type); if (resolvedBeanNames != null) &#123; return resolvedBeanNames; &#125; resolvedBeanNames = doGetBeanNamesForType(ResolvableType.forRawClass(type), includeNonSingletons, true); if (ClassUtils.isCacheSafe(type, getBeanClassLoader())) &#123; cache.put(type, resolvedBeanNames); &#125; return resolvedBeanNames;&#125; 从上面的解读中可以知道，实际的工作是在doGetBeanNamesForType()方法中完成的. 这个方法的实现可以分成两个部分，一部分是遍历容器中定义的所有对象的类型，找到其中匹配的对象；另一部分是遍历自定义的单例对象，找到其中匹配的对象名称. 但是不管是遍历哪部分的对象，其实现的思路都是一致的 首先匹配beanName对象的类型与请求的类型是否一致 不一致的情况下，再尝试匹配beanName的工厂对象创建的对象类型与请求的类型是否一致 具体的匹配操作是通过isTypeMatch()方法来完成的. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private String[] doGetBeanNamesForType(ResolvableType type, boolean includeNonSingletons, boolean allowEagerInit) &#123; List&lt;String&gt; result = new ArrayList&lt;String&gt;(); // 遍历容器中的对象 for (String beanName : this.beanDefinitionNames) &#123; RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); // Only check bean definition if it is complete. if (!mbd.isAbstract() &amp;&amp; (allowEagerInit || ((mbd.hasBeanClass() || !mbd.isLazyInit() || isAllowEagerClassLoading())) &amp;&amp; !requiresEagerInitForType(mbd.getFactoryBeanName()))) &#123; // In case of FactoryBean, match object created by FactoryBean. boolean isFactoryBean = isFactoryBean(beanName, mbd); boolean matchFound = (allowEagerInit || !isFactoryBean || containsSingleton(beanName)) &amp;&amp; (includeNonSingletons || isSingleton(beanName)) &amp;&amp; isTypeMatch(beanName, type); if (!matchFound &amp;&amp; isFactoryBean) &#123; // In case of FactoryBean, try to match FactoryBean instance itself next. beanName = FACTORY_BEAN_PREFIX + beanName; matchFound = (includeNonSingletons || mbd.isSingleton()) &amp;&amp; isTypeMatch(beanName, type); &#125; if (matchFound) &#123; result.add(beanName); &#125; &#125; &#125; // 遍历程序手动注册的单例对象 for (String beanName : this.manualSingletonNames) &#123; try &#123; // In case of FactoryBean, match object created by FactoryBean. if (isFactoryBean(beanName)) &#123; if ((includeNonSingletons || isSingleton(beanName)) &amp;&amp; isTypeMatch(beanName, type)) &#123; result.add(beanName); // Match found for this bean: do not match FactoryBean itself anymore. continue; &#125; // In case of FactoryBean, try to match FactoryBean itself next. beanName = FACTORY_BEAN_PREFIX + beanName; &#125; // Match raw bean instance (might be raw FactoryBean). if (isTypeMatch(beanName, type)) &#123; result.add(beanName); &#125; &#125; catch (NoSuchBeanDefinitionException ex) &#123; // Shouldn't happen - probably a result of circular reference resolution... if (logger.isDebugEnabled()) &#123; logger.debug(\"Failed to check manually registered singleton with name '\" + beanName + \"'\", ex); &#125; &#125; &#125; return StringUtils.toStringArray(result);&#125; isTypeMatch()方法的作用是判断提供的beanName对象是否与请求的类型匹配，在判断的过程，它会考虑beanName是否为FactoryBean，以及需要判断的类型是FactoryBean本身还是它创建的对象. 它的实现可以分成三个步骤 从缓存中获取实例对象 这里可以看到，当缓存中获取到对象时，它首先会判断该对象类型是否为FactoryBean，如果是的话它还需要判断是否比较的是FactoryBean本身的类型还是它创建的对象类型，这点是通过beanName来判断的. 如果不是FactoryBean, 则直接判断返回的对象类型与请求的类型是否匹配即可. 123456789101112131415Object beanInstance = getSingleton(beanName, false);if (beanInstance != null) &#123; if (beanInstance instanceof FactoryBean) &#123; if (!BeanFactoryUtils.isFactoryDereference(name)) &#123; Class&lt;?&gt; type = getTypeForFactoryBean((FactoryBean&lt;?&gt;) beanInstance); return (type != null &amp;&amp; typeToMatch.isAssignableFrom(type)); &#125; else &#123; return typeToMatch.isInstance(beanInstance); &#125; &#125; else &#123; return (!BeanFactoryUtils.isFactoryDereference(name) &amp;&amp; typeToMatch.isInstance(beanInstance)); &#125;&#125; 缓存获取失败的情况下，如果当前容器不包含bean的定义，且父容器不为空，则交给父容器判断类型匹配的工作 否则尝试从容器中定义的bean信息判断类型匹配信息 这里首先判断bean定义的对象是否是代理对象(dbd!=null)，如果是则判断被代理对象的类型能否满足条件，否则直接获取当前bean定义的类型. 在得到类型后，仍然需要判断当前对象是否是FactoryBean以及是否需要匹配的是FactoryBean对象本身的类型，这点和从缓存中获取到对象后的逻辑一样. 1234567891011121314151617181920212223242526272829303132333435363738394041424344// Retrieve corresponding bean definition.RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);Class&lt;?&gt; classToMatch = typeToMatch.getRawClass();Class&lt;?&gt;[] typesToMatch = (FactoryBean.class == classToMatch ? new Class&lt;?&gt;[] &#123;classToMatch&#125; : new Class&lt;?&gt;[] &#123;FactoryBean.class, classToMatch&#125;);// 判断当前bean定义是否是代理的对象，是的话首先判断被代理对象是否满足要求BeanDefinitionHolder dbd = mbd.getDecoratedDefinition();if (dbd != null &amp;&amp; !BeanFactoryUtils.isFactoryDereference(name)) &#123; RootBeanDefinition tbd = getMergedBeanDefinition(dbd.getBeanName(), dbd.getBeanDefinition(), mbd); Class&lt;?&gt; targetClass = predictBeanType(dbd.getBeanName(), tbd, typesToMatch); if (targetClass != null &amp;&amp; !FactoryBean.class.isAssignableFrom(targetClass)) &#123; return typeToMatch.isAssignableFrom(targetClass); &#125;&#125;//如果不是代理对象，获取当前bean定义的类型信息Class&lt;?&gt; beanType = predictBeanType(beanName, mbd, typesToMatch);if (beanType == null) &#123; return false;&#125;// 判断是否为FactoryBean以及是否需要匹配FactoryBean本身的类型if (FactoryBean.class.isAssignableFrom(beanType)) &#123; if (!BeanFactoryUtils.isFactoryDereference(name)) &#123; // If it's a FactoryBean, we want to look at what it creates, not the factory class. beanType = getTypeForFactoryBean(beanName, mbd); if (beanType == null) &#123; return false; &#125; &#125;&#125;else if (BeanFactoryUtils.isFactoryDereference(name)) &#123; // Special case: A SmartInstantiationAwareBeanPostProcessor returned a non-FactoryBean // type but we nevertheless are being asked to dereference a FactoryBean... // Let's check the original bean class and proceed with it if it is a FactoryBean. beanType = predictBeanType(beanName, mbd, FactoryBean.class); if (beanType == null || !FactoryBean.class.isAssignableFrom(beanType)) &#123; return false; &#125;&#125;return typeToMatch.isAssignableFrom(beanType); 在上面的解读中可以看到，获取beanName对象的实际类型是通过predictBeanType()方法来实现的，这个方法最终会调用doResolveBeanClass()方法来匹配，这个方法首先会根据typesToMatch参数判断当前是否在进行类型匹配操作，并以此为依据选择类加载器classLoaderToUse, 对于类型匹配操作来讲，Spring容器会使用临时的类加载器，以避免在类型匹配的过程中加载相关的类. 在确定了要使用的类加载器后，就会使用该加载器来加载bean，并返回相应的类信息. 12345678910111213141516171819202122232425262728293031323334353637383940414243private Class&lt;?&gt; doResolveBeanClass(RootBeanDefinition mbd, Class&lt;?&gt;... typesToMatch) throws ClassNotFoundException &#123; ClassLoader beanClassLoader = getBeanClassLoader(); ClassLoader classLoaderToUse = beanClassLoader; //判断当前是否是在进行类型匹配操作 if (!ObjectUtils.isEmpty(typesToMatch)) &#123; // When just doing type checks (i.e. not creating an actual instance yet), // use the specified temporary class loader (e.g. in a weaving scenario). ClassLoader tempClassLoader = getTempClassLoader(); if (tempClassLoader != null) &#123; classLoaderToUse = tempClassLoader; if (tempClassLoader instanceof DecoratingClassLoader) &#123; DecoratingClassLoader dcl = (DecoratingClassLoader) tempClassLoader; for (Class&lt;?&gt; typeToMatch : typesToMatch) &#123; dcl.excludeClass(typeToMatch.getName()); &#125; &#125; &#125; &#125; //首先从mbd中获取类名信息 String className = mbd.getBeanClassName(); if (className != null) &#123; Object evaluated = evaluateBeanDefinitionString(className, mbd); if (!className.equals(evaluated)) &#123; // A dynamically resolved expression, supported as of 4.2... if (evaluated instanceof Class) &#123; return (Class&lt;?&gt;) evaluated; &#125; else if (evaluated instanceof String) &#123; return ClassUtils.forName((String) evaluated, classLoaderToUse); &#125; else &#123; throw new IllegalStateException(\"Invalid class name expression result: \" + evaluated); &#125; &#125; // When resolving against a temporary class loader, exit early in order // to avoid storing the resolved Class in the bean definition. if (classLoaderToUse != beanClassLoader) &#123; return ClassUtils.forName(className, classLoaderToUse); &#125; &#125; return mbd.resolveBeanClass(beanClassLoader);&#125; 2.2 过滤bean名称在getBean()方法的第一个步骤中，首先根据对象的类型获取到了相应的bean名称数组，如果数组的长度超过1，那么需要对这些对象名称进行过滤. 过滤的主要思路就是去掉那些autowireCandidate属性设置为false的bean定义. 这里有个比较容易疑惑的地方，就是在过滤的过程中，也保留了containBeanDefinition()返回false的bean名称. 查看这个方法的javaDoc可以知道，这个方法仅判断当前的BeanFactory容器中是否含有这个名称的对象定义，不会考虑它的父容器中是否有这个bean. 但过滤完后，这些bean名称都是通过getBean()方法来进一步获取具体的对象定义，而getBean()方法在当前beanFactory如果找不到这个定义，会尝试从它的父容器中寻找，因此这里在过滤的时候，需要保留那些在当前容器中并不存在的bean名称. 1234567891011if (beanNames.length &gt; 1) &#123; ArrayList&lt;String&gt; autowireCandidates = new ArrayList&lt;String&gt;(); for (String beanName : beanNames) &#123; if (!containsBeanDefinition(beanName) || getBeanDefinition(beanName).isAutowireCandidate()) &#123; autowireCandidates.add(beanName); &#125; &#125; if (autowireCandidates.size() &gt; 0) &#123; beanNames = autowireCandidates.toArray(new String[autowireCandidates.size()]); &#125;&#125; 2.3 根据名称获取bean对象实例在完成了第二步的过滤后，接着就会用名称从容器中查找相应的bean实例. 这里分几种情况考虑： 如果只有一个名称满足条件，那么直接尝试获取这个名称指定的实例就可以了 如果满足条件的有多个名称 ，那么需要依次按primary, prirority进行过滤，直到找到唯一的实例对象为止 如果没有任何名称满足条件，则尝试使用父容器获取相应的实例对象 否则直接抛出异常 2.3.1 多个名称符合条件的情况对于第一种情况，只有一个名称满足条件，这里暂时略过，后面统一对getBean()这个方法进行详述. 而第三种情况，其实是在父容器中调用同样的方法，也直接跳过. 这里主要解读下第二种情况，从源码中可以看出，在多个名称符合条件的情况下，Spring框架首先会依次获取这些名称的对象，然后通过determinePrimaryCandidate()方法判断其中是否有唯一的primary属性为true的实例对象，如果有，直接返回这个对象； 如果没有找到，那么会继续调用determiHighestPriorityCandidate()方法判断是否有唯一的Priority注解的对象，如果有，直接返回这个对象，如果还是没有找到那么说明存在多个对象符合条件，那么就抛出异常. 123456789101112131415161718192021222324if (beanNames.length == 1) &#123; return getBean(beanNames[0], requiredType, args);&#125;else if (beanNames.length &gt; 1) &#123; Map&lt;String, Object&gt; candidates = new HashMap&lt;String, Object&gt;(); for (String beanName : beanNames) &#123; candidates.put(beanName, getBean(beanName, requiredType, args)); &#125; String primaryCandidate = determinePrimaryCandidate(candidates, requiredType); if (primaryCandidate != null) &#123; return getBean(primaryCandidate, requiredType, args); &#125; String priorityCandidate = determineHighestPriorityCandidate(candidates, requiredType); if (priorityCandidate != null) &#123; return getBean(priorityCandidate, requiredType, args); &#125; throw new NoUniqueBeanDefinitionException(requiredType, candidates.keySet());&#125;else if (getParentBeanFactory() != null) &#123; return getParentBeanFactory().getBean(requiredType, args);&#125;else &#123; throw new NoSuchBeanDefinitionException(requiredType);&#125; 首先来看看determinePrimaryCandidate()方法的实现，这里依次判断每个候选对象的primary属性，如果有超过一个对象设置primary属性为true, 那么直接抛出异常；如果只有一个对象设置了这个属性，则直接返回这个对象，根据上面的解读，如果只有唯一一个对象设置了这个属性值，那么这个对象将会被直接返回，否则返回null. 123456789101112131415161718192021222324252627282930313233 protected String determinePrimaryCandidate(Map&lt;String, Object&gt; candidateBeans, Class&lt;?&gt; requiredType) &#123; String primaryBeanName = null; for (Map.Entry&lt;String, Object&gt; entry : candidateBeans.entrySet()) &#123; String candidateBeanName = entry.getKey(); Object beanInstance = entry.getValue(); if (isPrimary(candidateBeanName, beanInstance)) &#123; if (primaryBeanName != null) &#123; boolean candidateLocal = containsBeanDefinition(candidateBeanName); boolean primaryLocal = containsBeanDefinition(primaryBeanName); if (candidateLocal &amp;&amp; primaryLocal) &#123; throw new NoUniqueBeanDefinitionException(requiredType, candidateBeans.size(), \"more than one 'primary' bean found among candidates: \" + candidateBeans.keySet()); &#125; else if (candidateLocal) &#123; primaryBeanName = candidateBeanName; &#125; &#125; else &#123; primaryBeanName = candidateBeanName; &#125; &#125; &#125; return primaryBeanName; &#125;protected boolean isPrimary(String beanName, Object beanInstance) &#123; if (containsBeanDefinition(beanName)) &#123; return getMergedLocalBeanDefinition(beanName).isPrimary(); &#125; BeanFactory parentFactory = getParentBeanFactory(); return (parentFactory instanceof DefaultListableBeanFactory &amp;&amp; ((DefaultListableBeanFactory) parentFactory).isPrimary(beanName, beanInstance));&#125; 另外再来看看determineHighestPriorirtyCandidate()方法. 应该来讲，这里的实现思路和上面determineByPrimaryCandidate()方法的思路完全一样，只不过判断是priority，在此基础上还增加了priority属性的比较，其它的都一样. 这里就不再赘述. 123456789101112131415161718192021222324252627protected String determineHighestPriorityCandidate(Map&lt;String, Object&gt; candidateBeans, Class&lt;?&gt; requiredType) &#123; String highestPriorityBeanName = null; Integer highestPriority = null; for (Map.Entry&lt;String, Object&gt; entry : candidateBeans.entrySet()) &#123; String candidateBeanName = entry.getKey(); Object beanInstance = entry.getValue(); Integer candidatePriority = getPriority(beanInstance); if (candidatePriority != null) &#123; if (highestPriorityBeanName != null) &#123; if (candidatePriority.equals(highestPriority)) &#123; throw new NoUniqueBeanDefinitionException(requiredType, candidateBeans.size(), \"Multiple beans found with the same priority ('\" + highestPriority + \"') \" + \"among candidates: \" + candidateBeans.keySet()); &#125; else if (candidatePriority &lt; highestPriority) &#123; highestPriorityBeanName = candidateBeanName; highestPriority = candidatePriority; &#125; &#125; else &#123; highestPriorityBeanName = candidateBeanName; highestPriority = candidatePriority; &#125; &#125; &#125; return highestPriorityBeanName;&#125; 2.3.2 只有一个名称符合条件的情况到这里，我们就把所有特殊的情况都解读过了，现在只剩下最基本的情况，就是根据bean名称来获取相应的实现，这也是在getBean()方法中实现的. 在AbstractBeanFactory类中可以看到，这个方法最终调用了doGetBean()方法，它的实现过程大体可以分成三个步骤： 尝试从已经创建或正在创建的singleton对象中获取，如果有则直接调用getObjectForBeanInstance()返回 如果当前的容器中不包含有这个bean的定义且父容器不为空的情况下，尝试从父容器中获取该bean实例对象 尝试在当前容器中创建这个bean实例对象，这步又可以进一步细分成以下两个步骤 保证当前bean对象的依赖对象已经创建完成 根据当前bean对象的作用域创建相应的实例对象 创建完对象后，如果类型不符合，那么尝试使用类型转换服务转换成目标类型. 接下来分别对这些步骤进行解读. 2.3.2.1 尝试从缓存中获取singleton在这一步中，BeanFactory会尝试从singletonObjects属性中读取这个beanName指定的实例对象，如果找到了说明这个对象之前已经被创建过了，直接返回这个对象即可；如果没有找到这个对象，但发现它正在被创建，那么会尝试从earlySingletonObjects属性中查找，如果还是没有找到，则尝试从singletonFactories中查找相应的对象工厂，如果有这个对象的对象工厂，则尝试创建这个对象. 123456789101112131415161718192021222324// Eagerly check singleton cache for manually registered singletons.Object sharedInstance = getSingleton(beanName);if (sharedInstance != null &amp;&amp; args == null) &#123; bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);&#125;//getSingleton方法protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123; synchronized (this.singletonObjects) &#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &#123; ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &#125; &#125; &#125; &#125; return (singletonObject != NULL_OBJECT ? singletonObject : null);&#125; 在获取到sharedInstance对象后，代码中会调用getObjectForBeanInstance()方法，这个方法的作用是对获取的对象进行解析，如果它是普通对象或者请求的是工厂对象本身(bean名称以’&amp;’开头)则直接返回； 否则就使用工厂方法创建相应的对象. 这里的逻辑相对简单，就不做过多的阐述. 12345678910111213141516171819202122232425262728293031protected Object getObjectForBeanInstance( Object beanInstance, String name, String beanName, RootBeanDefinition mbd) &#123; // Don't let calling code try to dereference the factory if the bean isn't a factory. if (BeanFactoryUtils.isFactoryDereference(name) &amp;&amp; !(beanInstance instanceof FactoryBean)) &#123; throw new BeanIsNotAFactoryException(transformedBeanName(name), beanInstance.getClass()); &#125; // Now we have the bean instance, which may be a normal bean or a FactoryBean. // If it's a FactoryBean, we use it to create a bean instance, unless the // caller actually wants a reference to the factory. if (!(beanInstance instanceof FactoryBean) || BeanFactoryUtils.isFactoryDereference(name)) &#123; return beanInstance; &#125; Object object = null; if (mbd == null) &#123; object = getCachedObjectForFactoryBean(beanName); &#125; if (object == null) &#123; // Return bean instance from factory. FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) beanInstance; // Caches object obtained from FactoryBean if it is a singleton. if (mbd == null &amp;&amp; containsBeanDefinition(beanName)) &#123; mbd = getMergedLocalBeanDefinition(beanName); &#125; boolean synthetic = (mbd != null &amp;&amp; mbd.isSynthetic()); object = getObjectFromFactoryBean(factory, beanName, !synthetic); &#125; return object;&#125; 2.3.2.2 从父容器中获取相应的bean实例对象如果当前容器对象不包含有这个beanName, 且父容器不为空的情况下，会尝试从父容器中获取这个bean实例 1234567891011121314// Check if bean definition exists in this factory.BeanFactory parentBeanFactory = getParentBeanFactory();if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125;&#125; 2.3.2.3 尝试从当前容器中加载bean对象当父容器为空，或者当前容器中含有指定的bean名称的定义，那么就会在当前容器中尝试加载该对象. 加载的过程可以分成两个步骤，第一个是确保当前对象依赖的所有对象都已经创建完成，第二个是根据对象作用域的不同创建相应的对象. 确保依赖的对象已经创建完成 123456789101112// Guarantee initialization of beans that the current bean depends on.String[] dependsOn = mbd.getDependsOn();if (dependsOn != null) &#123; for (String dependsOnBean : dependsOn) &#123; if (isDependent(beanName, dependsOnBean)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, \"Circular depends-on relationship between '\" + beanName + \"' and '\" + dependsOnBean + \"'\"); &#125; registerDependentBean(dependsOnBean, beanName); getBean(dependsOnBean); &#125;&#125; 对于每个依赖的对象，都调用isDependent方法来确认是否存在循环依赖关系. isDependent的作用是判断第二个参数指定的对象是否依赖于第一个参数的对象，如果后者依赖于前者，而前者的dependsOn属性中又包含有第二个，说明两者之前有循环依赖关系，这时直接抛出循环依赖异常. 1234567891011121314151617181920212223242526272829//该方法用于判断第二个参数是否依赖于第一个参数， 第一个参数表示当前对象名称，第二个参数表示依赖于当前对象的名称private boolean isDependent(String beanName, String dependentBeanName, Set&lt;String&gt; alreadySeen) &#123; String canonicalName = canonicalName(beanName); if (alreadySeen != null &amp;&amp; alreadySeen.contains(beanName)) &#123; return false; &#125; //dependentBeanMap属性中存储的是对象间的依赖关系，key为当前对象，value值为依赖于它的对象名称集合. Set&lt;String&gt; dependentBeans = this.dependentBeanMap.get(canonicalName); if (dependentBeans == null) &#123; return false; &#125; //如果dependentBeans中包含有这个名称，说明dependentBeanName依赖于当前对象 if (dependentBeans.contains(dependentBeanName)) &#123; return true; &#125; //如果denpendentBeanName不依赖于当前对象，则继续判断它传递依赖于当前对象，深度优先遍历 for (String transitiveDependency : dependentBeans) &#123; if (alreadySeen == null) &#123; alreadySeen = new HashSet&lt;String&gt;(); &#125; alreadySeen.add(beanName); if (isDependent(transitiveDependency, dependentBeanName, alreadySeen)) &#123; return true; &#125; &#125; return false;&#125; 如果不存在循环依赖关系，则调用registerDependentBean方法注册对象间的依赖关系. 这个方法会往dependentBeanMap中插入相应的名称，这个属性维护了当前对象以及依赖于这个对象的对象名称集合，另外这个方法还会往dependenciesForBeanMap属性中插入数据，这个属性维护的是当前对象以及当前对象所依赖的对象名称集合. 1234567891011121314151617181920212223242526public void registerDependentBean(String beanName, String dependentBeanName) &#123; // A quick check for an existing entry upfront, avoiding synchronization... String canonicalName = canonicalName(beanName); Set&lt;String&gt; dependentBeans = this.dependentBeanMap.get(canonicalName); if (dependentBeans != null &amp;&amp; dependentBeans.contains(dependentBeanName)) &#123; return; &#125; // No entry yet -&gt; fully synchronized manipulation of the dependentBeans Set synchronized (this.dependentBeanMap) &#123; dependentBeans = this.dependentBeanMap.get(canonicalName); if (dependentBeans == null) &#123; dependentBeans = new LinkedHashSet&lt;String&gt;(8); this.dependentBeanMap.put(canonicalName, dependentBeans); &#125; dependentBeans.add(dependentBeanName); &#125; synchronized (this.dependenciesForBeanMap) &#123; Set&lt;String&gt; dependenciesForBean = this.dependenciesForBeanMap.get(dependentBeanName); if (dependenciesForBean == null) &#123; dependenciesForBean = new LinkedHashSet&lt;String&gt;(8); this.dependenciesForBeanMap.put(dependentBeanName, dependenciesForBean); &#125; dependenciesForBean.add(canonicalName); &#125;&#125; 根据对象的作用域创建相应的对象 在确保依赖的对象都已经创建完成后，就可以开始创建当前对象了. 这里要根据对象的作用域(scope)来采用不同的方式创建. 先来看看singleton对象的创建. 这里调用了getSingleton方法来获取对象，并提供了匿名的ObjectFactory实现. 在getSingleton方法中，其实就是回调了ObjectFactory类的getObject方法, 这是“策略模式”的实践. 在获取到sharedInstance对象后，会调用getObjectForBeanInstance方法，这个方法的作用在前面已经提及过，它是用来判断sharedInstance对象的类型，如果是FactoryBean，则调用相应的方法返回对象，如果它是普通对象或请求的就是工厂对象本身，则直接返回. 关于createBean()方法的执行过程，下一篇会有详细的解读. 123456789101112131415161718if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125; 再来看看prototype对象的创建. 由于prototype域对象的特性是每次请求对象时都返回新的对象，因此这里的创建过程相对简单，就是调用createBean()方法返回新的实例，再调用getObjectForBeanInstance()方法进行转换即可. 123456789101112else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);&#125; 除此之外，Spring还支持自定义Scope，对于自定义Scope的对象来讲，它的创建过程与之前的两种情况大同小异，这里就不做过多阐述. 12345678910111213141516171819202122232425262728else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException(\"No Scope registered for scope name '\" + scopeName + \"'\"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() &#123; @Override public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, \"Scope '\" + scopeName + \"' is not active for the current thread; consider \" + \"defining a scoped proxy for this bean if you intend to refer to it from a singleton\", ex); &#125;&#125; 2.3.2.4 类型转换在经过上述步骤后，bean对象的实例就基本上创建好了，这时候还需要再进一步判断当前获取的实例对象类型与实际请求的类型是否匹配，如果不匹配的话，还需要进行类型转换操作. 类型转换主要是通过TypeConverter接口来完成的. 12345678910111213// Check if required type matches the type of the actual bean instance.if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) &#123; try &#123; return getTypeConverter().convertIfNecessary(bean, requiredType); &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(\"Failed to convert bean '\" + name + \"' to required type [\" + ClassUtils.getQualifiedName(requiredType) + \"]\", ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125;&#125;","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"DI","slug":"DI","permalink":"http://yoursite.com/tags/DI/"},{"name":"IoC","slug":"IoC","permalink":"http://yoursite.com/tags/IoC/"}]},{"title":"spring IoC源码分析(1)","slug":"spring/spring-ioc-source-code(1)","date":"2017-04-10T11:39:00.000Z","updated":"2017-04-11T07:33:14.000Z","comments":true,"path":"2017/04/10/spring/spring-ioc-source-code(1)/","link":"","permalink":"http://yoursite.com/2017/04/10/spring/spring-ioc-source-code(1)/","excerpt":"","text":"在JavaEE开发中，基于Spring开发是最目前最常见的方式. Spring框架不但提供了IoC, AOP等支持，在此基础上，还提供了一系列非常简单好用的模块，具体可以Spring官网上的说明. 作为Spring框架的基础，IoC机制使得整个应用程序的各个基础元素间依赖关系的管理变得更加灵活易用，这里我们不对IoC机制的定义进行过多的阐述，而是试图从源码的角度来分析，Spring框架是如何实现所谓的”依赖反转”. 0. 一切都要从BeanFactory说起BeanFactory接口作为整个Spring容器的最基础的接口，它定义了一系列的管理bean组件的方法，具体如下图所示, 从图中可以看出，这个接口中定义了从容器中获取bean的方法getBean, 还定义了判断bean的作用域(scope)的方法, isPrototype和isSingleton， 除此之外，它还提供了方法来判断容器是否含有指定元素containsBean方法. 一般情况下，在应用程序中，beanFactory都是以单例模式中实现，获取到这个容器对象后，就可以通过它来管理应用程序中所有的bean对象以及它们之间的依赖关系. 再来看看BeanFactory接口的类层次图，如下图所示，可以看到这个接口的子接口和实现有很多，其中最重要的接口为ApplicationContext接口，按Spring官方文档中的说法，ApplicatonContext接口提供了比BeanFactory更丰富的功能，包括国际化支持，资源获取，事件发布机制以及层次化的context结构. 1. 程序的入口为了简化程序的代码，我们定义了TestController和TestService, 前者依赖于后者, 具体的代码如下, 从这里也可以看出，Spring框架自动管理了applicationContext.xml中定义的bean对象以及它们之间的依赖关系. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//main.javapublic class Main &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); TestController testController = applicationContext.getBean(TestController.class); testController.test(); &#125;&#125;//applicationContext.xml&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;bean name=\"testController\" class=\"TestController\"&gt; &lt;property name=\"testService\" ref=\"testService\"/&gt; &lt;/bean&gt; &lt;bean name=\"testService\" class=\"TestService\"/&gt;&lt;/beans&gt; //TestControllerpublic class TestController &#123; private TestService testService; public TestService getTestService() &#123; return testService; &#125; public void setTestService(TestService testService) &#123; this.testService = testService; &#125; public void test()&#123; this.testService.sayHello(); &#125;&#125;//TestServicepublic class TestService &#123; public void sayHello()&#123; System.out.println(\"hello world.\"); &#125;&#125;//output: hello word 接下来我们就来看看Spring是如何做到这一切的. 1.1 初始化在上面的代码中，首先初始化了ApplicationContext接口的实例，在这里使用了ClassPathXmlApplicationContext类，除此之外，还可以使用FileSystemXmlApplicationContext, 两者的区别在于加载applicationContext.xml资源时的路径不同， ClassPathXmlApplicationContext类是从classpath目录下查找，而FileSystemXmlApplicationContext类是从文件系统中查找. 首先来看下ClassPathXmlApplicationContext的构造函数, 如下所示，在构造函数中首先设置了配置文件的路径，然后调用了refresh()方法, 可以这么说，refresh()方法实现了Spring框架中IoC机制的一大半功能，在这个方法中，完成了Bean对象的加载. 123456789public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125; &#125; 那就来看看refresh()方法的实现， 源码如下所示，实现的内容很多，但整个逻辑非常地清楚（由衷地对作者表示佩服），整个refresh()方法大体上可以分为以下这些步骤： 更新前的准备工作(prepareRefresh) 读取Bean对象的定义(obtainFreshBeanFactory) 初始化更新后的BeanFactory对象(prepareBeanFactory) 生成BeanFacotry对象后的处理工作(postProcessBeanFactory) 触发BeanFactoryPostProcessor接口（invokeBeanFactoryPostProcessors) 注册BeanPostProcessor接口(registerBeanPostProcessor) 初始化MessageSource(initMessageSource) 初始化事件发布器(initApplicationEventMulticaster) 触发refresh事件(onRefresh) 注册ApplicationEvent事件监听器(registerListeners) 结束BeanFactory的初始化工作(finishBeanFactoryInitialization) 结束refresh操作(finishRefresh) 清理缓存(resetCommonCaches) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364@Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn(\"Exception encountered during context initialization - \" + \"cancelling refresh attempt: \" + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125; &#125; 1.1.1 prepareRefresh首先来看下prepareRefresh方法的实现，作为refresh()方法中的第一个步骤，这个方法主要的功能就是完成更新前的准备工作, 如记录更新开始的时间，更新容器的状态，设置环境等, 其中最重要的是完成PropertySource的初始化，默认情况下，initPropertySources()方法是个空实现，但是它给子类提供了定制化初始化过程的机会，这也可以认为是“模板模式”的应用（严格来讲，模板模式中的方法是抽象方法，但思想是一样的）, 在阅读Spring框架源码的过程中，可以发现有很多设计模式的实践，在遇到时会再次提及. 1234567891011121314151617181920protected void prepareRefresh() &#123; this.startupDate = System.currentTimeMillis(); this.closed.set(false); this.active.set(true); if (logger.isInfoEnabled()) &#123; logger.info(\"Refreshing \" + this); &#125; // Initialize any placeholder property sources in the context environment initPropertySources(); // Validate that all properties marked as required are resolvable // see ConfigurablePropertyResolver#setRequiredProperties getEnvironment().validateRequiredProperties(); // Allow for the collection of early ApplicationEvents, // to be published once the multicaster is available... this.earlyApplicationEvents = new LinkedHashSet&lt;ApplicationEvent&gt;(); &#125; 1.1.2 obtainFreshBeanFactory这个方法中调用了refreshBeanFactory方法，后者完成了整个容器的Bean对象的加载工作，同样，这里的refreshBeanFactory方法也是个抽象方法，它的实现由子类提供，由于我们这里使用的是ClassPathXmlApplicationContext类，因此这个方法的具体实现由AbstractRefreshableApplicationContext类实现. 可以看到，refreshBeanFactory方法的步骤有： 判断当前是否已经有容器了，如果存在 ，则先删除原先容器中的对象，再关闭之前的容器(hasBeanFactory) 接着创建新的容器，并完成容器的初始化工作(createBeanFactory &amp; customizeBeanFactory) 使用新的容器来加载和管理bean对象的定义(loadBeanDefinitions) 将新建的容器对象赋给ApplicationContext 12345678910111213141516171819@Override protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(\"I/O error parsing bean definition source for \" + getDisplayName(), ex); &#125; &#125; 判断是否已经有BeanFactory以及关闭的操作相对比较简单，这里就略过，直接开始看创建新容器以及初始化的操作，可以看到这里生成的是DefaultListableBeanFactory对象，并在生成后根据配置设置参数allowBeanDefinitionOverriding和allowCircularReferences, 前者代表了是否允许重载bean的定义，后者定义了是否允许循环依赖. DefaultListableBeanFactory类是可以直接被使用的BeanFactory实现（不包括ApplicationContext接口的实现）. 1234567891011121314//创建新的BeanFactoryprotected DefaultListableBeanFactory createBeanFactory() &#123; return new DefaultListableBeanFactory(getInternalParentBeanFactory()); &#125;//初始化protected void customizeBeanFactory(DefaultListableBeanFactory beanFactory) &#123; if (this.allowBeanDefinitionOverriding != null) &#123; beanFactory.setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding); &#125; if (this.allowCircularReferences != null) &#123; beanFactory.setAllowCircularReferences(this.allowCircularReferences); &#125; &#125; 接下来就是使用新的容器来加载和管理Bean对象的定义了. 在Spring框架中，bean对象的运行时定义是通过BeanDefinition类来实现的，这个类中定义了关于Bean对象的所有信息，包括构造方法参数，属性值，初始化方法，静态工厂方法等等信息. BeanDefinition之间还可以有继承关系，ChildBeanDefinition继承了ParentBeanDefinition的信息，也可以重写相应的属性. 在spring中，加载bean的信息就是通过这里的loadBeanDefinitions()方法来完成的, 同样，这里的loadBeanDefinitions方法又是个抽象方法，ClassPathXmlApplicationContext类中是通过AbstractXmlApplicationContext类中的方法来完成的，从这里也可以看出，Spring框架中大量使用了”模板模式”，从而将实现延迟到了具体的子类中，大大提高了框架的灵活性，这点在开发中，尤其是在框架开发中非常重要. 在loadBeanDefinitions的实现中，首先定义了XmlBeanDefinitionReader类，它是BeanDefinitionReader接口的实现，主要用于从xml文件中读取配置信息，接着就是配置这个xmlBeanDefinitionReader对象，然后做些初始化的工作，这里值得注意的是，设置了BeanDefinitionReader对象中的ResourceLoader为当前对象，即XmlClassPathApplicationContext对象. 最后就是使用这个xmlBeanDefinitionReader来读取配置文件了. 从BeanDefinitionReader的实现中可以看出，它是一个个读取Resource文件和configLocations文件，其中，对于之前的配置来讲，Resource文件为空，而configLocation文件则是在构造ClassPathXmlApplicationContext对象时传入的参数值，即applicationContext.xml，因此BeanDefinitionReader会尝试从这些文件中获取相应的Bean信息. 1234567891011121314151617181920212223242526272829303132333435363738@Override protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; // Create a new XmlBeanDefinitionReader for the given BeanFactory. XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); // Configure the bean definition reader with this context's // resource loading environment. beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); // Allow a subclass to provide custom initialization of the reader, // then proceed with actually loading the bean definitions. initBeanDefinitionReader(beanDefinitionReader); loadBeanDefinitions(beanDefinitionReader); &#125;//初始化BeanDefinitionReaderprotected void initBeanDefinitionReader(XmlBeanDefinitionReader reader) &#123; reader.setValidating(this.validating); &#125;//利用BeanDefinitionReader来读取配置文件protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; Resource[] configResources = getConfigResources(); if (configResources != null) &#123; reader.loadBeanDefinitions(configResources); &#125; String[] configLocations = getConfigLocations(); if (configLocations != null) &#123; reader.loadBeanDefinitions(configLocations); &#125; &#125;//读取配置文件protected String[] getConfigLocations() &#123; return (this.configLocations != null ? this.configLocations : getDefaultConfigLocations()); &#125; 那么就来看看XmlBeanDefinitionReader是如何来加载Bean信息的. 代码虽然很长，但逻辑却很清楚，首先是获取到ResourceLoader对象，上面提及过，这里的ResourceLoader其实就是ClassPathXmlApplicationContext本身，然后通过这个对象读取location参数指定的资源信息，最后BeanDefinitionReader再从资源中读取相应的Bean定义信息. 1234567891011121314151617181920212223@Override public int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException &#123; Assert.notNull(locations, \"Location array must not be null\"); int counter = 0; for (String location : locations) &#123; counter += loadBeanDefinitions(location); &#125; return counter; &#125;//具体的加载过程 public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException &#123; ....省略一些代码 ResourceLoader resourceLoader = getResourceLoader(); Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location); int loadCount = loadBeanDefinitions(resources); if (actualResources != null) &#123; for (Resource resource : resources) &#123; actualResources.add(resource); &#125; &#125; ....省略一些代码 &#125; 那么再来看看BeanDefinitionReader又是如何从Resource资源对象中读取bean对象的定义的呢？这个方法的实现由XmlClassPathApplicationContext提供，它首先将Resource文件以Xml的格式读取，并形成相应的DOM, 然后调用registerBeanDefinitions()方法来注册bean. 在这个方法中，首先创建了一个BeanDefinitionDocumentReader对象，然后通过这个documentReader来加载Bean. 12345678910111213141516171819202122232425 public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException &#123; ....省略一些代码 InputStream inputStream = encodedResource.getResource().getInputStream(); try &#123; InputSource inputSource = new InputSource(inputStream); if (encodedResource.getEncoding() != null) &#123; inputSource.setEncoding(encodedResource.getEncoding()); &#125; return doLoadBeanDefinitions(inputSource, encodedResource.getResource()); &#125; finally &#123; inputStream.close(); &#125; ....省略一些代码 &#125;//doLoadBeanDefinitionsDocument doc = doLoadDocument(inputSource, resource);return registerBeanDefinitions(doc, resource);//registerBeanDefinitionsBeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();int countBefore = getRegistry().getBeanDefinitionCount();documentReader.registerBeanDefinitions(doc, createReaderContext(resource));return getRegistry().getBeanDefinitionCount() - countBefore; 再来看看这个documentReader又是怎么做的，中间的过程代码这里就直接忽略了，总的来讲documentReader对象在registerBeanDefinitions方法中调用了doRegisterBeanDefinitions()方法，后者完成了加载工作. 这里又可以看出Spring框架中方法命名的一个特点，基本上某个方法如果以do开始，那么这个方法就是实际完成工作的地方，而与它对应的那个方法只是做些协调配置的工作. 在doRegisterBeanDefinition方法中，首先创建了个代理对象，在创建这个代理类的过程中，对一些默认值属性值进行了初始化，包括default-lay-init, default-merge, default-autowire等等属性，这些属性都是在元素中配置的属性，由于涉及到的属性较多，这里就不将全部的源码贴出，仅以lazyInit为例，如果设置的值为default，则会尝试从parent中读取相应的属性，并将属性值填充到delegate对象的defaults属性. 12345678910111213141516171819202122232425262728protected void doRegisterBeanDefinitions(Element root) &#123; BeanDefinitionParserDelegate parent = this.delegate; this.delegate = createDelegate(getReaderContext(), root, parent); ...省略一些代码 preProcessXml(root); parseBeanDefinitions(root, this.delegate); postProcessXml(root); this.delegate = parent; &#125;protected BeanDefinitionParserDelegate createDelegate( XmlReaderContext readerContext, Element root, BeanDefinitionParserDelegate parentDelegate) &#123; BeanDefinitionParserDelegate delegate = new BeanDefinitionParserDelegate(readerContext); delegate.initDefaults(root, parentDelegate); return delegate; &#125;//delegate.initDefaults()方法的部分代码，以lazyInit为例，其它类似String lazyInit = root.getAttribute(DEFAULT_LAZY_INIT_ATTRIBUTE); if (DEFAULT_VALUE.equals(lazyInit)) &#123; // Potentially inherited from outer &lt;beans&gt; sections, otherwise falling back to false. lazyInit = (parentDefaults != null ? parentDefaults.getLazyInit() : FALSE_VALUE); &#125; defaults.setLazyInit(lazyInit); 在完成delegate对象的初始化后，就由这个代理对象来解析bean的定义. 在这个方法中，首先判断根结点是否是默认的命名空间(即beans元素的命名空间http://www.springframework.org/schema/beans). 如果是则依次遍历根结点下的每个子结点，分别判断这些结点的命名空间，默认命名空间则调用parseDefaultElement()方法来解析，否则调用parseCustomElement()方法来解析. parseDefaultElemet()方法是用来处理默认命名空间中的元素，它只负责处理四类子结点，分别是import, alias, bean以及嵌套的beans结点. 而parseCustomElement()方法是用来解析非默认命名空间中定义的结点，如context，mvc等等，对于这些自定义的命名空间，首先调用NamespaceHandlerResolver类的resolve()方法获取命名空间与实际的NamespaceHandler之间的对应关系，根据命名空间获取相应的解析器，并由解析器完成相应的解析工作, 如context命名空间的解析器为NamespaceHandlerResolver类. 由于自定义的命名空间不胜枚举，这里就不再进行详细阐述，有需要的时候可以查看具体的实现. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); for (int i = 0; i &lt; nl.getLength(); i++) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element) node; if (delegate.isDefaultNamespace(ele)) &#123; parseDefaultElement(ele, delegate); &#125; else &#123; delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125; &#125;private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123; importBeanDefinitionResource(ele); &#125; else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123; processAliasRegistration(ele); &#125; else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123; processBeanDefinition(ele, delegate); &#125; else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123; // recurse doRegisterBeanDefinitions(ele); &#125; &#125;public BeanDefinition parseCustomElement(Element ele, BeanDefinition containingBd) &#123; String namespaceUri = getNamespaceURI(ele); NamespaceHandler handler = this.readerContext.getNamespaceHandlerResolver().resolve(namespaceUri); if (handler == null) &#123; error(\"Unable to locate Spring NamespaceHandler for XML schema namespace [\" + namespaceUri + \"]\", ele); return null; &#125; return handler.parse(ele, new ParserContext(this.readerContext, this, containingBd)); &#125; 到此为止，就基本上完成了bean信息的加载过程，obtainFreshBeanFactory方法的执行也基本结束了，总结来看，容器类先是生成了XmlBeanDefinitionReader对象来读取Bean对象的定义，后者又将这个过程委托给BeanDefinitionDocumentReader来完成，而documentReader又委托给了BeanDefinitionParserDelegate，而这个delegate对象中真正完成了bean对象的加载. 1AbstractApplicationContext.loadBeanDefinitions -&gt; XmlBeanDefinitionReader.loadBeanDefinitions -&gt; BeanDefinitionDocumentReader.loadBeanDefinitions -&gt; BeanDefinitionParserDelegate.loadBeanDefinitions -&gt; parseDefaultElement, parseCustomElement 1.1.3 prepareBeanFactory可以看到，prepareBeanFactory方法首先设置beanFactory的属性值，包括ClassLoader, BeanExpressionResolver, PropertyEditorRegistrar, 然后增加了ApplicationContextAwareProcessor这个Aware接口，这就是为什么Spring框架中可以允许自动注入ApplicationContext对象的原因了. 接着，分别调用了ignoreDependencyInterface和registerResolvableDependency方法，前者的作用是忽略相应的接口依赖，这些接口会通过其它的方式完成注入，后者往容器中配置了依赖注入规则，当遇到这些类的依赖时，直接使用指定的对象， 例如需要依赖BeanFactory时，直接使用新生成的容器对象. 最后，prepareBeanFactory方法就会在容器查找框架特定的类定义，如loadTimeWeaver， environment, systemProperties, systemEnvironment等类，如果找到这些Bean的定义，则先实例化这些对象. 123456789101112131415161718192021222324252627282930313233343536373839protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; // Tell the internal bean factory to use the context's class loader etc. beanFactory.setBeanClassLoader(getClassLoader()); beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader())); beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment())); // Configure the bean factory with context callbacks. beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this)); beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class); beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class); beanFactory.ignoreDependencyInterface(MessageSourceAware.class); beanFactory.ignoreDependencyInterface(ApplicationContextAware.class); beanFactory.ignoreDependencyInterface(EnvironmentAware.class); // BeanFactory interface not registered as resolvable type in a plain factory. // MessageSource registered (and found for autowiring) as a bean. beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory); beanFactory.registerResolvableDependency(ResourceLoader.class, this); beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this); beanFactory.registerResolvableDependency(ApplicationContext.class, this); // Detect a LoadTimeWeaver and prepare for weaving, if found. if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); // Set a temporary ClassLoader for type matching. beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125; // Register default environment beans. if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties()); &#125; if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123; beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment()); &#125;&#125; 1.1.4 postProcessBeanFactory在AbstractApplicationContext中，这个方法的实现是空实现，但它给子类一个机会，在完成容器的更新后进行一些定制化的操作，例如在AbstractRefreshableWebApplicationContext的实现中，就会在这个方法中注册ServletContextAwareProcessor接口. 12345678910//AbstractRefreshableWebApplicationContext@Override protected void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123; beanFactory.addBeanPostProcessor(new ServletContextAwareProcessor(this.servletContext, this.servletConfig)); beanFactory.ignoreDependencyInterface(ServletContextAware.class); beanFactory.ignoreDependencyInterface(ServletConfigAware.class); WebApplicationContextUtils.registerWebApplicationScopes(beanFactory, this.servletContext); WebApplicationContextUtils.registerEnvironmentBeans(beanFactory, this.servletContext, this.servletConfig); &#125; 1.1.5 invokeBeanFactoryPostProcessors从方法名就可以看出，这个方法的作用是触发容器中定义的BeanFactoryPostProcessor接口. BeanFactoryPostProcessor接口可以在容器加载完bean信息后对它们的属性进行修改，如进行属性值的替换等操作. Spring文档中告诉我们，框架会自动识别实现了BeanFactoryPostProcessor接口的bean对象，其中的秘密就在这里. 12345678910protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123; PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors()); // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor) if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123; beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory)); beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader())); &#125;&#125; 这里主要来看下invokeBeanFactoryPostProcessors的执行过程. 这里的逻辑要分成两大部分： 处理当前beanFactory中已经有的beanFactoryPostProcessor: 这部分已经通过方法的第二个参数传入. 在处理这部分接口对象时，首先要区分当前的BeanFactory对象是否是BeanDefinitionRegistry接口的实现，如果是, 则除了要处理BeanFactoryPostProcessor接口，还需要找到这些BeanFactoryPostProcessor中实现了BeanDefinitionRegistryPostProcessor接口的接口，并执行该接口的方法，否则直接遍历执行BeanFactoryPostProcessor接口即可. 处理当前beanFactory中定义的beanFactoryPostProcessor接口: 这部分的处理和第一部分基本上类似，但需要考虑PriorityOrdered, Ordered接口的优先性，先处理实现了PriorityOrdered的接口，再处理实现了Ordered的接口，然后是普通的接口. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127public static void invokeBeanFactoryPostProcessors( ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123; //第一部分，处理参数beanFactoryPostProcessors中的接口，需考虑容器为BeanDefinitionRegistry时的情况 Set&lt;String&gt; processedBeans = new HashSet&lt;String&gt;(); if (beanFactory instanceof BeanDefinitionRegistry) &#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new LinkedList&lt;BeanFactoryPostProcessor&gt;(); List&lt;BeanDefinitionRegistryPostProcessor&gt; registryPostProcessors = new LinkedList&lt;BeanDefinitionRegistryPostProcessor&gt;(); for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123; if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123; BeanDefinitionRegistryPostProcessor registryPostProcessor = (BeanDefinitionRegistryPostProcessor) postProcessor; registryPostProcessor.postProcessBeanDefinitionRegistry(registry); registryPostProcessors.add(registryPostProcessor); &#125; else &#123; regularPostProcessors.add(postProcessor); &#125; &#125; //第二部分，与第一部分的实现思路大体一致，但需要考虑PriorityOrdered， Ordered接口 String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); // First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered. List&lt;BeanDefinitionRegistryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanDefinitionRegistryPostProcessor&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(beanFactory, priorityOrderedPostProcessors); registryPostProcessors.addAll(priorityOrderedPostProcessors); invokeBeanDefinitionRegistryPostProcessors(priorityOrderedPostProcessors, registry); // Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered. postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); List&lt;BeanDefinitionRegistryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanDefinitionRegistryPostProcessor&gt;(); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class)); processedBeans.add(ppName); &#125; &#125; sortPostProcessors(beanFactory, orderedPostProcessors); registryPostProcessors.addAll(orderedPostProcessors); invokeBeanDefinitionRegistryPostProcessors(orderedPostProcessors, registry); // Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear. boolean reiterate = true; while (reiterate) &#123; reiterate = false; postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false); for (String ppName : postProcessorNames) &#123; if (!processedBeans.contains(ppName)) &#123; BeanDefinitionRegistryPostProcessor pp = beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class); registryPostProcessors.add(pp); processedBeans.add(ppName); pp.postProcessBeanDefinitionRegistry(registry); reiterate = true; &#125; &#125; &#125; // Now, invoke the postProcessBeanFactory callback of all processors handled so far. invokeBeanFactoryPostProcessors(registryPostProcessors, beanFactory); invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory); &#125; else &#123; // Invoke factory processors registered with the context instance. invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let the bean factory post-processors apply to them! String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false); // Separate between BeanFactoryPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;(); for (String ppName : postProcessorNames) &#123; if (processedBeans.contains(ppName)) &#123; // skip - already processed in first phase above &#125; else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class)); &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered. sortPostProcessors(beanFactory, priorityOrderedPostProcessors); invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory); // Next, invoke the BeanFactoryPostProcessors that implement Ordered. List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); for (String postProcessorName : orderedPostProcessorNames) &#123; orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; sortPostProcessors(beanFactory, orderedPostProcessors); invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory); // Finally, invoke all other BeanFactoryPostProcessors. List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanFactoryPostProcessor&gt;(); for (String postProcessorName : nonOrderedPostProcessorNames) &#123; nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class)); &#125; invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory); // Clear cached merged bean definitions since the post-processors might have // modified the original metadata, e.g. replacing placeholders in values... beanFactory.clearMetadataCache(); &#125; 1.1.5 registerBeanPostProcessors顾名思义，registerBeanPostProcessors方法就是往容器中注册BeanPostProcess接口，作为Spring容器的第二个扩展点，BeanPostProcessor接口允许应用程序对bean对象的实例化过程进行定制，例如，可以根据配置信息在实例化完成后产生相应的代理对象等等，事实上，Spring框架中提供的AOP机制就是通过BeanPostProcessor来实现的. 具体来看看这个方法实现的过程. 总体来讲和之前的实现差异不大，仍然是按PriorityOrdered，Ordered以及普通接口分成三类，然后分别往容器中按一定的顺序注册BeanPostProcessor接口. 到此为止，Spring容器已经完成了bean定义的加载，BeanFactoryPostProcessor接口的处理，并往容器中注册了BeanPostProcessor接口. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public static void registerBeanPostProcessors( ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123; String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false); // Register BeanPostProcessorChecker that logs an info message when // a bean is created during BeanPostProcessor instantiation, i.e. when // a bean is not eligible for getting processed by all BeanPostProcessors. int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length; beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount)); // Separate between BeanPostProcessors that implement PriorityOrdered, // Ordered, and the rest. List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;String&gt;(); List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;String&gt;(); for (String ppName : postProcessorNames) &#123; if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); priorityOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123; orderedPostProcessorNames.add(ppName); &#125; else &#123; nonOrderedPostProcessorNames.add(ppName); &#125; &#125; // First, register the BeanPostProcessors that implement PriorityOrdered. sortPostProcessors(beanFactory, priorityOrderedPostProcessors); registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors); // Next, register the BeanPostProcessors that implement Ordered. List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : orderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); orderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; sortPostProcessors(beanFactory, orderedPostProcessors); registerBeanPostProcessors(beanFactory, orderedPostProcessors); // Now, register all regular BeanPostProcessors. List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;BeanPostProcessor&gt;(); for (String ppName : nonOrderedPostProcessorNames) &#123; BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class); nonOrderedPostProcessors.add(pp); if (pp instanceof MergedBeanDefinitionPostProcessor) &#123; internalPostProcessors.add(pp); &#125; &#125; registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors); // Finally, re-register all internal BeanPostProcessors. sortPostProcessors(beanFactory, internalPostProcessors); registerBeanPostProcessors(beanFactory, internalPostProcessors); beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext)); &#125; 1.1.6 initMessageSourceSpring框架关于国际化的支持主要是通过MessageSource接口来完成的，它允许应用程序根据不同的地区显示不同的消息，在initMessageSource方法中，首先查看容器中是否定义了MessageSource接口的实现，如果没有定义这个接口的实现，则使用默认的MessageSource实现DelegatingMessageSource. 123456789101112131415161718192021protected void initMessageSource() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) &#123; this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class); // Make MessageSource aware of parent MessageSource. if (this.parent != null &amp;&amp; this.messageSource instanceof HierarchicalMessageSource) &#123; HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource; if (hms.getParentMessageSource() == null) &#123; // Only set parent context as parent MessageSource if no parent MessageSource // registered already. hms.setParentMessageSource(getInternalParentMessageSource()); &#125; &#125; &#125; else &#123; //默认情况，使用空的MessageSource实现 DelegatingMessageSource dms = new DelegatingMessageSource(); dms.setParentMessageSource(getInternalParentMessageSource()); this.messageSource = dms; beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource); &#125;&#125; 1.1.7 initApplicationEventMulticaster这个方法主要是负责容器的ApplicationEventMulticaster对象的初始化工作，实现的逻辑与上面基本一致 ，首先判断容器中是否已经定义了这个对象，如果没有则使用默认的实现. 在Spring框架中，ApplicationEventMulticater接口主要应用程序事件的广播，可以往容器中注册ApplicationEvent接口及ApplicationListener接口，两者分别代表了事件及事件监听器，当发生相应的事件后，就可以通过ApplicationEventMulticaster接口来通知相应的监听器进行处理. 1234567891011protected void initApplicationEventMulticaster() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123; this.applicationEventMulticaster = beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class); &#125; else &#123; this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory); beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster); &#125;&#125; 1.1.8 onRefreshonRefresh()方法作为容器初始化过程中的”钩子”方法，允许子类在容器完成初始化后进行一些定制化的操作，如注册一些特定的对象等. 默认情况下为空实现. 1.1.9 registerListeners在上面已经提到过，Spring容器支持事件的触发与广播，主要是通过ApplicationEventMulticater来实现的，但前提是容器中必须注册相应的事件及监听器，而这一步就是在这里完成. 这里首先获取容器中注册的ApplicationListener接口对象，在ApplicationEventMulticaster中完成注册，在注册完成后，检查初始化过程中是否已经有事件产生，如果有，则直接触发这些事件. 12345678910111213141516171819202122protected void registerListeners() &#123; // Register statically specified listeners first. for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123; getApplicationEventMulticaster().addApplicationListener(listener); &#125; // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) &#123; getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); &#125; // Publish early application events now that we finally have a multicaster... Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (earlyEventsToProcess != null) &#123; for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123; getApplicationEventMulticaster().multicastEvent(earlyEvent); &#125; &#125;&#125; 1.1.10 finishBeanFactoryInitializationfinishBeanFactoryInitialization方法中主要完成容器初始化完成后的收尾工作，包括配置ConversionService, 注册LoadTimeWeaverAware接口，冻结配置以及初始化对象实例等操作. ConversionService是Spring容器中进行类型转换的入口, 所有涉及到类型转换的场景， 如配置文件中的值到属性类型间的转换，都是从ConversionService完成的. 除此之外，这个方法中还对当前的配置进行了冻结，以示可以进行缓存操作. 1234567891011121314151617181920212223242526272829303132333435protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // Initialize conversion service for this context. if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // Register a default embedded value resolver if no bean post-processor // (such as a PropertyPlaceholderConfigurer bean) registered any before: // at this point, primarily for resolution in annotation attribute values. if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(new StringValueResolver() &#123; @Override public String resolveStringValue(String strVal) &#123; return getEnvironment().resolvePlaceholders(strVal); &#125; &#125;); &#125; // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early. String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // Stop using the temporary ClassLoader for type matching. beanFactory.setTempClassLoader(null); // Allow for caching all bean definition metadata, not expecting further changes. beanFactory.freezeConfiguration(); // Instantiate all remaining (non-lazy-init) singletons. beanFactory.preInstantiateSingletons();&#125; 在finishBeanFactoryInitialization方法的最后一步，调用了preInstaniateSingletons()方法. Spring文档中告诉我们，对于作用域为singleton的对象，lazy-init属性默认为false, 意味着容器总是会“预先”初始化这些对象，而这步就是在preInstantiateSingletons()这个方法中完成的. 这又是一个抽象方法，它的实现由DefaultListableBeanFactory类提供. 可以看到，预先初始化的对象需要满足三个条件： 不是抽象类 scope为singleton lazyInit属性为false 在满足了以上三点后，容器就会尝试初始化这些singleton对象，首先判断这个类定义是否是FactoryBean，如果是的话，则再次判断它的eagerInit属性，只要在这个属性为true的情况下才开始实例化操作. 如果这个bean定义是普通的对象，则直接开始实例化操作. 对象的实例化操作都是通过getBean()方法来完成的，关于这个方法会在本文的第二部分进行详细的阐述，这里就不做叙述. 在完成对象的实例化操作后， 还会调用实现了SmartInitializingSingleton接口的对象的回调方法. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public void preInstantiateSingletons() throws BeansException &#123; // Iterate over a copy to allow for init methods which in turn register new bean definitions. // While this may not be part of the regular factory bootstrap, it does otherwise work fine. List&lt;String&gt; beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames); // Trigger initialization of all non-lazy singleton beans... for (String beanName : beanNames) &#123; RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; if (isFactoryBean(beanName)) &#123; final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName); boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() &#123; @Override public Boolean run() &#123; return ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit(); &#125; &#125;, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; getBean(beanName); &#125; &#125; else &#123; getBean(beanName); &#125; &#125; &#125; // Trigger post-initialization callback for all applicable beans... for (String beanName : beanNames) &#123; Object singletonInstance = getSingleton(beanName); if (singletonInstance instanceof SmartInitializingSingleton) &#123; final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance; if (System.getSecurityManager() != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; smartSingleton.afterSingletonsInstantiated(); return null; &#125; &#125;, getAccessControlContext()); &#125; else &#123; smartSingleton.afterSingletonsInstantiated(); &#125; &#125; &#125;&#125; 1.1.11 finishRefresh到这里，容器的初始化工作已经基本完成，这个方法主要是完成LifecycleProcessor接口的配置与调用，并发布ContextRefreshEvent事件. LifecycleProcessor接口主要是负责与生命周期相关的方法，与之前一些接口的配置过程类似，这里也是先在容器中查询是否有相应的接口定义，如果没有则使用默认的实现. 在配置完LifecycleProcessor接口后，就会调用其onRefresh()方法，并发布ContextRefreshEvent事件. 这里值得注意的是getBean()方法，关于这个方法的实现过程会在本文的第二部分中进行详细阐述, 这里只要知道它是从容器中获取相应的实例对象即可. 123456789101112131415161718192021222324252627protected void finishRefresh() &#123; // Initialize lifecycle processor for this context. initLifecycleProcessor(); // Propagate refresh to lifecycle processor first. getLifecycleProcessor().onRefresh(); // Publish the final event. publishEvent(new ContextRefreshedEvent(this)); // Participate in LiveBeansView MBean, if active. LiveBeansView.registerApplicationContext(this);&#125;protected void initLifecycleProcessor() &#123; ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (beanFactory.containsLocalBean(LIFECYCLE_PROCESSOR_BEAN_NAME)) &#123; this.lifecycleProcessor = beanFactory.getBean(LIFECYCLE_PROCESSOR_BEAN_NAME, LifecycleProcessor.class); &#125; else &#123; DefaultLifecycleProcessor defaultProcessor = new DefaultLifecycleProcessor(); defaultProcessor.setBeanFactory(beanFactory); this.lifecycleProcessor = defaultProcessor; beanFactory.registerSingleton(LIFECYCLE_PROCESSOR_BEAN_NAME, this.lifecycleProcessor); &#125;&#125; 到此为止，示例代码中构造ApplicationContext对象的源码就已经全部解读完毕了，总得来讲，在构造函数中调用了refresh()方法来加载配置文件中定义的BeanDefinition，并根据配置文件注册了BeanPostProcessor接口，以及一些配置接口，在加载完bean定义后，还对lazyInit为false的”单例”对象进行了实例化操作. 在这个构造函数返回后，应用程序定义的所有对象以及它们之间的依赖关系就已经在容器中配置好了. 对象间的依赖关系是在调用getBean()方法获取对象时由容器根据定义自动满足的，这部分内容见本文的第二部分. 1ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"applicationContext.xml\");","categories":[],"tags":[{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"},{"name":"ioc","slug":"ioc","permalink":"http://yoursite.com/tags/ioc/"},{"name":"DI","slug":"DI","permalink":"http://yoursite.com/tags/DI/"}]},{"title":"JVM的类加载机制","slug":"JVM/JVM的类加载机制","date":"2017-02-03T07:18:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/02/03/JVM/JVM的类加载机制/","link":"","permalink":"http://yoursite.com/2017/02/03/JVM/JVM的类加载机制/","excerpt":"","text":"JVM的类从被加载到虚拟机，到从内存中卸载，可以分为七个步骤，分别是加载， 验证， 准备， 解析， 初始化， 使用以及卸载. 如下图所示， 其中验证、准备和解析又被称统称为是“连接”阶段. 加载虚拟机在加载阶段将类定义加载到内存中，并在方法区中建立相应的运行时数据结构，同时在堆上建立相应的Class对象实例，作为访问方法区运行时数据的入口. 通过类的全限定名获取类定义的二进制字节流 根据获取到的二进制字节流在方法区中建立运行时的数据结构 在堆中建立相应的Class对象实例，作为访问方法区运行时数据结构的入口 这里值得一提的是， 在第1步中”根据类的全限定名获取类定义的二进制字节流”， 并不要求一定要从Class文件中加载，任何可以获取到合法的类定义字节流的途径都可以. 相对于类加载的其它阶段， 类加载的过程（准确地说，是类加载阶段的第1步）是开发者可控性最强的阶段， 开发人员可以根据需要选择从任何需要的地方获取相应的类定义数据. 类加载器在虚拟中， 类加载的第1步是通过“类加载器”来完成的，类加载器又可以分为不同的层次, 每个类加载器均有父加载器（启动加载器除外）， 在加载类对象的时候 ，类加载器采用了的是“双亲委派模型”. (这里). 具体来讲，当类加载器尝试加载某个类之前，它总是先将加载操作“委托”给父加载器执行，只有当父加载器无法加载该类对象时，它才自己尝试加载. 启动加载器(Bootstrap ClassLoader) 扩展加载器(Extend ClassLoader) 应用加载器(Application ClassLoader) 自定义加载器(Custom ClassLoader) 另外，在虚拟机中，任意类的唯一性由类加载器以及这个类本身共同决定. 换句话说，即使是完全相同的一个类，如果加载的时候使用不同的类加载器，那么对于虚拟机而言就是两个不同的类. 在JAVA虚拟机中，类加载器可以细分为四类: 验证在完成类加载后，紧接着虚拟机要完成的操作就是“验证”, 在这步中虚拟机要完成的对类定义对象的验证，以保证加载的类对象是符合格式规范，且不会做破坏虚拟机的事情. 在验证阶段，虚拟机要完成的动作又可进一步细分为： 文件格式的验证: 这步验证的主要目的是保证字节流能够在方法区中正确无误地建立运行时数据结构，主要验证的内容包括确认字节流是否符合文件规范的要求，以及文件版本号能否被当前的虚拟机所处理. 在完成这步验证后，类定义的字节流就会在方法区中建立相应的运行时数据结构，后续的验证都会基于方法区中的数据结构来进行. 元数据的验证： 这步验证主要是对类定义的各种元数据进行确认，保证不会出现不符合JAVA规范的元数据信息 字节码的验证： 这步验证主要是确保类定义的数据流和控制流没有问题，以确保在类的执行过程中，不会有危及虚拟机安全的动作 符号引用的验证： 这步验证主要是确保类定义的符号引用都能被正确地解析成直接引用 准备准备阶段是正式为类变量分配内存并设置初始值的阶段， 这些内存都将在方法区中分配.这句话中，有三个地方值得引起我们的注意： 为类变量分配内存： 在准备阶段，只会为类变量分配内存，不包括实例变量 为类变量设置初始值： 这里的“初始值”通常情况下是指数据类型的初始值，而不是开发人员设置的值. 内存将在方法区中分配： 类变量的内存都在被分配在方法区中，而不是堆上 这里有个例外，就是当类变量被final修饰时，在准备阶段会完成类变量的赋值操作. 123456789例1： public static int value = 3;在完成准备阶段后，value的值会被初始化成0，而不是3（这步是在初始化阶段完成的）例2： public static final int value = 3;则完成“准备”阶段后，value的值会被初始化成3 解析类文件的解析过程是将符号引用转化成直接引用的过程. TODO 初始化在进入初始化阶段后，虚拟机才真正开始执行程序中定义的代码. 在“准备”阶段，类变量完成了内存分配及初始值的设置，而在这里，类变量将进一步按照程序的设置，完成赋值操作. 或者可以这么说，在初始化阶段，虚拟机调用了类构造器()方法. 这里简单介绍下类构造器()方法的执行规则： ()方法是由编译器收集类中定义的所有类变量的赋值操作和静态语句块合并产生的，收集的顺序由语句在源文件中出现的顺序决定. 其中， 静态语句块中只能访问到定义在静态语句块之前的变量，对于定义在静态语句块之后的变量，在语句块中可以赋值，但不能访问 ()方法与实例构造器不同，它不需要显式地调用父类构造器，虚拟机会保证在调用子类()方法之前，已经完成父类()方法的调用. ()方法对于类或接口来讲不是必需的，如果类中没有静态语句块，也没有对类变量进行赋值操作，则可以不用生成()方法 虚拟机会保证类的()方法在多线程环境中被正确地加锁和同步. 参考文献 类加载机制 JVM类加载机制 示例代码 类加载的“初始化”1 类加载的“初始化”2","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://yoursite.com/tags/JVM/"},{"name":"类加载","slug":"类加载","permalink":"http://yoursite.com/tags/类加载/"}]},{"title":"注解","slug":"JVM/注解","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/JVM/注解/","link":"","permalink":"http://yoursite.com/2017/01/25/JVM/注解/","excerpt":"","text":"注解元注解元注解是注解的注解，JAVA中提供了四种元注解 @Target: 它是用来标识注解的使用范围，可选的范围包括包、类型、方法、构造方法、成员变量、局部变量以及方法变量等 @Retention: 它是用来标识注解的生命周期，可选的生命周期由RetentionPolicy定义，可选的值包括源代码、CLASS文件以及运行时 @Docuemnted: 它是一个标记注解，用来标识该注解会出现在javadoc中； 如果没有使用这个注解，那么相应的注解就不会出现在javadoc @Inherited: 它也是个标记注解， 用于标识注解是否会被子类继承. 如果某个类被带有@Inherited注解的注解标记时，则该注解会被子类继承 值得注意的是，@Inherited只会被子类继承，但不会从接口、重载方法等地方继承注解 自定义注解使用@interface定义注解时，自动继承了annotation接口 定义注解的语法： public @interface 注解名称{} 关于注解的定义有以下几点需要关注： 注解的每个方法声明一个配置参数， 方法的名称就是配置参数的名称， 方法的返回值就是配置参数的类型 可以通过default来声明参数的默认值 注解支持的参数类型为： 基本数据类型、Class、Enum、Annotation 注解元素必须有值，要么在定义注解时设置默认值，要么在使用注解时设置相应值，不能为空或者NULL. 因此在定义注解时，一般会给每个配置参数设置相应的默认值, 通常情况下，负数或者空字符串代表这个参数不存在 注解处理器一般是在工具框架中、或者反射的方式进行处理 注解的作用 编译检查： 如@Override 反射 生成帮助文档 相关的类图 参考文献 http://www.cnblogs.com/peida/archive/2013/04/24/3036689.html http://www.cnblogs.com/skywang12345/p/3344137.html","categories":[],"tags":[]},{"title":"zookeeper学习摘要","slug":"zookeeper学习摘要","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/zookeeper学习摘要/","link":"","permalink":"http://yoursite.com/2017/01/25/zookeeper学习摘要/","excerpt":"","text":"Stat结构 zxid: zookeeper transaction id, 这个ID表示了全局的顺序, zxid的值越小，那么该操作发生的时间越早. czxid: 导致这个节点创建的操作zxid编号 ctime: 创建这个节点的时间 mzxid： 最近一次编辑这个节点数据的zxid编号（注意，这里只会在编辑节点数据时才会变化，如果编辑的是子节点，并不会引起这个数据发生变化） mtime: 最近一次编辑这个节点的时间 dataVersion: 节点的数据版本，每个修改节点数据版本号都会增加1 cversion: 子节点的数据版本， 增加或删除子节点都会导致这个版本增加1 aversion: 节点的权限版本，每个修改节点的权限信息都会导致这个版本增加1 ephemeralOwner: 当这个节点是个ephemeral节点时，这个值代表创建这个节点的session id；如果这个节点不是ephemeral节点，那么这个值为0 dataLength: 数据长度. numChildren: 子节点个数 ACL控制 ZK中的ACL格式为scheme:id:permissions， 内置的scheme包括以下几种，针对每一种scheme都有对应的id形式： world: 这种scheme只有一个id，就是anyone, 即world:anyone, 它代表所有人. auth: 这种scheme不需要id信息，只要是认证过的用户都有相应的权限 digest: 这种scheme对应的id为username:BASE64(SHA1(password)) ip: 这种scheme对应的id为ip信息，ip信息中可以指定ip段，例如：192.168.32.15/16表示只需要校验前16位的ip段信息 权限信息 读权限(r)：读取节点数据和子节点信息 写权限(w)： 设置节点数据的权限 删除权限(d)： 删除子节点的权限 增加权限(c)：增加子节点的权限 管理权限(a)： 更改权限的权限 参考文档 http://www.itnose.net/detail/6445740.html","categories":[],"tags":[]},{"title":"java集合学习之Map和Set的实现4","slug":"集合/java集合学习之Map和Set的实现4","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/集合/java集合学习之Map和Set的实现4/","link":"","permalink":"http://yoursite.com/2017/01/25/集合/java集合学习之Map和Set的实现4/","excerpt":"","text":"java集合学习之Map和Set的实现4Map接口并不继承自Collection接口，它是一系列key-value值的集合，它的类继承图如下， AbstractMap作为map接口的抽象实现，它实现了map接口中的通用方法，如size, get, putAll等方法. 这个类只定义了一个抽象接口，entrySet， 其它所有的方法都是通过这个方法返回的值来完成的，实现逻辑比较清晰. 从containValue和containsKey的实现中也可以证实， abstractMap的key和value值都是可以包含null的，并且这个实现不是线程安全的，继承自这个抽象类的包括HashMap、TreeMap， LinkedHashMap， 所以这些类都继承了相应的性质. HashMapHashMap的底层使用“链表数组”来存储节点数据, hashMap中定义了两个变量，loadFactor与size， 前者定义了哈希表中容量达到“多满”时，对哈希表进行“重新哈希”操作，后者记录了哈希表中的entry数量. 当往hashmap中插入新的entry(key, value)时，会执行以下的操作： 根据key值计算其哈希值，hash(key), 这里返回的就是key对象的hashCode值 在插入之前，首先判断用于存储节点的数组是否为空，如果为空的话则进行resize操作（后续会重点阐述这个方法） 然后根据hash(key)与n-1进行“与”操作，得到该entry所属的bin位置（即数组中的位置） 如果bin中的值为null, 那么新增的节点为该bin的第一个节点，直接创建新的节点，并将该节点放在该bin的首节点位置（即数组中的元素） 如果bin中的值不为null, 则依次遍历链表上的结点，如果该结点的hash(key)与key值都与要插入的(key, value)相等，那么就执行更新操作，否则为插入操作. 在上面的阐述中我们提到，HashMap的实现中有两个很重要的变量，一个是init capacity，初始的容器大小， 一个load factor， 负载系数. 两者乘积的结果决定了这个hashMap最多能容纳的entry数量，一旦超过这个数量，hashMap就会执行一次rehash，导致整个哈希表的容量扩展为原来的两倍. 默认的load factor为0.75. resize方法可以分为两个部分，第一部分是根据当前容器的状态（oldCap, oldThr, oldTable)来确定新的容器大小(newCap, newThr), 第二部分则是根据第一部分计算得来的值申请新的存储空间，并对现有的entry进行“重哈希”操作. 首先获取bin的数量大小(oldCap)，只要这个值不为0，且不超过最大数量(MAXIMUM_CAPACITY), 就直接将bin的数量翻倍. 如果这个值为0，同时oldThr的值不为0， 说明这是第一次初始化bin大小，直接将oldThr的值赋予newCap即可. 如果两者均为0， 则直接使用默认值(16和12). 在获取到新的容器大小后，就可以直接分配新的数组， 并对现有的节点进行”重哈希“操作. 这里是个比较精妙的做法，详解如下： 首先每个节点的bin的位置是通过hash(key)与容器大小n-1进行”与“操作后得到的，由于n的值为2的幂次方，任何一个数与n-1进行”与“操作，等同于用这个值做掩码. 新的容器大小是原来容器大小的两倍，从位运算的角度来看，就是将1的位置左移一位即可 结合前面两点，重新做哈希的时候，只需要判断所有节点hash(key)在新的容量大小所在的那个1的那个位置上的值，如果是0，则意味着这个节点保持原来的位置（即代码中loHead的逻辑）, 否则（即该位为1）该结点与新的容器大小n-1进行与操作得到的值一定会发生变化，而delta值刚好等于oldCap， 即代码中hiHead的逻辑 关于这个，再具体举个例子，假设原来的bin数组长度为8，即n_old = 8 = 1000(2), 那么此时的n_old - 1= 7 = 0111(2) 此时如果进行resize操作，那么n_new = 8 * 2 = 16 = 10000(2)， 此时的n_new - 1 = 15 = 01111(2) 假设原来有个结点的hash(key) = 2 = 10(2)， 同时还有个结点的hash(key) = 18 = 10010(2)的结点，它们在resize前在数组中第3个bin的位置 ，而在resize操作之后，hash(key)=2的结点，由于它的第5个byte的值为0，它的位置保持不变，还在第3个bin，而hash(key)=18的结点，它的第5个byte=1，因此它的位置从原来的第3个bin移到了第19个， 两者的位置差刚好等于原来的数组大小n_old = 16. 我们经常会说，HashMap是线程不安全的，另外，它的遍历顺序是不确定的，甚至它的遍历顺序随着遍历时间的不同返回的顺序都是不一样的，从源码上看，hashMap的实现中没有任何并发方面的考虑，而它的遍历顺序是顺序着bin数组从前往后遍历，而bin数组中的链表会随着新结点的加入有可能发生变化(resize操作引起的)，因此它的顺序是不可预知的. LinkedHashMapLinkedHashMap派生自HashMap，也就是说，LHM的底层还是和hashMap一样，是通过数组加链表的方式存储着元素，但是， 它与HashMap最大的不同在于，它的遍历是有序的，或者说是可预测的. LHM为了保证遍历时的顺序性，除了链表数组，它还同时维护了一个双向链表，这个双向链表的顺序是随着访问或者插入的顺序而变化的(根据accessOrder参数指定）, 而在遍历的时候，只要依次遍历这个双向链表即可 . LinkedHashMap利用了hashMap的大部分方法，但是在一些方法上进行了重写，以维护双向链表. 以插入新的结点为例， 在hashMap的putVal中，调用了newNode来获取，LHM重写了这个方法，在返回新建的结点之前，通过linkNodeLast将新建的结点插入到双向链表的最后面, 这意味着，如果遍历的时候沿着这个双链表进行，就可以满足按插入顺序进行遍历的需求，事实上也是这么实现的. 删除结点的时候有一点不同，在hashmap的删除结点方法实现的最后 ，调用了afterNodeRemoval方法，这是hashMap定义的hook函数，也是在模板模式中常用的方式，这些hook方法允许子类在一些点上可以自定义类的行为，而LHM就是通过重写这个方法来实现结点从容器中删除后，同时也从双向链表中删除. HashTable前面提到了，基于AbstractMap实现的子类都是线程不安全的，在并发条件下使用存在问题，而hashTable实现解决了这一问题，它的实现机制很简单，甚至可以说是粗暴，就是在HashMap实现的基础上，对每个方法加关键字synchronized，以实现线程安全的目的, 可想而知，这样线程安全的实现性能是不会太好的. 另外，它与hashMap还有一点不同的是，它的key和value值都是不允许为Null的. TreeMap从类的继承图上可以看出， TreeMap实现了SortedMap和NavigableMap接口，前者规定了集合中的元素是按照key的”自然”顺序或者指定的comparator接口进行排序的，而NavigableMap接口定义了一系列遍历集合中元素的方法， 它的底层实现是通过红黑树结构完成的. （红黑树算法原理还没搞明白，所以 TreeMap暂时不分析源码了…）,另外，值得一提的是，这个类的实现也是线程不安全的。 Set在了解了Map及其子类的实现之后，再来理解Set及其子类的实现就变得非常容易. 从图中可以看出，set的继承图与map的继承图完全一样，每个map的实现都有一个对应的set实现（hashMap对应hashSet， TreeMap对应treeSet等等）. 事实上，set的底层实现就是通过其对应的map类型来实现的，从前面的描述可以知道，map的key值是不允许重复的， 但value值是可以重复的（重复的key值会覆盖），而set中的元素也是不能重复的，因此，只要把map的keySet当作对应的set实现就可以了. 因此，HashSet的底层实现是通过HashMap来实现的，LinkedHashSet的底层实现是通过LinkedHashMap来实现的， TreeSet的底层实现是通过TreeMap来实现的 关于set的实现就基本讲完了. 参考文献 http://liujiacai.net/blog/2015/09/03/java-hashmap/ 可视化 resize方法的讲解","categories":[],"tags":[]},{"title":"反射-Member接口","slug":"JVM/反射/反射-Member接口","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/JVM/反射/反射-Member接口/","link":"","permalink":"http://yoursite.com/2017/01/25/JVM/反射/反射-Member接口/","excerpt":"","text":"反射-Member接口Member接口定义了单个成员（可以是属性、构造函数或者方法）的信息，它提供了以下几个方法： getDeclaringClass: 返回声明这个成员的类信息 getModifier: 返回修饰符信息 getName: 返回成员的名称信息 isSynthetic：标识当前成员是否为人造的，即是否是由编译器引入的 在反射框架中，Field, Method以及Constructor都实现了这个接口","categories":[],"tags":[]},{"title":"设计模式总述","slug":"设计模式/设计模式总述","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/设计模式/设计模式总述/","link":"","permalink":"http://yoursite.com/2017/01/25/设计模式/设计模式总述/","excerpt":"","text":"总述参考文献 https://sourcemaking.com/design_patterns/facade http://design-patterns.readthedocs.io/zh_CN/latest/structural_patterns/adapter.html","categories":[],"tags":[]},{"title":"备忘","slug":"IO/netty/备忘","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/IO/netty/备忘/","link":"","permalink":"http://yoursite.com/2017/01/25/IO/netty/备忘/","excerpt":"","text":"备忘 netty是如何实现对于某个channel的IO事件，交由同一个线程去处理?channel持有一个eventloop，后续所有的操作都会交由这个eventllop操作，具体是在每个操作前，判断一下当前的执行线程是不是eventloop，如果是，直接执行，如果不是，则将要执行的事情放到eventloop的执行任务队列中 什么时候创建的多个NioServerSocketChannel?（与问题5类似）netty中, nioServerSocketChannel只是在bind的时候被创建一次，后续也不会创建，但可以通过register方法创建相应的channel. NIO的标准操作哪里去了? NioEventLoop中实现了轮询的逻辑 NioServerSocketChannel构造函数中实现了channel的配置信息 Register方法实现了注册 selector是在哪里开始监听事件的，它的interseteOps是在哪里被设置的（如何监听连接，与问题6类似）?bind操作中触发了fireChannelActive事件，这个事件会调用channel的read方法，然后会调用unsafe的doBeginRead方法，在这个方法中，channel的兴趣事件被真正设置, 而channel的interestOps在它的构造函数中就已经被设置好了 SocketChannel是怎么被创建的（它是有多个吗？还是只有一个？）socketChannel是在客户端发起连接操作时，由NioEventLoop的轮询操作捕获到相应的IO事件，它调用了unsafe的read方法，在该方法中，NioSocketChannel被创建，且通过NioServerSocketChannel的read事件传播, 在NioSSC的pipeline初始化的时候，设置了ServerBootstrapAcceptor的处理器，它会处理channelRead事件，并在这个事件的处理中，初始化NioSC的相应属性, 然后将NioSC注册到childGroup中. 对于每一个新的连接，服务端都会创建一个新的请求. server端是如何处理连接的见问题5 参考文献 NioEventLoop的运行情况 服务启动的代码 系列的开始文章","categories":[],"tags":[]},{"title":"reactor模型","slug":"IO/netty/reactor模型","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/IO/netty/reactor模型/","link":"","permalink":"http://yoursite.com/2017/01/25/IO/netty/reactor模型/","excerpt":"","text":"Reactor模型Reactor模型的中心思想是将所有要处理的IO事件及其处理器注册到一个中心的IO多路复用器上，并将主线程阻塞在多路复用器上；当有相应的IO事件到达时，多路复用器将IO事件分发给相应的处理器进行处理.Reactor模型的模型图如下所示， 其中包括几个核心组件： Initiation Dispatcher（分发器）： 这是Reactor模型的中心组件，所有的IO事件及其处理器都要在这里进行注册，同时它还拥有一个多路复用器（Synchronous event demultiplexer），在进程启动时，它会阻塞多路复用器以监听注册的IO事件，当有IO事件到达时，多路复用器会通知分发器，而分发器会调用之前注册的事件处理器对相应的IO事件进行处理. Synchronous event demultiplexer(多路复用器）: 多路复用器负责监听相应的IO事件，当IO事件到达时，由多路复用器负责通知到分发器. 事件处理器： 通常情况下，事件处理器会将它要处理的事件及其自己注册到分发器中，当分发器得到多路复用器的事件通知后，就会回调这些事件处理器进行处理， IO事件中往往有发生当前IO事件的句柄信息（handle） 事件： Reactor中的事件基本上可以认为是IO事件， 这些IO事件都会发生在一定的句柄中(handle)， 它是用来标识网络设备的标识. 拿JAVA中的NIO编程举例（以下的例子）， ServerSocketChannel就是图中的handle, 它可能发生的事件包括Accept, Read, Write等等， 而Selector就是NIO中的多路复用器，整个程序的实现就是分发器. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public static void main(String[] args) throws IOException &#123; //handle ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(HOST, PORT)); serverSocketChannel.configureBlocking(false); //demultiplexer Selector selector = Selector.open(); int insteresSet = SelectionKey.OP_ACCEPT; //register serverSocketChannel.register(selector, insteresSet); //event loop while (true) &#123; //阻塞等待事件 selector.select(); Set&lt;SelectionKey&gt; selectionKeyset = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iter = selectionKeyset.iterator(); while (iter.hasNext()) &#123; SelectionKey selectionKey = iter.next(); if (selectionKey.isAcceptable()) &#123; //accept event handler acceptProcessor(selectionKey); &#125; else if (selectionKey.isReadable()) &#123; //read event handler readProcessor(selectionKey); &#125; else &#123; System.out.println(\"Unknown op.\"); &#125; iter.remove(); &#125; &#125; &#125; //read事件处理器 private static void readProcessor(SelectionKey selectionKey) throws IOException &#123; SocketChannel sc = (SocketChannel) selectionKey.channel(); ByteBuffer byteBuffer = ByteBuffer.allocate(64); sc.read(byteBuffer); byteBuffer.flip(); String content = Charset.forName(\"utf-8\").newDecoder().decode(byteBuffer).toString(); String response = \"你好, 客户端. 我已经收到你的消息, 内容为\\\"\" + content + \"\\\"\"; sc.write(ByteBuffer.wrap(response.getBytes())); sc.close(); &#125; //accept事件处理器 private static void acceptProcessor(SelectionKey selectionKey) throws IOException &#123; ServerSocketChannel ssc = (ServerSocketChannel) selectionKey.channel(); SocketChannel sc = ssc.accept(); sc.configureBlocking(false); sc.register(selectionKey.selector(), SelectionKey.OP_READ); &#125; Reactor的实现在java nio中，提供了Reactor实现需要的组件， Selector实现了多路复用器的角色， SelectionKey代表了通道到多路复用器间的注册关系（在Reactor模型中， 事件及其处理器是注册到分发器中， 这里有点小小的区别，但不影响实现 ），同时也代表了相应的IO事件； 对比下来，如果想用JAVA NIO实现Reactor模型，还需要提供分发器（Dispatcher）， 事件处理器， 并在通道注册到多路复用器时绑定相应的事件处理器（这个可以在调用注册方法时提供相应的attachment来实现）, 因此， 实现的关键点就是提供分发器和事件处理器. 根据实现方式的不同，又可以进一步细分为： 1. 单线程版本参见代码Reactor单线程（版本号： ea3714f）， 查看这个版本的代码可以看出，分发器自始至终只启动了一个线程，这个线程负责监听IO事件，当IO事件到达时，它依次调用相应的事件处理器进行处理， 待所有IO事件被处理完后，分发器将开启下一轮监听. 这样的实现代码逻辑简单，思路清晰，不需要处理多线程时存在的竞争条件和锁的问题，但它有个致命的缺点，当客户端数量增加时，可能会有大量的IO事件产生，这些事件的处理过程都是串行进行的，必然会导致分发器的处理效率下降，无法满足业务量扩展的需要. 2. 多线程版本参见代码Reactor线程池版本（版本号：4019213), 这个版本的代码要注意的是事件处理器的处理逻辑被放到了线程池中进行，这也就意味着，程序必须要考虑并发的情况（比如，同一个读事件被多次分发， 读事件处理的过程中注册的事件类型被改变等等问题）. 在代码中每个处理器都引入了当前的处理模式（读或者写），以此来避免处理过程中事件类型被改变的问题； 同时引入了“正在处理中”的状态，防止同一次读事件被多次分发多次处理. 但值得一提的是，这个版本只是将事件的处理放到线程池中，而对于事件的分发(比如连接事件)还是保持单线程，在客户端连接数增加时，会出现性能瓶颈 3. 扩展的多线程版本略 参考文献 Reactor的论文 http://blog.csdn.net/u013074465/article/details/46276967 http://jeewanthad.blogspot.jp/2013/02/reactor-pattern-explained-part-1.html RI","categories":[],"tags":[]},{"title":"Netty源码学习系列---服务端的启动","slug":"IO/netty/Netty源码学习系列---服务端的启动","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/IO/netty/Netty源码学习系列---服务端的启动/","link":"","permalink":"http://yoursite.com/2017/01/25/IO/netty/Netty源码学习系列---服务端的启动/","excerpt":"","text":"Netty源码学习系列—服务端的启动netty作为一套NIO框架，它封装了JAVA中的原生的NIO操作逻辑. 在学习netty源码的时候，我们就遵循这样的思路，先用JAVA原生的NIO API实现服务端程序，然后对照这些步骤，一步步地去netty中寻找相应的实现，看看作为框架，它是怎么封装基本的操作，并实现良好的扩展性. 原生JAVA NIO API实现服务端代码如下所示，从代码中可以将整个服务端的启动过程分为以下几个步骤： 创建ServerSocketChannel, 初始化成非阻塞模式，并将它绑定到指定的地址 初始化selector（多路复用器） 将serverSocketChannel注册到selector， 并监听accept事件 开启轮询操作，将对IO事件进行处理，在IO事件的处理中，还会变化ssc的监听事件 Netty是怎么做的在阅读netty源码之前，比照之前的原生java代码实现，我们要试图回答这样的一个问题，netty是分别在哪里实现这些“标准”操作的？ netty实现的服务端代码如下，表面上看来，和上面那段代码看起来完全不一样，但作为java nio框架，底层的操作一定离不开那些原生的API，现在看到的不过是被高度封装后的代码而已， OK，那就顺着这段代码开始阅读netty源码. ServerSocketChannel的初始化源码的第一行初始了ServerBootStrap对象，它继承自AbstractBootStrap对象，从名字上可以看出，这个对象的作用就是引导服务端的启动程序，通过这个对象可以配置服务端启动过程中需要用到的参数. 从上面的“标准”代码中可以看到，对于服务端来讲，需要配置的参数包括绑定的地址和服务端channel，但在netty的配置中除了这两项还多了其它的一些配置： bossEventGroup和workerEventLoopGroup: netty框架在实现的过程中，使用了Reactor模型，这两个参数就是在reactor模型中定义的，关于Reactor模型的详细内容，可以参考这里. 简单来讲，reactor模型的实现中，可以定义两组线程池，一组用来处理来自客户端的连接请求，而另一组用来处理已连接的客户端产生的IO事件， 从而提高处理连接和IO事件的效率. childHandler: 这个参数配置是客户端连接完成后，后续的IO事件的处理器， 事件处理器的概念也是来自reactor模型， 在netty中，事件处理器被组织成channelPipeline的形式，当通道中有IO事件发生时，这些事件会顺着pipeline依次通过每个事件处理器，事件处理器会根据需要选择对IO事件进行处理或发往下一个处理器，关于pipeline和处理器的更多内容，会在后续的文章中进行阐述。 初始化完serverBootStrap后，就会调用bind方法执行绑定操作. bind方法中会调用doBind方法， 在doBind方法中，netty会根据之前配置的引导参数，完成SSC的初始化和绑定. doBind方法的实现可以简单的分成两个步骤： initAndRegister和doBind0, 前者完成初始化和注册（后续会讲到），后者完成真正的绑定操作. 1. 初始化SSC的初始化是在initAndRegister方法中完成的， 可以看到，首先调用了channelFactory这个工厂类获取一个新的channel对象， 还记得在serverBootStrap对象中配置的channel参数吗？这里工厂类就是根据配置的这个channel参数通过反射机制生成新的对象. 反射机制中调用ServerSocketChannel的无参数构造函数，并通过一系列的父类构造函数完成了包括pipeline、unsafe、channel的非阻塞模式以及监听事件的初始化操作. 在完成channel对象的构造之后， 会调用init方法继续完成对channel对象的初始化操作. 这里初始化的内容也是根据serverBootStrap中的配置参数进行的， 这里值得注意的是第181行，在这里往pipeline中增加了一个ChannelInitializer处理器，这个处理器在通道注册(channelRegister事件)的时候，会往pipeline中添加ServerBootstrapAcceptor处理器，而这个sba处理器会对新进来的连接进行处理, 后续会再次对这个地方进行说明. 到这里为止，netty就完成了SSC的初始化操作. 2. 注册操作在完成SSC的初始化操作后，netty会马上将这个SSC通道注册到eventLoop中， 也就是在这个注册操作中，完成了IO事件的轮询及SSC到Selector的注册. register方法会最终调用AbstractNioChannel对象的doRegister方法，如下所示，在doRegister方法中调用了java nio原生的register方法，将创建的SSC注册到相应的selector（多路复用器）中. 这里值得一提的是，在register的时候，设置的interestOps为0， 这意味着当selector进行轮询的时候，并不会监听SSC的任何IO事件，那么netty又是怎么实现监听客户端的连接的呢（这种情况下，要注册的InterestOps为OP_ACCEPT），这个问题会在后面提到. 3. 绑定操作回到ServerBootStrap的doBind操作， 在完成了InitAndRegister操作后，serverBootStrap会继续调用doBind0操作， 这个操作会沿着pipeline传播到unsafe对象，并由unsafe调用java原生的bind方法执行绑定操作. SSC监听客户端的连接在前面的描述中我们提到，在SSC注册到多路复用器的时候，设置的interesOps为0，那么它是怎么实现监听连接事件的呢？ 回到之前的注册方法， 将SSC注册到多路复用器之后，netty会通过pipeline触发channelRegister的事件，这个事件会沿着pipeline往下传播，还记得SSC在初始化的时候，往pipeline里设置的那个ChannelInitializer处理器吗？这个处理器会处理channelRegister事件，并往pipeline中添加一个ServerBootstrapAcceptor的处理器，这个处理器会监听channelRead事件，而客户端的连接请求就是在这个处理器中被处理的. 可以看到，在serverBootstrapAcceptor的处理中，在初始化新建的客户端连接之后，将它注册到了workerEventLoopGroup之中. 那么，现在的问题就变成了，这个channelRead事件是在哪里被触发，又是怎么被传递给这个sba的呢？回头看“标准”实现代码，服务端启动后，是通过selector不断轮询的方式，来及时地处理客户端连接以及其它的IO事件. 那么在netty实现的代码中，肯定也有哪些地方完成了这些操作，执行那些操作的地方也必然会触发这个channelRead事件，并传递给sba. 再回头来看看绑定部分的代码. 在SSC发起bind操作之后，它会将绑定操作委托给它的pipeline, 后者又进一步委托给channelHandlerContext(关于channel, channelPipeline, channelHandler, ChannelHandlerContext之间的关系，可以参考这里.）查看channelHandlerContext的绑定操作，我们会发现以下这样的代码，这段代码在netty的源码中经常可以看到，简单来说，它的意思是判断一下当前操作的线程是不是当前channel绑定的那个eventLoop线程，如果是就直接执行相应操作，否则，将要执行的操作包装成一个task扔给eventLoop线程中的任务队列，在它方便的时候执行. 这样的机制保证了netty中任何一个channel的所有事件，都是由同一个eventLoop线程执行的, 即使是在同时有多个channel的情况下，也可以保证同一个channel的所有事件是按顺序执行的，而不用考虑多线程情况下的竞争条件和锁等问题（这个实现后续会在其它文章中进一步说明，这里点到为止） 在了解了以上的执行方式之后，我们就会发现channelHandlerContext的bind操作是在ssc的eventLoop中被调用的，因此它要执行的任务也是被包装成了task对象放到eventLoop的消息队列中等待执行. 继续查看eventLoop的代码，终于看到了熟悉的for循环轮询操作，这段代码的实现逻辑把任务分成两种类型，一种是IO事件（select操作），还有一种是消息队列中的任务. 两者执行的时候由ioRatio分配. 继续追踪代码，可以发现在processSelectedKeysOptimized方法中调用了处理selectionKey的方法，后者在处理accept事件时，会调用unsafe的read方法，这个方法最终会调用doReadMessage方法，doReadMessage中我们再次看到了熟悉的“标准”代码， SSC先是执行了accept操作，然后为每个新建立的客户端连接创建NioSocketChannel对象，并把这些对象作为pipeline的channelRead事件发布，这些事件会被ServerBootstrapAcceptor处理，完成客户端的连接. 现在还剩下最后一个问题，SSC初始化时，注册到selector中的interesOps为0， 那它是什么时候修改了这个interesOps的呢？（要不然即使进入了processSelectedKey方法，也是处理不了accept事件的啊）. 再回头来看看SSC的注册过程吧，在SSC完成第一次注册后，SSC会触发channelActive事件，这个事件会最终触发channel的doBeginRead操作，在这个方法中，会根据SSC在生成时设置好的interesOps来修改注册参数. 到此为止，我们已经从netty源码中找到了所有服务端启动的关键步骤. 总结一下： ServerBootStrap中包含了整个服务端启动过程中需要的所有配置参数 SSC构造函数中完成了SSC初始化， 并设置了相应的pipeline， pipeline中预置了客户端连接事件的处理器(ServerBootstrapAcceptor)，在后续的initAndRegister方法中完成了包括注册到selector, 关联eventLoop, 启动监听线程，设置interesOps等操作 在NioEventLoop的轮询中，会将新建立的客户端连接作为channelRead事件传播，并最终由ServerBootstrapAcceptor处理 参考文献 服务启动的代码","categories":[],"tags":[]},{"title":"ClassLoader的双亲委派模型","slug":"JVM/ClassLoader的双亲委派模型","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/JVM/ClassLoader的双亲委派模型/","link":"","permalink":"http://yoursite.com/2017/01/25/JVM/ClassLoader的双亲委派模型/","excerpt":"","text":"ClassLoader的双亲委派模型ClassLoader的层次在java中，ClassLoader的层次可细分为： BootStrap ClassLoader： 负责加载JDK中的核心类库 Extension ClassLoader： 负责加载/lib/ext/下的类库，负责JAVA扩展库 App ClassLoader： 负责加载应用程序classpath下的所有Jar包和class文件 自定义classLoader： 用户自定义的classLoader， 在自定义classLoader的时候，强烈建议重载findClass，而不是loadClass， 因为默认的loadClass方法实现了委派模型，通过重写findClass方法，可以让自定义的classLoader保持这种模型； 但由于loadClass方法并不是final的，因此，还是可以直接重写这个方法来破坏委派模型，但这不是一种好的实践方式. 双亲委派模型在加载类时，会先试图让父类加载器执行这个任务， 只有当父类加载器找不到该类时，才会由自己开始尝试加载这个类. ClassLoader的loadClass的过程 ， 其源码与时序图如下： 首先调用findLoadedClass来检查当前类是否已经加载，如果加载就直接返回 如果没有加载，则通过父classLoader来尝试加载，这里体现了委派模型（delegation model） 如果前面两步都没有加载到类信息，则此时classLoader调用findClass尝试加载findClass一般是先加载类数据(loadClassData),然后再调用defineClass方法来定义类，defineClass被final修饰 如果前三步都没有加载成功，则抛出ClassNotFoundException的异常信息. 类的加载在JAVA语言中，类由它的全限定名来唯一确定，当类加载到JVM中时，事实上，类是由加载它的类加载器以及它的全限定名共同确定的， 也就是说: 即使是同一个类文件，如果是由不同的类加载器加载，那么对于JVM来讲，就是不同的类对象 不同类加载器加载得到的类对象永远都是不同的，即使它们是由同一份类文件加载获得 加载某个类时，与它关联的所有类也会由当前类的类加载器加载得到. 比如，在JAVA中所有的类都继承自Object对象，那么当加载类时，会自动发起加载Object对象的操作（但是由于委派模型，Object类通常是由启动加载器加载得到的） 类对象的状态 未加载： 未加载的类对象仅仅是class文件 加载：加载的类对象是指已经被加载到JVM中，但还没被实例化，或者调用子类信息，或者运行相应的方法 激活：激活状态的类对象是指被加载到JVM中，且被实例化，或调用子类信息，或运行了相应的方法 数组是由JVM加载的，因此如果对数组获取getClassLoader，获取到的和它的元素类型的classLoader是一样的，如果数组元素为原生类型，则返回null 加载资源class的getResourceAsStream方法将加载资源的操作委托给它的classLoader来执行，但是在委托之前，它会将传入的资源名称进行解析，解析规则如下： 如果资源的名称是以“/”开始， 那么对应的资源名称就是去掉“/“后的那部分名称 如果资源的名称不是以“/“开始，那么对应的资源名称就是将当前的包名加资源名(将包名中的”.”替换为”/“） 123例如： getResourceAsStream(&quot;/A/B/C/D&quot;) ------&gt; A/B/C/D通过类com.cmcc.syw.LoaderTest.java调用getResourceAsStream(&quot;A/B/C/D&quot;) -------&gt; com.cmcc.syw.A.B.C.D 参考文献 http://blog.csdn.net/xyang81/article/details/7292380 http://docs.oracle.com/javase/7/docs/technotes/tools/findingclasses.html http://www.programgo.com/article/64522195716/","categories":[],"tags":[]},{"title":"Bytebuf学习","slug":"IO/netty/Bytebuf学习","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/IO/netty/Bytebuf学习/","link":"","permalink":"http://yoursite.com/2017/01/25/IO/netty/Bytebuf学习/","excerpt":"","text":"Bytebuf学习ByteBuf同时支持随机和序列化的方式读取byte数组， 它是nio buffer以及byte数组的抽象视图类. ByteBuf的指针ByteBuf中定义了两个指针， readerIndex和writerIndex， 分别指示当前的读位置与写位置; 整个ByteBuf被这两个指标分隔成三个区域， 从起始位置到readerIndex为已读区域(discardable)， 从readerIndex到writerIndex为可读区域(readable)， 从writerIndex到结束为可写区域(writable)， 如下图所示 ByteBuf的读写 随机读写: 通过指定下标， 以随机的方式读写ByteBuf中的数据， ByteBuf提供了一系列set/get开头的方法，这些方法不会改变ByteBuf中的指针位置 顺序读写: 根据当前readerIndex和writerIndex的位置信息，通过readByte和writeByte进行读写操作 ByteBuf的指针操作 clear： 同时将rederIndex与writerIndex重置为0， 也就是意味着恢复到原始的状态，此时可读的字符数为0， 可写的字符数也为0 mark/reset: ByteBuf有两个指针， readerIndex和writerIndex， 因此对这两个指针分别提供了相应的mark/reset操作， mark操作会将当前的指针位置记录下来，后续执行reset操作的时候，会将指针重新指到这个位置. ByteBuf的视图操作ByteBuf提供了许多创建视图对象的操作，这些视图对象拥有独立的readerIndex和writerIndex指针，但和原始的ByteBuf共享同一个byte数组，这意味着，如果视图对象修改了其中的某些值(或者原始的bytebuf对象修改了某些值）， 这些值将反应到所有的视图对象中. 视图操作包括duplicate, slice, retainedDuplicate等等，具体可以参考javadoc. 其它操作 nioByteBuffer: ByteBuf可以通过nioByteBuffer转化成nio ByteBuffer对象 array: Bytebuf通过array方法转化成byte数组对象 这两个方法都会获取到底层的字符数组，同样地，如果修改了这些数组的值，相应的修改也会反应到byteBuf中 ByteBuf的层级结构 AbstractByteBuf： 这个是ByteBuf的抽象实现 ，实现了ByteBuf 接口绝大部分的功能. AbstractDerivedByteBuf： 这个实现也可以认为是实现了包装其它bytebuf对象的功能， 它的所有子类实现都和被包装类共享同一份数据; 它的子类包括ReadOnlyByteBuf, DuplicatedByteBuf以及SliceByteBuf AbstractReferenceCountedByteBuf: 这个抽象类是所有需要进行引用计数的bytebuf的基类，也可以认为是绝大部分ByteBuf实现的基类. 它的实现又可以大体分为Unpooled实现和pooled实现两大类，具体可参见javadoc SwappedByteBuf： 这个实现可以包装其它的ByteBuf实现类，它会将byteBuf对象的byteOrder进行对调. WrappedByteBuf： 这个实现是对其它的bytebuf对象进行包装，实现类似于装饰器模式的功能 示例代码 https://github.com/Essviv/nio/blob/master/src/main/java/com/cmcc/syw/practise/BytebufPractise.java","categories":[],"tags":[]},{"title":"JVM的方法调用","slug":"JVM/JVM的方法调用","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/JVM/JVM的方法调用/","link":"","permalink":"http://yoursite.com/2017/01/25/JVM/JVM的方法调用/","excerpt":"","text":"JVM的方法调用关键字： 编译时静态多分派，运行时动态单分派 ”静态多分派“是指在编译阶段，编译器根据方法接收者以及参数的静态类型来决定选用的方法版本 ”动态单分派“是指在运行阶段，只根据方法接收者的实际类型来决定调用的实际方法 方法调用并不等于于方法执行，方法调用阶段唯一的任务就是确定被调用方法的版本（即调用哪一个方法） 在class文件编译的过程中，没有传统编译中的连接过程，也就是说，所有的方法调用在class中都是指向常量池符号引用. 1. 解析(Resolution）在类加载的解析阶段，会将其中一部分符号引用改成直接引用，但这么做的前提是，在编译阶段，具体要调用的方法的版本就已经确定下来了，这个过程被称为解析(Resolution). 符合这种“编译时确定，运行时不可变”的方法包括以下几种，这些方法都被称为是”非虚方法“, 它们的解析过程是静态的，在编译阶段就被完全确定，在类加载时的解析阶段就会把相应的符号引用变成直接引用. 私有方法(private) 类静态方法(static) 实例构造器() 父类方法 final方法 2. 分派(Dispatch)分派可以是静态的，也可以是动态的（这里的静态和动态是指分派时依据的参数类型是静态类型还是动态类型），根据分派时依据的宗量数不同，又可以分为单分派和多分派；两者结合就得到了静态单分派、静态多分派、动态单分派以及动态多分派等分派类型. JAVA是一种“编译时静态多分派， 运行时动态单分派”的语言， 这句话的理解包括两个部分：静态/动态, 单分派/多分派; 静态/动态: 静态动态是指在分派时根据方法接收者和参数的哪种类型（静态类型还是动态类型）进行的，如果是根据方法接收者和参数的静态类型决定，那么就被称为是静态分派， 否则就是动态分派 单分派/多分派: 单分派和多分派是根据分派时依据的宗量数来定义的，如果分派时根据多个宗量来确定，那么就被称为是多分派， 否则就是单分派 编译时静态多分派： 在JAVA编译器进行编译时，编译器会同时根据方法接收者以及参数的静态类型选择方法， 静态多分派最直接的例子就是overload（重载） 运行时动态单分派： 在运行时期， JAVA虚拟机会仅根据方法接收者的动态类型选择实际调用的方法， 动态多分派的例子是override(重写) 参考文献 http://wiki.jikexueyuan.com/project/java-vm/polymorphism.html 示例代码","categories":[],"tags":[]},{"title":"java集合学习之Queue的实现5","slug":"集合/java集合学习之Queue的实现5","date":"2017-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/25/集合/java集合学习之Queue的实现5/","link":"","permalink":"http://yoursite.com/2017/01/25/集合/java集合学习之Queue的实现5/","excerpt":"","text":"java集合学习之Queue的实现5Queue接口这个接口的类继承图如下所示，可以看到，这个接口主要有三种实现， AbstractQueue、Deque以及BlockingQueue（在图中未展示）. 这个接口只定义了6个方法，可以分成两组，一组在操作无法完成时会抛出异常，一组在操作无法完成时会返回特定的值， 如下，分别为add/remove/element和offer/poll/peek AbstractQueue抽象实现AbstractQueue代表了Queue接口的抽象实现，它定义了add/remove/element方法，底层调用了相应的抽象方法offer/poll/peek AbstractQueue有一个具体的实现为PriorityQueue, 它的底层是使用“最大堆”来实现的， 具体的实现过程可参考（演示动画） Deque接口Deque接口可以认为是”double end queue”， 从它提供的接口中也可以看出，这是双向都可以进行操作的队列实现， 观察它的接口方法也可以知道，基本是把queue接口的方法分别在头和尾两端定义相应的方法即可，如queue接口中的add方法，到了deque接口就有addFirst和addLast方法，queue接口中的peek方法对应了deque接口中的peekFirst和peekLast方法等等. Deque接口实现包括LinkedList和ArrayDeque. 其中LinkedList的实现已经在LinkedList一章讲过，这里就不再赘述. 重点来讲讲ArrayDeque的实现. ArrayDeque顾名思义可以知道，这个类的底层是通过数组来实现的，但既然是个双向队列，必然会涉及到从两端进行操作. 在ArrayDeque中，最重要是addFirst/addLast以及pollFirst/pollLast方法，其它的方法都是通过这些方法定义的. 首先值得说明的是head和tail变量，任何时刻，ArrayDeque中元素的顺序都是从head开始，沿数组下标增长的方向前进，直到遇到tail所处的位置，如果在遇到tail之前，已经达到了数组的最后一个元素，则从头开始继续，直到遇到tail. 从后面的方法实现中也可以看到，所有与位置相关的操作都需要与数组长度进行掩码操作，这样可以循环地利用数组. 先从addFirst和addLast方法讲起，可以看到这个两个方法的实现并不复杂，通过当前head和tail的位置插入相应的元素即可，有个细微的差别，head是在当前位置的前一个位置上进行插入，而tail是在当前的位置插入后再往后移一个位置，换句话说，head的位置为下一次poll获取元素的位置，而tail的位置始终指向下一次要插入的位置. 另外，可以看到在获取位置的时候，均进行了掩码操作，这么做的原因是可以循环地利用数组. pollFirst/pollLast方法的实现逻辑也大致相同， 当底层数组被元素填满后，就会调用doubleCapacity将数组的容量扩展为原来的2倍，容量扩展后还要涉及到数组元素的拷贝. 由于调用doubleCapacity的时候，数组已经被元素填满了，即tailf==head，从doubleCapacity的实现中看到，在将数组大小翻倍后，它会将head右边所有的元素拷贝到新数组的前面，然后将head左边的所有元素拷贝到后面. 前面我们说过，arrayDeque中维护了head和tail变量，任意时刻，元素的顺序为从head开始，沿数组下标增加的方向前进，直到遇到tail, 这也是为什么先拷贝右边的元素，然后再拷贝左边元素的原因. 明白了addFirst, addLast, pollFirst以及pollLast方法的实现后，再来理解offerFirst, offerLast, removeFirst和removeLast就比较容易了，实现如下，不做过多阐述. 不管是增加还是删除，前面讲的都是在两端执行操作，在arrayDeque中还定义了针对某个元素的操作，如删除某个元素，实现如下，这段代码的逻辑是遍历整个deque, 在找到元素后，执行delete操作 delete方法的实现如下，可以看到，删除元素后，要对剩余的元素进行挪动。这个方法中为了让挪动的元素最少， 以被删除的元素为界，分为前半段和后半段， 哪段元素数量少就挪哪一段. 以前半段元素少为例（即满足front","categories":[],"tags":[]},{"title":"Spring的IoC框架","slug":"Web/Spring的IoC框架","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/Web/Spring的IoC框架/","link":"","permalink":"http://yoursite.com/2017/01/24/Web/Spring的IoC框架/","excerpt":"","text":"容器的含义Spring中的ApplicationContext继承自BeanFactory， 除了提供了BeanFactory的功能外，还额外提供了依赖管理，消息、生命周期监听等等功能，它就是所谓的“容器” Bean定义Bean在容器的定义由BeanDefinition定义. 具体的内容包括： 完整的类名 类的依赖关系 类的生命周期回调 类的其它属性 bean的命名 每个Bean可以由一个id, 多个name来命名；必要的时候还可以通过alias来定义别名 对于没有声明名称的bean，spring容器会自动为它生成一个名称，生成的名称遵循Java规范，将类名的首字母小写，而后遵守camelCase原则 Bean的初始化从BeanDefinition的内容中可以看出，bean的类名是不可缺少的元素，在spring的配置中，这个属性是通过class属性来定义的. 可以通过三种方式来指定class属性的值： 直接指定由容器创建的类名，这种情况有点类似于用new操作符直接生成对象 通过其它类的静态工厂方法生成相应的类，这种情况下，class方法为静态类的类名，而通过factory-method指定的静态方法返回的对象类型由为实际生成的对象类型. As a rule, use the prototype scope for all stateful beans and the singleton scope for stateless beans. 通过其它类的方法生成相应的类，这种情况下，class属性的值为空，factory-bean为带有生成方法的对象名，factory-method为生成相应对象的方法名，而真正定义的对象类型则为factory-method返回的类型. 这种方法与类的静态方法生成bean对象基本类似，只不过前一种是通过静态类方法实现，而这种是通过对象方法实现. 依赖注入在Spring的语境中，依赖注入是指在容器中生成相应的对象后，由容器根据配置信息自动完成bean之间依赖关系的注入，而不是由bean自己去维护和管理相应的依赖关系的做法。在spring中，可以通过两种方式进行依赖注入，通常情况下，通过构造函数进行那些必须的依赖关系的注入，而使用setter方法完成那些可选的依赖关系的注入. 1. 构造函数使用构造函数完成依赖注入与使用带有参数的静态类工厂方法来实现依赖注入是一样的道理，因此在后面的描述中，不对这两种情况进行更多的区分. 使用构造函数完成依赖注入的时候，需要完成参数类型的解析. 在类型不会千万歧义的情况下（即所有参数的类型都不相同），提供的参数会自动按照相应的类型提供给相应的构造函数，而不需要显式地指定参数的位置 但是如果遇到无法自动完成类型的解析时，则可以通过type属性显式地指定参数的类型 也可以通过index参数直接指定参数的位置，这样提供的bean将会作为第index个构造参数提供给构造方法 2. setter方法顾名思义，setter方法就是在spring构造完对象后（通常是调用类的无参数构造函数或静态类的不带参数的方法生成的），通过set方法完成相应属性的注入. 依赖注入配置的细节 在配置文件中，属性的值总是通过string类型进行表达的，但实际上的参数类型并不一定是string,两者之间的转换可以通过ConversionService来完成 可以通过p命名空间很方便地实现属性地赋值 通过idref标签可以引用到相应的bean，这种引用方式让容器可以在部署的时候就检查引用的对象是否真实存在，而不是等到运行时再检查 作用域 singleton: 每个容器单实例 prototype: 原型，每次请求时都会创建一个新的实例; 在这种作用域情况下，容器只负责初始化bean，一旦初始化结束，容器就不再管理这个bean，后续的维护包括资源的回收等问题，全部交由客户端自行维护，因此对于这种作用域的对象来讲，它的析构函数并不会被容器调用，如果客户端需要执行这些操作，可以考虑使用PostProcessor接口来完成.另外，如果在singleton作用域的对象中注入了prototype对象，这种引用关系是在初始化的时候就引入了. 这意味着，当singleton对象被初始化完之后，内部的prototype类型的对象就不会再发生变化; 因为初始化操作只会发生一次，如果需要在运行时每次获取新的prototype对象，则需要spring提供的’方法注入’方式来解决 application: 每个servletContext一个实例，它与singleton的区别在于它的范围是servletContext， 而singleton是在容器范围 request: 每个请求一个实例 session: 每个会话一个实例 globalSession, webSocket： 前者是用于PortletServlet，后者用于webSocket，略","categories":[],"tags":[]},{"title":"memo","slug":"集合/memo","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/集合/memo/","link":"","permalink":"http://yoursite.com/2017/01/24/集合/memo/","excerpt":"","text":"memo需要进一步深入学习的点： BlockingQueue CocurrentHashMap BlockingDeque 以上内容可以从这里找到答案 hashCode和equals： http://tutorials.jenkov.com/java-collections/hashcode-equals.html","categories":[],"tags":[]},{"title":"snowflake","slug":"工具/snowflake","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/工具/snowflake/","link":"","permalink":"http://yoursite.com/2017/01/24/工具/snowflake/","excerpt":"","text":"Snoaflake snowflake算法背后的思想是： 时间 + 空间 + 序列号","categories":[],"tags":[]},{"title":"RabbitMQ的HA方案","slug":"消息队列/rabbitMQ/RabbitMQ的HA方案","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/消息队列/rabbitMQ/RabbitMQ的HA方案/","link":"","permalink":"http://yoursite.com/2017/01/24/消息队列/rabbitMQ/RabbitMQ的HA方案/","excerpt":"","text":"RabbitMQ的HA方案默认情况下，queue可以认为是只存在于它被声明的那个节点中，但是broker和binding可以认为存在于集群中的所有节点中. 可以通过镜像的方式，将queue复制到其它的节点中，以此来提高可用性 镜像队列之间彼此形成了一主多从的关系，当主镜像队列因为某些原因消失时，一个从镜像自动被推选为主镜像 不论客户端连接到哪个结点，它都将连接到主镜像队列中，所有队列的操作也都是通过主镜像队列来完成，这样就保证了队列的FIFO特性 发布到主镜像队列中的消息将会被自动镜像到所有的从镜像中 如果主镜像中的消息确认已经被消费了，那么从镜像会自动将该消息删除 这种镜像的方式并不能将流量分散到各个节点，因为每个节点做的事情是一样的，但是它提高了可用性，如果主镜像队列因为某些原因消失了，那么从镜像可以自动升级为主镜像，保证了队列的可用性 配置镜像 队列镜像的配置是通过policy来完成的，通过ha-mode和ha-params参数来配置 ha-mode = all, ha-params = null: 所有的队列将被镜像到集群中的所有节点中 ha-mode = exactly, ha-params = count: 所有的队列将被准确地镜像count份，如果集群中的节点少于count个，那么将会被镜像到所有的节点中 ha-mode = nodes, ha-params = [node_names]: 所有的队列将被镜像到列表中提供的节点中，节点的名称为rabbitmctl cluster_status中列出的节点名 主队列镜像的位置也是可以配置的，可以在声明队列时设置，也可以在配置文件中设置，也可以通过配置policy中的queue-master-locator参数来完成，可选的参数有： min-masters: 将集群中拥有最少主队列镜像的那个节点作为主镜像所在的节点 client-local: 将声明这个队列的节点作为主镜像所在的节点 random: 随机挑选集群中的节点 如果新配置的policy导致原先的主镜像所在的节点不在队列的镜像集群中，那么RMQ会保持原来的主镜像所在的节点，直到新的主镜像完成同步后，才会将原来的主镜像队列删除。 1如果原来的队列Q被镜像到了[A, B]节点中，其中A节点为主镜像所在的节点，现在配置了新的policy，将队列中镜像到了[C, D]中，那么RMQ的操作将会是，保留[A, C, D], 直到C或者D完成了队列的同步后，再把A从镜像队列中删除，最后变成[C, D] 排它队列: 由于具有排它性的队列当声明它的连接(connection)关闭时，会被自动删除，因此这种类型的队列永远也不会被镜像，而且它也不会被持久化，一旦连接关闭，它就会被自动删除，因此镜像和持久化都是没有意义的。 具体的配置可以通过rabbitmctl的set_policy来完成 ，也可以通过RMQ的管理界面来完成 节点间的同步机制和故障转移1. 同步机制节点可以选择在任意时刻加入到集群中，当一个节点新增到集群中时，它的镜像队列是空的，随后所有新增的消息都会自动发布到这个新的节点中，但之前队列中已经有的消息并不会自动出现在这个新的队列镜像中，但是随着时间的推移，这部分队列头部的消息被逐步消费掉，等到它们被全部消费掉的时候，新增节点中的消息将和其它节点的消息完全一致， 这种同步的机制被称为“自然同步”(natural synchronization) 当然也可以选择显式地同步消息队列，但是由于同步会导致队列暂停响应，因此，建议只针对那些不活跃的队列进行显式同步，而对于那些活跃的队列只需要使用上述的方式进行同步即可 显式的同步有两种方式，一种是手动同步，一种是自动同步，可以通过设置ha-sync-mode参数来完成，分别为manual和automatic. 在RMQ3.6.0之后，可以通过设置ha-sync-batch-size参数来批量同步，默认每次只同步一条消息. 2. 故障转移当集群中的主镜像掉线时，集群中的某个从节点将会被推选为主镜像，如果此时集群中没有其它节点，那么该节点中那些被设置为持久化的消息将被持久化到硬盘，如果重启了该节点，这些消息将会被恢复； 如果某个从镜像原先属于某个集群中，那么当这个从镜像重启时，它将会重新加入到\b集群中，但是由于此时这个从镜像并不知道自己队列中的内容和主\b镜像中的内容是否一致，因此重新加入集群中意味着它将抛弃之前持久化的所有消息，以保持与主镜像内容的一致性 当关闭主镜像时，如果此时集群中所有的从节点都处于未同步的状态，那么要分两种情况： 如果关闭请求是来自可控制的事件(如RMQ服务器关闭或者系统关闭）那么RMQ会拒绝进行故障转移，此时它会直接将整个队列关闭，从而避免数据的丢失，但是这时候会造成队列的不可用 如果关闭请求是来自不可控制的事件(如服务器崩溃或节点掉线) 那么即使所有的从节点都处于未同步的状态，那么集群还是会自动进行故障转移，此时保障了集群的可用性，但是有可能会千万数据的丢失 如果想保证集群的可用性，在任何情况下都进行故障转移，那么可以设置ha-promote-on-shutdown参数为always, 这时在任何情况下，只要主镜像关闭了，即使集群中所有的从节点都处于未同步的状态，集群也将进行故障转移操作. 当整个集群全部下线时，最后一个下线的节点必须是最先重新启动的节点，因为它是整个集群最后的主镜像，如果它没有被最先启动，那么所有启动的从镜像将会等待30秒，然后失败； 如果需要将这个主镜像从集群中移除，那么可以通过rabbitmqctl设置forget_cluster_node\b参数, 关于这个参数含义的解释可以参阅参考文档中的“Loss a master while all slaves are stopped.”一节。 HA方案下消息发送确认及事务的语义HA方案下，消息发送确认及事务的语义是指所有的镜像队列都确认消息发送或者事务提交完成，也就是说，只要集群中的某个镜像没有对发送的消息进行确认，那么发布者将会被暂停，直到这个镜像发送了确认，或者集群中的其他镜像节点认为这个镜像已经掉线（掉线的检测是RMQ通过间隔一定时间的心跳检测来完成的) HA方案下，发布者的流量控制是也是通过这种方式来实现的，只有当集群中所有的镜像都允许发布者发布消息的时候，发布者才可以继续发布消息，否则它只能继续等待或者直到集群中的其它节点认为该节点已经掉线 有些时间，消费者可能会需要知道集群中的某个节点掉线的通知，这可以通过设置x-cancel-on-ha-failover参数来实现，具体可以参见文档 HA方案下节点掉线的处理和语义 如果是从镜像掉线，那么主镜像依然是主镜像，其它的从镜像也不会得到任何通知或者采取任何操作 如果是主镜像掉线，那么以下的操作将会被执行： 最老的那个从镜像将会被推选为新的主镜像，因为这样才能使丢消息的概率降到最低 如果所有的从镜像都没有处于“已同步”的状态，那么那些只存在于主镜像中的消息将会丢失 新的主镜像会认为之前所有到主镜像的连接都已经被突然中断，因此它会把所有没有收到消费确认的消息重新推到队列中，不管这种没有确认是由于网络中断造成的，还是由于原来的主镜像没有把相应的确认消息同步给它们造成的，这种做法可能会导致消费者重新消费到一条它已经处理过的消息 所有到原来的主镜像的连接都将被取消 不管是主镜像掉线还是从镜像掉线，都不会影响到发布者的发布确认，因此从发布者的角度来讲，发布消息到镜像集群中和发布消息到其它任何类型的队列中是没有区别的. 另外，在掉线期间发布的消息也不会丢失，因为所有的消息都是直接发布到镜像集群中的所有节点中 参考文档 HA方案","categories":[],"tags":[]},{"title":"阻塞锁与自旋锁","slug":"多线程/juc/AQS框架/阻塞锁与自旋锁","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/多线程/juc/AQS框架/阻塞锁与自旋锁/","link":"","permalink":"http://yoursite.com/2017/01/24/多线程/juc/AQS框架/阻塞锁与自旋锁/","excerpt":"","text":"阻塞锁与自旋锁在学习JAVA并发包的时候发现其底层的实现是通过AQS框架来完成的，而AQS框架中维护了一个CLH队列，CLH队列使用了CLH锁，因此上网搜了下这方面的内容，发现原来在并行编程中有这么多的锁类型，索性做个总结，此为本篇内容的缘由. 1. 阻塞锁阻塞锁是指当线程尝试获取锁失败时，线程进入阻塞状态，直到接收信号后被唤醒.(线程的状态包括新建、就绪、运行、阻塞及死亡）在JAVA中，能够唤醒阻塞线程的操作包括Object.notify, Object.notifyAll, Condition.signal, LockSupport.unpark(JUC中引入） 阻塞锁的优点是在线程获取锁失败后，不会一直处于运行状态（占用CPU）， 因此在竞争激烈的情况下， 阻塞锁的性能将明显优于自旋锁 2. 自旋锁自旋锁的特性是，当线程尝试获取锁失败时（锁已经被其它线程占用了），它不会将线程切换为沉睡状态，而是开启无限循环，不断地轮询锁的状态（这也是“自旋”的来历），当锁状态被更改时，获取到锁并进入临界区. 自旋锁本身并没有关注公平性、可重入性等特性，另外，由于自旋锁的实现需要不断轮询锁的状态，因此需要占用CPU，适用于临界区时间很短的场景. 自旋锁又可进一步细分为排队自旋锁(TicketLock)、MCS锁以及CLH锁， 其中排队自旋锁解决的是公平性的问题 排队自旋锁： 排队自旋锁关注的是公平性问题，每个线程在尝试获取锁的时候都会被分发唯一的一个号码，而锁本身提供了服务号服务，类似于现实生活中的排队叫号服务，每个线程都有个号码，锁对象每次叫一个号，拿到相应事情的线程获得锁. 排队自旋锁虽然解决了公平性问题，但由于所有的线程都在读写同一个变量(服务号），因此每一次读写操作都必须同步处理器缓存，会导致大量的总线流量 MCS锁：MCS锁采用了链表的形式对尝试获取锁失败的线程排队，MCS锁自旋的是自身的本地变量，它是显式的队列，有真实的后继节点. CLH锁： CLH锁和MCS非常类似，但CLH锁自旋的是前驱节点的变量, 它是隐式的队列，没有真实的后继节点 关于自旋锁的实现代码可以参见这里 3. JUC中的相关实现在java的并发包中，提供了LockSupport类，它提供了阻塞与唤醒的原语操作. 事实上，JUC中的AQS框架就是基于CLH队列实现，但是它还使用LockSupport类进行了改良，使原来的CLH自旋锁变成了阻塞锁. 使用LockSupport类实现CLH阻塞锁的代码可以参见这里 关于JUC中的AQS框架源码的分析，可以查看这里 参考文献 CLH锁学习： http://googi.iteye.com/blog/1736570 自旋锁的比较与实现： http://coderbee.net/index.php/concurrent/20131115/577 JAVA锁的系列文章： http://ifeve.com/java_lock_see1/ MCS锁的文章： https://www.ibm.com/developerworks/cn/linux/l-cn-mcsspinlock/ JUC系列文章：http://www.cnblogs.com/skywang12345/p/java_threads_category.html 示例代码 各种锁的实现示例: https://github.com/Essviv/spring/tree/master/src/main/java/com/cmcc/syw/concurrency/lock","categories":[],"tags":[]},{"title":"equals和hashCode方法的使用约定","slug":"JAVA基础/equals和hashCode方法的使用约定","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/JAVA基础/equals和hashCode方法的使用约定/","link":"","permalink":"http://yoursite.com/2017/01/24/JAVA基础/equals和hashCode方法的使用约定/","excerpt":"","text":"Java的Object类中提供了两个重要的方法，equals和hashCode， 在map和set中这两个方法起到了至关重要的作用，以下是使用和重写这两个方法时的约定 如果两个对象通过equals比较的结果为true, 那么它们的hashCode也必须一样 如果两个对象的hashCode相等，那么这两个对象不一定相等（即equals不一定返回true） 默认情况下，equals方法调用了==操作符，也就是说，它只会在指向同一个对象时才会返回true, 而hashCode默认是将对象的地址转化成唯一的整型数字. 在“Effective Java”有这样一条建议： 如果你重写了equals方法，那么一定要重写hashCode 错误的例子： 这里只重写了equals方法，但没有重写hashCode，这导致在这个类被用作map的key时，出现了一些不正常的情况（事实上这个是和hashMap的实现有关系的） 正确的例子，这个例子中的类继承自上面那个类，但是它重写了hashCode类，保证了当equals返回true时，hashCode也能返回相同的值，解决了上述的问题 事实上，上述问题与hashMap的内部实现有着很大的关系，关于hashMap的源码解析，请见HashMap源码解析","categories":[],"tags":[]},{"title":"迭代器模式","slug":"设计模式/迭代器模式","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/设计模式/迭代器模式/","link":"","permalink":"http://yoursite.com/2017/01/24/设计模式/迭代器模式/","excerpt":"","text":"迭代器模式迭代器模式中涉及到两个关键的组件， 集合类与迭代器. 迭代器简化了遍历集合类元素的操作，使得外界可以不用了解集合类中的数据组织情况就可以访问其中的所有元素， 它的UML图比较简单，如下所示， UML图中定义了两个抽象接口，Aggregate和Iterator， 分别对应于上面所说的集合类和迭代器，集合类中提供了相应的方法来获取迭代器，而迭代器中提供了相应的方法来遍历集合类中的元素. 以JAVA中提供的集合框架为例，Collection接口就是这里的Aggregate接口，而Iterator接口就对应这里的Iterator接口，collection接口中提供了iterator方法来获取相应的迭代器，而iterator接口中提供了hasNext， next, remove等操作来遍历和访问集合中的元素. 示例代码 迭代器实现","categories":[],"tags":[]},{"title":"Synchronized关键字","slug":"多线程/Synchronized关键字","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/多线程/Synchronized关键字/","link":"","permalink":"http://yoursite.com/2017/01/24/多线程/Synchronized关键字/","excerpt":"","text":"Synchronized关键字 synchronized提供的是排它的、不公平的、可重入的锁，这是JAVA对象内含的锁对象. Keep in mind that using synchronized on methods is really just shorthand (assume class is SomeClass) 1synchronized static void foo() &#123; ...&#125; is the same as 1static void foo() &#123; synchronized(SomeClass.class) &#123; ... &#125;&#125; and 1synchronized void foo() &#123; ...&#125; is the same as 1void foo() &#123; synchronized(this) &#123; ... &#125;&#125; happens-beforehappends-before关系是一种保证关系，它保证一个语句的执行结果对另一个语句可见，其本质是一种可见性保证。以下几种情况均存在这种关系: 在同一个线程中执行的语句，自动拥有happends-before的关系 对锁的unlock操作和随后对同一个锁的lock操作有happens-before关系，由于这种关系有传递性，因此在unlock之前的所有操作对lock之后所有的操作可见 对volatile变量的写操作和随后对它的读操作有happens-before关系 线程的start操作和线程中执行的所有操作有happens-before关系 被调用了join操作的线程, 它执行的所有操作对调用该(join)操作的线程有happens-before关系 参考文献 https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/package-summary.html#MemoryVisibility http://blog.sina.com.cn/s/blog_4ae8f77f0101iifx.html","categories":[],"tags":[]},{"title":"Memcached","slug":"缓存/Memcached","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/缓存/Memcached/","link":"","permalink":"http://yoursite.com/2017/01/24/缓存/Memcached/","excerpt":"","text":"Memcached命令格式123456 &lt;command&gt; &lt;key&gt; &lt;flags&gt; &lt;expireTime&gt; &lt;bytes&gt; &lt;datablock&gt;e.g. set name 0 0 8 sunyiwei command: 要执行的命令，如set, get, replace等 key: 操作的键名称 flags: 客户端存储的键值对之外的信息 expireTime: 过期时间，设置为0则为永久有效 bytes: 数据长度 datablock: 实际的数据内容 执行命令（CRUD） C: add, set R: get, gets U: set, cas, replace D: delete 统计命令 stats: 当前服务器运行的统计信息 stats items: 内存模型memcached中将内存模型主要有三个概念，page, slab和chunk，如下图所示 Page: 内存分配的单位，即每次memcached申请内存的大小，申请得到的内存将分配给相应的slab进行使用 Slab: memcached中将一组相同大小的chunk归为一组，称为slab， 每个slab中的chunk大小都是相同的，并且只负责一定大小范围内的数据存储 Chunk: 固定大小，它的大小即为所在slab的最大存储尺寸；memcached中数据实际存储的地方，同一个slab中的chunk大小均相同，但不同slab中的chunk的大小可以不相同 memcached的执行参数12345678910111213141516171819-p &lt;num&gt; 设置TCP端口号(默认不设置为: 11211)-U &lt;num&gt; UDP监听端口(默认: 11211, 0 时关闭) -l &lt;ip_addr&gt; 绑定地址(默认:所有都允许,无论内外网或者本机更换IP，有安全隐患，若设置为127.0.0.1就只能本机访问)-d 以daemon方式运行-u &lt;username&gt; 绑定使用指定用户运行进程&lt;username&gt;-m &lt;num&gt; 允许最大内存用量，单位M (默认: 64 MB)-P &lt;file&gt; 将PID写入文件&lt;file&gt;，这样可以使得后边进行快速进程终止, 需要与-d 一起使用-vv 用very verbose模式启动，将打印相应的调试信息和错误信息-h 打印本帮助文档例如： ./usr/local/bin/memcached -d -u root -l 192.168.1.197 -m 2048 -p 12121 几点说明 memcached内存中的数据并不会被删除，当记录到期后，memcached会采用lazy expiration的策略将这条记录置为不可见，同时，这条记录所占用的空间可以被重复使用; 另外，lazy expiration的策略也会导致memcached并不会花时间在检查记录的过期上 memcached默认使用的是LRU(Least Recently Used)的策略来删除数据，可以通过-M参数禁用该机制 参考 memcached的内存模型： http://xenojoshua.com/2011/04/deep-in-memcached-how-it-works/ memcached和redis在内存管理方面的对比： http://www.biaodianfu.com/redis-vs-memcached.html 缓存的设计: http://data.qq.com/article?id=2879 协议说明： https://github.com/memcached/memcached/blob/master/doc/protocol.txt CheatSheet: http://lzone.de/cheat-sheet/memcached","categories":[],"tags":[]},{"title":"多线程进阶","slug":"多线程/多线程进阶","date":"2017-01-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/24/多线程/多线程进阶/","link":"","permalink":"http://yoursite.com/2017/01/24/多线程/多线程进阶/","excerpt":"","text":"多线程进阶 锁对象synchronized关键字内部使用的是一种较为简单的重入锁机制，可以通过Lock接口来实现相应的功能。Lock接口的好处在于在尝试获取对象锁时，可以直接返回或者等待一段时间后再返回，更为灵活 另外，读写锁提供了更为精巧的方式来控制同时读写的问题，它特别适合于解决读写互斥，写写互斥，但读读不互斥的情景。 在使用Lock接口时，获取锁对象后，注意要把解锁的操作（unlock）放在finally块中，否则锁对象将被一直占用，导致后续的线程无法继续 Executor这部分内容可分为三部分，分别为： Executor接口： executor, executorService, ScheduledExecutorSerivce 线程池 Fork/Join框架 1. Executor接口 Runnable, Future, Callable: Runnable是用来运行任务，它没有返回值，相对地，callable有返回值，并且有可能会抛出异常；Callable调用时会返回future,可以通过future对象来控制线程的状态，比如取消，等待结果等等 ExecutorService: 在executor的基础上增加了对线程管理和线程池管理的函数，并且可以执行callable线程（Executor只能执行runnable线程，且没有管理生命周期的功能） 2. 线程池线程池可以重复地利用已经存在的线程，一方面可以节省重复创建线程的时间，另一方面也可以防止大量的创建线程导致系统资源耗尽。一般情况下，线程池需要配合阻塞队列来实现，这样，当外部提交执行任务时，只需要往队列里塞入相应的任务即可，在线程池内部的线程处于空间状态时，会自动地去消费队列中的任务，如果此时队列为空，则阻塞等待，其实质是“生产者-消费者” 3. Fork/Join框架待理解 异步集合 BlockingQueue: 阻塞队列，从队列中获取元素时，它会阻塞或超时(javadoc) ConcurrentMap: map的异步实现，它将增加、删除或者修改键值的操作原子化，从而避免了同步操作(javadoc) ConcurrentNavigableMap: 支持模糊匹配的map实现，可以认为是treeMap的异步实现(javadoc) 原子变量对原子变量的操作都是原子性的，也就是说，set操作和之后的get操作有happens-before的关系 异步随机数略 参考资料 http://tutorials.jenkov.com/java-concurrency/locks.html http://docs.oracle.com/javase/tutorial/essential/concurrency/newlocks.html http://tutorials.jenkov.com/java-concurrency/thread-pools.html http://docs.oracle.com/javase/tutorial/essential/concurrency/pools.html hashtable和concurrentMap的比较","categories":[],"tags":[]},{"title":"ThreadPoolExecutor源码解析","slug":"多线程/juc/线程池/ThreadPoolExecutor源码解析","date":"2017-01-04T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2017/01/04/多线程/juc/线程池/ThreadPoolExecutor源码解析/","link":"","permalink":"http://yoursite.com/2017/01/04/多线程/juc/线程池/ThreadPoolExecutor源码解析/","excerpt":"","text":"ThreadPoolExecutor(TPE)源码解析1. Ctl变量TPE的状态由ctl变量定义和追踪，ctl的低位（29位）定义了当前正在运行的工作线程数，而高位（3位）定义了当前线程池的状态 Running: 正在运行，并且接受新的任务 Shutdown: 不接受新的任务，但会执行已提交的任务 Stop: 不接受新的任务，也不会执行已提交的任务 Tidy: 清理工作线程的阶段 Terminated: 线程池已完全停止 2. 配置参数 CoolPoolSize: 核心线程数，当目前线程池中线程数小于这个值时，新的任务提交进来，线程池会创建新的线程来执行这个任务 MaximumPoolSize: 线程池中最大的线程数，线程数达到这个数时，再有新的任务提交进来，会调用RejectHandler接口执行拒绝操作；可以将这个值设置为Integer.MaxValue，表示不对线程池的线程数做限制 BlockingQueue: 当目前线程池中线程数超过CoolPoolSize, 但没有达到MaximumPoolSize时，线程池会优先将新提交的任务缓存到队列中，当入队失败时（或达到队列的上限），才会考虑创建新的线程；可以使用LinkedBlockingQueue这样的实现 ，可以“无限制”的将任务入队，这种情况下，MaximumPoolSize参数无效 RejectHandler: 当目前线程池中的线程数超过MaximumPoolSize的值时，会调用RejectHandler接口，JCU中提供了多种现成的实现 Hook方法： 当线程池执行每个任务时，会调用beforeExecute方法，当执行完每个任务后，会调用afterExecute方法；这两个hook方法允许子类在任务前后执行特定的操作. 参考文章 ThreadPoolExecutor源码分析","categories":[],"tags":[]},{"title":"JUC","slug":"多线程/juc/JUC","date":"2016-12-29T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/29/多线程/juc/JUC/","link":"","permalink":"http://yoursite.com/2016/12/29/多线程/juc/JUC/","excerpt":"","text":"JUC并发包又可以进一步细分为： 原子操作 线程池 并发集合 锁及工具类 其中， 原子操作和LockSupport共同提供了CAS操作机制，它们共同为AQS的实现提供了基石. 而AQS框架进一步可以被封装成各种Lock实现，为线程池、并发集合提供支持. AtomicOperation, LockSupport ===&gt; AQS ===&gt; Lock ====&gt; Executor、Concurrent Collection","categories":[],"tags":[]},{"title":"Redis和Memcached的区别","slug":"缓存/Redis和Memcached的区别","date":"2016-12-22T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/22/缓存/Redis和Memcached的区别/","link":"","permalink":"http://yoursite.com/2016/12/22/缓存/Redis和Memcached的区别/","excerpt":"","text":"Redis和Memcached的区别 支持的数据类型不一样Redis除了支持key-value之外，还支持Set, sortedSet, List以及Map类型，这些不同的类型使得redis可以应对更丰富的场景;Memcached只支持key-value的形式，因此它比较适合做缓存的场景 网络IO模型redis采用单线程IO复用模型，所有的命令是流水线式地进行处理；memcached采用非阻塞IO复用模型，分为监听主线程和worker子线程，主线程负责监听来自客户端的连接，并将接收到的请求交由worker线程进行处理。多线程模型可以充分发挥多核的作用，但也由此引入了竞争条件和锁的问题. （e.g. stats） 内存模型redis使用现场申请内存的方式来分配内存，也就是说，当需要存储数据时，redis会通过malloc等方式申请内存；而memcached是采用预分配内存池的方式，在系统启动时，会按照一定的间隔分配slab和chunk， 每个slab中的chunk块大小是固定的，每次存储数据时，选用能放下数据的最小chunk块， 这种方式可以快速地分配内存，但很容易造成内存碎片， 当slab中的chunk被使用完时，会申请page（1M）大小的内存，然后分配给slab，再按指定的chunk大小进行细分. 持久化redis提供了aof以及rdb的方式进行持久化，而memcached没有相应的持久化机制 集群管理redis更倾向于通过服务端的分布式存储构造集群，同时也提供了主从备份的苏通; 而memcached本身不支持分布式，只能通过客户端通过像一致性哈希等算法进行分布式存储。 参考文献 http://gnucto.blog.51cto.com/3391516/998509 http://blog.jobbole.com/101496/","categories":[],"tags":[]},{"title":"java集合学习之List的实现3","slug":"集合/java集合学习之List的实现3","date":"2016-12-20T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/20/集合/java集合学习之List的实现3/","link":"","permalink":"http://yoursite.com/2016/12/20/集合/java集合学习之List的实现3/","excerpt":"","text":"java集合学习之List的实现3在Java集合框架中，对于List接口的实现主要有两种， ArrayList和LinkedList. 前者底层是基于数组的实现，后者底层是基于双向链表的实现. ArrayList底层是通过Object[]数组来存储数据， 从arrayList的add方法可以看到，当往ArrayList中添加新的元素时，它会先确保当前的数据容量大小，如果长度不够，则会将数组长度*1.5后复制数组. 既然arrayList以数组作为底层存储，那么它也同样拥有数组访问的特性，即随机读取的效率较高，但增加和删除数据的效率较低，因为要复制数组中的元素 arrayList中还有个重要的变量modCount， 这个变量存储了ArrayList结构被修改的次数，每次增加或者删除数组元素都会引起这个变量值发生变化，在迭代器进行遍历的过程中，这个变量的值保证了不会有其它的线程并发地修改数组的内容，如果有的话，则会引发fast-fail机制. 可以看到，在迭代器进行迭代的过程中，会调用checkForComodification方法， 这个方法就是判断当前的modCount与创建迭代器时的值是否一致 ，如果不一致，则会抛出ConcurrentModificationException. 从ArrayList迭代器的实现中可以看出，在迭代器遍历的过程，如果有其它线程修改了arrayList的结构（增加或者删除元素，但不包括修改元素的值）则会引起ConcurrentModificationException， 但是，如果调用的是迭代器的remove方法则不会有这个问题，从remove方法的实现中可以看到，在数组中移除相应的元素后，迭代器会重新设置expectedModCount的值，这样就能避免抛出异常的问题. LinkedList从名字上可以看出，这个List实现是通过链表的方式来完成的，在LinkedList中定义了链表中的节点Node, 可以看到这个节点定义了前向、后向节点以及当前节点的元素对象. 而在LinkedList的定义中，只定义了first, last节点对象，分别来代表链表中的头尾结点. LinkedList定义了一系列的link和unlink私有方法，这些方法完成了链表相关的所有操作. 从源码中可以看出，first(last结点类似)最开始的时候为null, 当新增结点时，会将first结点指向这个新的结点，同时修改size和modCount的值. 另外，这里可以看到，在新建结点时，first结点的prev设置为null, 也就是说，first结点的前置结点为空，因此这里是双向链表，但不是循环链表.unlink方法将指定元素从链表中移除，这个方法将指定结点与前后结点的链接关系去除，并且重新构建了前后结点的关联关系，逻辑相对简单，不做过多阐述. 有了link和unlink方法后，就可以很方便地实现list接口中定义的方法，只需要在链表中特定的位置上加入或删除相应的结点即可. 另外，LinkedList中还提供了node方法，它是用来支持随机访问的，可以看到，在遍历链表中的节点时，如果查询的index小于链表长度的一半，LinkedList会尝试从前往后找，如果大于长度的一半，则会尝试从后往前找. 对于像add(index, elem)或者像remove(index, elem)这些方法来讲，都需要先调用node方法找到index位置的那个结点，然后才能开始新增或者删除的操作. 由些可见，LinkedList适合于在链表头或者链表尾增加或者删除结点，但不适合于随机访问较多的场合. 值得一提的是，LinkedList不仅仅实现了List接口，它还实现了Deque接口，这个接口定义了双向队列的操作，从前面的描述中也能看到， LinkedList很适合从头或者尾进行操作的场景. 因此可以很方便地实现Deque接口中定义的方法(element, peek, add, remove, offer, poll） ArrayList和LinkedList的比较 ArrayList的底层是用数组实现的，读取任意元素的时间复杂度均为O(1), 因此它非常适合于随机访问比较多的场景，但是由于新增和删除元素都涉及到数组元素拷贝，它的新增和删除操作的性能不如LinkedList. LinkedList底层使用链表实现，新增和删除链表中的结点只需要更改前后结点的prev和next指针指向即可，因此可以很方便地在链表中的任意位置进行新增和插入操作，但是，对于随机访问的场景，由于需要从头结点或者尾结点开始遍历查找，因此性能不如ArrayList. Vectorvector也实现了List接口，同时它的底层也是通过数组实现的，但和ArrayList不同的是，Vector是线程安全的，在进行操作的时候，vector会使用synchronized关键字进行同步，因此它的性能要比ArrayList低很多, 对于不需要考虑多线程的场景，建议使用ArrayList 参考文献 ArrayList和LinkedList源码解析 ArrayList与Vector的比较","categories":[],"tags":[]},{"title":"java集合学习之接口1","slug":"集合/java集合学习之接口1","date":"2016-12-20T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/20/集合/java集合学习之接口1/","link":"","permalink":"http://yoursite.com/2016/12/20/集合/java集合学习之接口1/","excerpt":"","text":"java集合学习之接口1java集合框架的内容包括四个部分， 分别为接口，实现， 聚合操作和算法. 本章只详述接口部分的内容。 接口： 接口可从宏观上分为两类， 分别为map和collection， collection又可细分为set, list, queue, deque.在理解接口的时候，可以从以下几个方面来理解： 接口提供了哪些功能 接口有哪些具体的实现，以及它们之间的区别 接口可以有哪些操作 Collection接口collection接口中包括了集合最基本的操作，比如size, add, remove, iterator, isEmpty, contains等等操作，不同的collection实现类可以通过构造函数很方便地进行类型转换.如下: List&lt;String&gt; strings = new LinkedList&lt;String&gt;(); Set&lt;String&gt; stringSets = new HashSet&lt;String&gt;(strings); 遍历collection的方式 在JDK1.8中，可以通过聚合操作来完成 collection.stream().filter(e –&gt; e.getColor == Colors.RED).forEach(e –&gt; doSth(e)) 使用forEach操作 for(String s : collection){ doSth(s); } 使用iterator操作: 这里的iterator使用了迭代器模式，可以借此机会复习下迭代器模式，在遍历的过程中，使用迭代器的remove方法也是唯一能够安全地操作collection中的元素的方法，如果在遍历的过程中使用其它的方式改变了collection中的元素，其行为是不可预知的. Iterator iter = collection.iterator(); while(iter.hasNext()){ doSth(iter.next()); } Set接口Set接口定义了元素不能重复的集合类，它可以认为是数学意义上的集合，在JAVA的集合框架中有三种不同的实现： HashSet: 底层使用HashMap进行存储，事实上HashMap的keySet就是这个hashSet, 它不保证集合遍历的顺序，但这是效率最好的实现 TreeSet: 底层使用红黑树存储，根据它们的值进行排序，效率比hashSet略慢 LinkedHashSet: 底层使用hashMap以及双向链接进行存储，它能够保证元素遍历的顺序与插入的顺序一致 既然把set接口认为是数学意义上的集合，很显然就可以对它进行交集、并集、求差等操作，事实上set接口中的retailAll和removeAll方法就是用来实现这些功能的 List接口List接口定义了一组有序集合，集合中的元素可以重复，它提供了顺序访问以及搜寻功能，同时也提供了遍历和局部视图功能，可以取出集合中的某部分元素集合进行操作，在JAVA集合框架中，提供了两种实现： ArrayList: 底层使用数组来实现元素的存储，在绝大部分情况下，这种实现的性能是比较好的。 LinkedList: List的链表实现, 底层使用双向链表进行存储，这种实现在增删元素时性能更佳，但顺序访问时性能不好，因为需要遍历整个链表 Queue接口Queue是一系列准备用于处理的元素的集合，除了collection提供的方法之外，它还提供了额外的增改查操作，对于所有的增改查操作，queue接口都提供了两种实现方式，在操作失败的时候，一种是抛出异常，另一种是返回特定的值（如null或者false， 依不同的操作而定), 具体的操作如下： 其中，add， remove和element在操作失败的时候会抛出异常, 而与它们一一对应的offer, poll和peek在操作失败时则会返回false，另外remove/poll和element/peek的区别在于，前者从queue中取到元素后，会把元素从queue中删除，而后者则不会 Deque接口deque接口是可以从头尾进行增删改的队列接口，应该说它是queue接口的扩展，因为它同时实现了queue(FIFO）以及堆(LIFO)的功能，从它的提供的操作来看，也可以很清楚地看到这点，所有在queue中的六个操作(add, offer, remove, poll, element, peek)在deque都有头元素以及尾元素的实现，具体操作如下： 可以看到，所有的六个操作都有了两种针对头元素和尾元素的实现，但语义不变 Map接口map接口提供了将Key映射成value的对象，它可以认为是数学意义上的函数。它提供了基本的增删改查的操作以及相应的视图操作(put, remove, get, contains, size, empty, entrySet, keySet, values)等等 注意在map接口提供的三个视图中，keySet和entrySet都是set类型的，也就是说它们是不能重复的，但是values只是collection类型，这意味着它的值是可以重复的（这也是数学意义上函数的定义). 另外，在视图上的一些操作（如removeAll, retailAll等)都会影响到原来的map的内容,具体可以查阅HashMap的keySet方法的实现源码 在JAVA集合框架中也提供了三种实现： HashMap, TreeMap和LinkedHashMap.它们的语义及特点正如这些名字所指示的那样，和对应的三个Set(HashSet, TreeSet, LinkedHashSet)相同，事实上，对应的set在实现的时候，内部就是借助了Map的key不能重复的特点，直接将map的keySet进行使用 multimap的语义是它的每个Key值可以指向多个value, 在java的集合框架中并没有这种类型，事实上，这种主义的Map完全可以通过将值的类型设置为某种集合来实现，如Map&lt;String, List&lt;String&gt;&gt;. 因此，这种类型的map将不再被特殊讨论和对待. Comparable接口在进一步学习容器接口之前，有必要先了解下Comparable接口，顾名思义，这个接口定义了对象的比较属性，实现了这个接口的类就具备了可比较性，比较的语义由实现决定，在JAVA的实现中有很多类都实现了这个接口，比如String，按照字母顺序进行比较；Date类会按照时间顺序进行比较 Comparator接口这是另一个用来实现对象比较的接口，在一些集合类算法中，如果某些类对象没有实现comparable接口，在使用排序算法时，可以额外提供一个comparator接口来实现排序功能，事实上，comparator接口是一种策略模式的实现，策略模式的结构图如下: SortedSet接口SortedSet是一种set接口，但是它把元素按照升序进行排列，排序的规则由元素本身提供(自然排序)，前提是元素实现了Comparable接口，否则将返回类型转换错误; 如果元素没有实现comparable接口，也可以提供comparator接口，通过使用策略模式来进行排序SortedSet接口提供了几类操作：视图操作，端点操作以及获取内部使用的comparator的接口的操作 视图操作情况下，如果原来的集合中的元素被修改了，视图中的元素也会发生相应的变化，反过来也一样，也就是说，可以把视图当作集合的一个窗口，视图操作获取的元素只不过通过这个窗口能看到的原来的集合中的部分元素 端点操作默认是左闭右开区间，即包含头节点，但不包含尾节点，但可以通过在头节点或者尾节点后增加“\\0”来改变这种行为，如果头节点增加了这个标识，意味着头节点将不被包括在返回的集合中(左开区间），如果尾节点增加了这个标识，意味着它将会被包括在返回的集合中（右闭区间) SortedMap接口这个接口所有的操作和属性都和SortedSet一致，因此这里就略过不讲 在JAVA的集合框架中，提供了TreeSet来实现SortedSet接口 后续的学习集合框架的学习以源码分析为主，因为集合类的使用主要还是以接口类提供的方法为主，而每个集合类提供的接口完全可以由其特性猜出一二，不需要. 备注 具体的Sample代码可以参见这里 参考文档： 集合说明文档 系列文章： 集合系列文章","categories":[],"tags":[]},{"title":"java集合学习之通用接口2","slug":"集合/java集合学习之通用接口2","date":"2016-12-20T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/20/集合/java集合学习之通用接口2/","link":"","permalink":"http://yoursite.com/2016/12/20/集合/java集合学习之通用接口2/","excerpt":"","text":"java集合学习之通用接口2Collection接口collection接口定义了通用的集合操作，简单说来，可以分为： 增加操作: add, addAll, 往集合中增加相应类型的元素或者把另一个集合中的元素全部加到当前集合中 删除操作: remove, removeAll, clear, 删除集合中指定的元素或者删除出现在指定集合中的所有元素, 元素的相等通过equals方法来判断 查询: contains, containsAll, 判断集合中是否含有指定的元素或者是指定集合的超集, 元素的相等通过equals方法判断 size, isEmpty: 查询集合的元素个数 修改: retainAll, 保留指定集合中的所有元素, 可以认为是数学意义上集合的“交集”操作 遍历: iterator, 迭代器模式的应用，整个集合框架中都使用了相同的方式来进行遍历操作 转换: toArray，这个方法是集合类与数组类之间的桥梁，将集合类转化成相应的数组. 同时，这个方法也必须保证返回的数组能够被“安全”地使用，换句话说，如果返回的数组被修改了，也不能影响到原来的集合类. collection接口的操作相对简单，意义也非常明确，不存在理解上的难点. Comparable接口comparable接口只提供了一个方法，就是compareTo(T)， 所有实现了这个接口的类都是可以用来进行比较操作的. Comparator接口Comparator接口提供了compare方法，该方法接收两个参数，分别是用来比较的两个参数，对于那些没有实现comparable接口的对象来讲，comparator实现了“策略模式”, 让这些对象相互之间可以进行比较， 比如在调用sort方法的时候，如果用于排序的对象本身实现了comparable接口，就可以直接使用对象本身提供的compareTo方法进行比较，对于那些没有实现comparable接口的对象而言，可以在sort方法中提供一个comparator接口作为参数，从而通过“策略模式”完成排序. 示例代码 collection comparable comparator","categories":[],"tags":[]},{"title":"ReentrantReadWriteLock源码分析","slug":"多线程/juc/AQS框架/ReentrantReadWriteLock源码分析","date":"2016-12-16T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/16/多线程/juc/AQS框架/ReentrantReadWriteLock源码分析/","link":"","permalink":"http://yoursite.com/2016/12/16/多线程/juc/AQS框架/ReentrantReadWriteLock源码分析/","excerpt":"","text":"ReentrantReadWriteLock源码分析在之前的源码分析 中，ReentrantLock展示了排它锁的实现，而CountDownLatch和Semaphore则展示了共享锁的实现，接下来，我们要一起看看ReentrantReadWriteLock(RRWL)的源码，它同时实现了独占锁和共享锁，对于写操作而言，它是独占锁；对于读操作来讲，它是可共享的. 首先看下RRWL的结构，可以发现，它分别提供了readLock和writeLock, 分别用于实现读锁和写锁的相应功能，后续所有的操作也是委托给这两个锁对象进行操作；再进一步查看可发现，这两个锁对象都是由sync对象提供支持的，在RRWL内部提供了sync抽象类的两种实现，公平锁和不公平锁. 也就是说，和之前一样，sync类还是实现整个RRWL机制的关键，接下来就来看看它的具体实现。 1. Sync对象的内部结构 Sync对象将state变量分成两个部分，高16位作为共享锁的数量，低16位作为独占锁的数量， 这也是RRWL的读写锁最大支持65535（2^16-1)的原因. sync类还定义了HoldCounter和ThreadLocalHoldCounter内部类，前者定义了某个线程重入共享锁的次数，后者从名字上可以看出是线程私有的变量， sync定义了cachedHoldCounter变量（类型为HoldCounter）和readHolds变量（类型为ThreadLocalHoldCounter）, 分别用于记录最后一次成功获取读锁的holdCounter对象和线程私有的holdCounter对象. sync还定义了firstReader和firstReaderHoldCount, 用于记录第一个获取到共享锁的线程与它的重入次数. 2. 获取独占锁获取独占锁的逻辑为判断当前锁的状态，只有在可重入（当前线程拥有写锁）或读写锁均没有被占用的时候，才尝试获取锁 如果当前有读锁或者（当前有写锁且占用写锁的线程不是当前线程）， 直接返回. 如果当前线程拥有写锁，此时为重入，直接返回成功 当前没有读锁和写锁(state=0)， 判断是否应该阻塞（公平性策略，稍后提到），如果不需要阻塞，则尝试更新状态，状态更新成功则设置独占线程，写锁获取成功，否则获取独占锁失败 3. 释放独占锁由于同一时间只会有一个线程拥有独占锁，因此释放独占锁的操作不需要考虑并发的情况，释放逻辑也很简单，只要在确认调用该操作的线程为拥有写锁的线程的前提下，更改锁的state状态变量的值即可. 这里的逻辑与ReentrantLock重入锁的逻辑是一模一样的. 4. 获取共享锁获取共享锁的实现逻辑如下： 如果当前已经有线程占用写锁，且占用的线程不是当前线程，直接返回获取共享锁失败 尝试获取共享锁，如果获取共享锁成功，则进入计数器相关的操作 尝试获取共享锁失败，则进行fullTryAcquireShared的操作 4.1 尝试获取共享锁成功当尝试获取共享锁成功时，首先判断当前的线程是否为第一次成功获取读锁的线程（r==0）,如果是，则设置firstReader与firstReaderHoldCount的值; 如果不是, 则获取cachedHoldCounter变量，并判断是不是当前线程的holdCounter，如果不是，则从readHolds中重新获取. (这里使用cachedHoldCounter变量的作用是尽量减少map的查找，因为绝大部分情况下，下一次释放共享锁的线程就是上一次获取共享锁的那个线程. ), 然后把计数器加1并返回成功. 4.2 尝试获取共享锁失败如果尝试获取共享锁失败，则进行fullTryAcquireShared方法的操作. 这里的逻辑也可以分为三个部分： 如果当前已经有线程占用了写锁，且该线程不是当前线程，直接返回获取共享锁失败 如果公平策略中要求读线程要阻塞，则只有一种情况会继续获取共享锁，那就是重入操作，同样也可以分两种情况 当前线程是第一个获取共享锁的线程，直接进入获取锁的操作. 如果不是第一个获取共享锁的线程，则判断它的holdCounter的次数，只要不为0，说明这个是一次重入操作，则尝试获取锁; rh.count==0意味着这个是新的线程在尝试获取共享锁，由于需要保证公平性，则尝试获取共享锁失败. 如果公平策略不要求线程阻塞（即不需要保证公平性），则直接进入获取共享锁的操作 获取共享锁的操作，包括获取成功后更新计数器的操作都和之前的逻辑一样，这里不作赘述. 5. 释放共享锁释放共享锁的操作分为两个部分，首先是减少计数器，然后是通过for循环，不断地尝试更新state变量的值，直到成功为止. 逻辑相对比较简单，略. 6. 公平性RRWL的实现中，提供了公平性策略，在获取读写锁的时候，均可以设置公平性策略. FairSync和NonFairSync分别对应了公平锁和非公平锁的实现. 6.1 非公平的RRWL实现先来看看NonFairSync的实现. 可以看到，公平性是通过两个方法来提供的，writerShouldBlock和readerShouldBlock方法，对应写锁和读锁的获取时的公平性策略. 可以看到，在非公平的锁机制中，写锁是不需要阻塞的，也就是说，在尝试获取写锁时，可以马上尝试获取而不用阻塞等待，这就有可能造成后来的写锁获取请求比等待队列中的写锁获取请求更快拿到写锁，可能会造成写线程”饥饿”的情况. 而在获取读锁的过程中，虽然也是不公平的，但有一点需要保证，就是排队的首节点不是写请求，这样实现是为了防止写请求“饥饿”. 这里可细分为两种情况，一种头结点是写请求，那么后续的读请求都必须进行等待队列（除非是重入操作）另一种头结点是读请求，那么后续再进来的读请求会一直尝试获取读请求. 6.2 公平锁的实现公平锁的实现逻辑比较简单，在尝试获取锁（不论是共享锁还是独占锁）之前，先判断下当前的队列中是否已经有其它线程在排队等候了，如果有，直接进入自旋等待操作. 参考文献 http://www.cnblogs.com/leesf456/p/5419132.html http://brokendreams.iteye.com/blog/2250866 http://blog.csdn.net/yuhongye111/article/details/39055531 http://www.cnblogs.com/chenssy/p/4922430.html","categories":[],"tags":[]},{"title":"LockSupport与Condition的使用","slug":"多线程/juc/AQS框架/LockSupport与Condition的使用","date":"2016-12-16T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/16/多线程/juc/AQS框架/LockSupport与Condition的使用/","link":"","permalink":"http://yoursite.com/2016/12/16/多线程/juc/AQS框架/LockSupport与Condition的使用/","excerpt":"","text":"LockSupport与Condition的使用LockSupportLockSupport提供了线程阻塞与唤醒的原语操作(primitive)，它是JUC的锁机制的基础.每一个使用LockSupport的线程都有一个许可，在该许可可用的情况下，调用park操作会占用该许可，并直接返回, 否则将阻塞等待; 而其它的线程则可以通过unpark方法唤醒处于阻塞中的线程. ConditionCondition对象提供了和await, notify, nofityAll类似的功能，但是它要和Lock一起使用. 参考文献 http://cmsblogs.com/?p=1735","categories":[],"tags":[]},{"title":"CountDownLatch, Semaphore, CyclicBarrier源码解析","slug":"多线程/juc/AQS框架/CountDownLatch, Semaphore, CyclicBarrier源码解析","date":"2016-12-15T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/15/多线程/juc/AQS框架/CountDownLatch, Semaphore, CyclicBarrier源码解析/","link":"","permalink":"http://yoursite.com/2016/12/15/多线程/juc/AQS框架/CountDownLatch, Semaphore, CyclicBarrier源码解析/","excerpt":"","text":"CountDownLatch, Semaphore, CyclicBarrier源码解析java并发包下提供了AQS框架，使得锁的实现变得非常容易. 之前我们分析了ReentrantLock的源码（这里），我们知道这个是可重入的、公平性可选的独占锁. 简单回忆一下，在线程尝试获取锁对象时，RL底层会委托给sync对象进行处理，sync对象派生自AQS抽象类，并实现了AQS类中独占锁的两个方法, tryAcquire和tryRelease. 在获取锁的时候，如果锁被占用，则构建新的CLH队列节点并等待，直到其它的节点将它唤醒. 这里我们接着来分析java并发包中提供的另一种类型的锁，共享锁. 顾名思义，这种锁允许多个线程共同持有. 在并发包中，信号量semaphore和计数器(?). CountDownLatch的底层都是基于共享锁来实现的. 有了之前阅读独占锁源码的经验，我们还是直接从共享锁的具体实现入手. 这里以信号量为主进行分析. 1. 信号量信号量定义了同一时间最多能有多少个线程获取到锁，超过这个数量时，尝试获取线程的锁会进行等待. semaphore对象在初始化时，需要传入一个数量，这个数量意味着能同时获取共享锁的线程数量（也被称为是许可数量）. 这个数量最终被用来构造AQS类，并成为AQS类中state的初始值.事实上，每当有线程尝试获取共享锁时，semaphore就会把state变量的值减掉相应的许可数量，state数量为0意味着当前许可全部发放出去了，当前持有共享锁的线程数达到饱和，后续再有线程尝试获取共享锁时，就需要等待，直到其它的线程释放了许可. 2. 获取共享锁semaphore的实现与ReentrantLock重入锁保持了一致的风格，底层都是委托给sync对象. acquire方法调用了AQS抽象类的acquireSharedInterruptibly方法. 这个方法中首先判断线程是否被打断，然后尝试获取共享锁，如果获取共享锁失败（返回负值），那么将当前线程构建CLH节点后进入等待状态， 直到获取共享锁成功为止. semaphore的sync对象也提供了两种公平性支持， 公平锁和非公平锁. 这里以公平锁的实现为例. 在公平锁的实现中，尝试获取锁之前，首先调用hasQueuedPredecessors方法，判断是否有其它线程等待的时间超过当前线程，如果有，直接返回获取失败. 这样的机制保证了锁的公平性，等待时间越长的线程，在尝试获取锁时拥有越高的优先级. 这个方法中，h!=t意味着队列不为空，也就是目前已经有等待中的线程了. 而下一个条件判断目前队列的第一个节点是否为当前线程. 两个条件同时成立就意味着，目前等待的队列不为空，且第一个节点的线程不是当前线程，也就意味着当前已经有其它线程在等待了. 在公平性判断完成后，tryAcquireShared方法会判断当前可用的许可数量及申请的许可数量，如果数量足够就尝试获取，数量不够就直接返回. 非公平锁只要把公平性判断的逻辑移除就可以了，但在一些极端条件下，有可能会有导致线程饥饿的情况出现. 如果尝试获取共享锁失败，说明要么已经有优先级更高的线程，要么就是可用的许可数量不够了，那么尝试获取共享锁的线程进入排队等待逻辑， 这部分是通过doAcquireSharedInterruptibly方法实现的. 这个方法首先调用addWaiter方法构建新的CLH节点并进行入队操作（具体可参见独占锁关于这部分的描述这里，这里略），接着开始“自旋”的逻辑，也就是for循环的内容. 循环中的逻辑可以分为两个部分. 第一部分判断当前节点是否为头节点的下一节点, 这意味着当前节点是队列的首节点，可以继续尝试获取共享锁. 如果获取锁成功，则将释放信息往下传播；否则判断当前节点是否需要进入等待状态，并根据返回结果进行相应的处理. 如果当前节点是CLH队列的头节点，并成功获取到共享锁时，semaphore会调用setHeadAndPropagate方法将释放信息继续往下传播. 这个方法会将当前节点置为头结点，并通知下一个结点. 这也是共享锁和独占锁最大的区别，独占锁在同一时间只会有一个线程占用锁对象，因此在释放锁的时候，只需要唤醒后继节点即可，而共享锁需要将释放的信息由队列传播，这样队列中的节点才有可能同时获取到共享锁. 传播释放信息的代码在doReleaseShared方法中, 可以看到，这里判断头结点的状态是否为signal，是的话就将它重置成0后唤醒后继节点，如果是处于重置状态的头结点，则将它置为传播状态，以供后续传播使用.注意这里只会在头结点状态为signal的时候尝试将release信息传播给队列中的下一个结点，但它本身并不会去改变头结点的位置. 当release信息传播之后，会唤醒队列中的下一个结点，如果这个结点获取共享锁成功，才会调用上面的setHeadAndPropagate方法，这时候头结点的位置才会发生变化. 如果尝试获取共享锁失败，则会进行判断是否等待的逻辑. 这部分逻辑和RL重入锁部分的逻辑是一样的，都是根据前置节点的状态（CLH锁的特点）决定是否需要执行park操作. 3. 释放共享锁semaphore中关于释放共享锁的代码就是在上面说的doReleaseShared方法中实现的，上面已经讲过了，这里不再赘述. 4. CountDownLatch前面以信号量为例，讲解了java并发包中的共享锁的实现. CountDownLatch底层也是共享锁，只不过做了点小小地改动. CountDownLatch在构造函数中接受一个数值N作为参数，这个数值N也被当作是state的值，此时可以认为countDownLatch被N个对象共享. 当有线程调用countDown时，底层的实现其实是调用releaseShared释放一把共享锁，而调用await意味着尝试获取锁. 与一般共享锁不一样的地方是，在CountDownLatch的实现中，只有当N个对象都被释放后（即调用了N次countDown操作, state=0），获取共享锁的操作才会成功. 这也就意味着，调用了N次countDown之后，await方法才会返回. 这也是CountDownLatch作为计数器最常见的使用场景. 5. CyclicBarriercyclicBarrier也被称为是栅栏，它为多个线程协同操作提供了类似于“到达点”一样的功能，多个线程必须都到达代码中的某个时点后，才可以继续进行，否则必须等待其它线程的到达. 它的实现比较简单，底层是通过ReentrantLock重入锁和Condition对象实现同步，同时，它也可以作为学习Condition类的示例. 参考文献 http://www.infoq.com/cn/articles/java8-abstractqueuedsynchronizer http://www.cnblogs.com/zhanjindong/p/java-concurrent-package-aqs-AbstractQueuedSynchronizer.html 示例代码 https://github.com/Essviv/spring/blob/master/src/main/java/com/cmcc/syw/concurrency/lock/SharedLockTester.java","categories":[],"tags":[]},{"title":"AQS框架源码解析","slug":"多线程/juc/AQS框架/AQS框架源码解析","date":"2016-12-14T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/14/多线程/juc/AQS框架/AQS框架源码解析/","link":"","permalink":"http://yoursite.com/2016/12/14/多线程/juc/AQS框架/AQS框架源码解析/","excerpt":"","text":"AQS框架源码解析AQS类的全称是AbstractQueuedSynchronizer， 它的核心是通过维护一个名为state的整型变量和CLH队列（这里）， 子类通过修改状态变量的值来实现获取锁和释放锁的操作. AQS可以说是整个JUC并发包中的核心类，它是典型的模板模式应用（这里）， 同时，它也提供了实现Lock接口的基础. 事实上， JUC中的可重入锁(ReentrantLock)、可重入读写锁(ReentrantReadWriteLock)、信号量（Semaphore)以及栅栏（Barrier)等类的底层实现就是基于AQS类来完成的. 0. AQS实现概述查看整个AQS框架的源码可以发现，虽然整个类中定义了很多方法，但是绝大部分方法都是private或者final，这意味着这些方法都是无法被子类继承和重载的，整个模板类只定义五个方法供子类重写： tryAcquire: 定义了以独占方式获取锁的方法 tryRelease: 定义了释放独占锁的方法 tryAcquireShared： 定义了以共享的方式获取锁 tryReleaseShared: 定义了释放共享锁的方法 isHeldExclusivly: 判断当前锁是否被当前线程以独占的方式获取. 这五个方法默认的实现是抛出UnsupportedOperationException异常，子类可以根据需要选择相应的方法进行重写. 下面将以可重入锁（ReentrantLock）的实现为例对AQS类的源码进行阐述. 1. 可重入锁（ReentranLock, RL）可重入锁是一种排它锁（exclusive）， 当一个线程获取到锁对象后，其它的线程就无法再获取相应的锁对象. 这种锁是可重入的，意味着当一个线程可以多次获取锁对象，前提是它已经抢到这个锁了. 2. RL源码 —- Lock操作上面说到，RL的底层实现就是依赖于AQS模板类来实现的，查看RL的源码我们发现，它本身并不继承自AQS，但它定义了一个内部类Sync是AQS的子类. 我们还发现，RL中的方法都是调用了这个sync对象的相应方法完成的，因此这个sync对象应该就是阅读源码的重点. 以Lock接口的lock方法为例， RL中的实现调用了sync.lock()方法，而sync类的lock是个抽象方法，被它的两个子类实现（FairSync和NonFairSync）. NonFairSync的lock源码如下，在尝试获取锁对象时，它会尝试先调用AQS的comapreAndSetState方法来改变state状态变量的值(注意这里通过CAS机制保证了操作的原子性). 如果修改成功，意味着当前线程获取到了锁对象，将当前线程设置为独占线程后直接返回；如果修改失败，则调用AQS类的acquire方法，因为RL是独占锁，所以这里传入的参数值为1. AQS类的acquire方法实现如下，可以看到，这里首先尝试调用子类的tryAcquire方法，如果这个方法返回了true， 说明当前线程获取到了锁，直接返回，否则进入acquireQueued操作. 首先来看NonFairSync的tryAcquire实现： 它首先获取锁对象的状态，如果状态变量为0，说明此时没有线程在占用锁，则再次调用compareAndSetState方法设置状态变量的值，如果设置成功，说明当前线程获取到了锁对象，直接返回即可. 如果当前状态变量的值不为0，说明锁已经被占用了，则判断这个独占线程是否为当前线程（“重入”的体现），如果是，直接将state状态变量加上相应的状态值即可. 否则当前线程尝试获取锁失败. 如果tryAcquire方法返回false,说明尝试获取锁失败了，则进入acquireQueued的执行，这个方法主要的作用是实现CLH队列的“阻塞”操作. （CLH锁的内容可查阅这里 ) . 但值得注意的是，CLH锁是“自旋”锁，而acquireQueued方法里使用的是LockSupport类提供的“阻塞”锁机制. 从里往外看，addWaiter首先构建了一个新的等待节点， 接着判断队列的tail尾结点是否为空，如果它为空，意味着队列为空，则直接尝试入队操作, 入队成功直接返回，否则调用enq方法进行入队. 在enq方法中，通过for循环不断地轮询，如果tail结点为空，则初始化这个结点. 可以想像，当线程第一次尝试获取锁对象时会进入这个分支执行，然后初始化head与tail结点，而第二次进入for循环时，就会进入到else分支. 在这里会不断地尝试将新生成的node结点通过compareAndSetTail方法加到tail结点的末尾, 从而完成入队操作. 在enq方法返回后，addWaiter方法就返回了. 然后就会进入acquireQueued方法的执行. 这也是个死循环，每次进入循环后，都会首先判断当前节点的先驱节点是否为head节点，如果是，意味着已经轮到当前节点获取锁了（这里是“公平”锁的体现），于是开始尝试获取锁对象（tryAcquire的实现已经在前面说过了），获取成功则表示当前线程已经获取到锁对象，直接退出. 如果当前节点的先驱结点不是head结点或者尝试获取锁对象时失败, 意味着队列前面还有正在排队的结点，则进入shouldParkAfterFailedAcquire方法的执行. shouldParkAfterFailedAcquire方法的作用是根据先驱结点与当前结点的状态判断是否需要让当前线程进入阻塞状态. 如果先驱节点的状态是signal，则表示需要当前结点关联的线程需要被阻塞； 如果先驱节点的状态是cancel， 则跳过这些结点 否则设置先驱节点的状态为signal 可以看到，第一次进入这个方法的时候，先驱结点的状态为0，然后会被修改成signal，等到第二次进入的时候，就会直接返回true,意味着当前线程需要进入阻塞状态. 如果shouldParkAfterFailedAcquire方法返回true,那么就会进入parkAndCheckInterrupt方法的执行. 这个方法很简单，就是调用了LockSupport.park方法，让当前线程进入阻塞状态，直到有其它线程唤醒它为止. 到这里，整个lock方法已经完成了. 总结来讲，它的执行可以分为以下几步： 首先尝试调用compareAndSetState操作设置状态变量的值，设置成功能意味着获取锁对象成功，直接返回 进入acquire操作， 首先调用子类的tryAcquire方法尝试获取锁对象，获取到了直接返回成功 如果tryAcquire方法返回失败，则通过addWaiter创建新的CLH结点并将它入队. 入队完后调用acquireQueued方法进入阻塞操作，阻塞操作是通过LockSupport类的park来完成的. 在获取到锁对象之前，线程会一直处于阻塞、唤醒、尝试获取锁对象的过程中，直到获取锁对象成功. 3. RL源码 —- Unlock操作在第二小节中，我们提到在成功获取锁对象前，线程会一直处于阻塞、唤醒、尝试获取锁对象的过程中， 同时我们也知道线程是通过LockSuppot.park方法进入阻塞状态的，那么什么时候由谁去唤醒它呢？ 继续来看RL的unlock操作. 同样地，RL的unlock也是调用了sync中的release方法，由于RL是排它锁，同一时间只会有一个线程拥有锁对象，因此在release方法中不需要考虑并发的问题. 但作为重入锁，可能存在多次调用lock的情况，这时候只调用一次unlock并不一定意味着释放锁操作. 因此在release方法中调用了tryRelease方法. 在这个方法中，首先判断调用这个方法的线程是否是独占线程，如果不是直接抛出异常. 接着判断当前的状态变量在执行当前的释放之后是否为0，如果是0意味着锁对象被真正释放了，否则意味着当前线程继续持有锁对象. 当tryRelease返回true时说明锁对象被释放了，则调用unparkSuccssor，在这个方法，找到当前结点后的第一点状态不为cancel的结点，然后调用unpark方法来唤醒它. 到此，unlock方法完成. 4. 其它这里只是以RL为例，简单阐述了AQS框架的实现源码，事实上，在JUC中，除了RL， NonReentrantLock、Semaphore等等都是类似的实现思路, 可以通过类比的方式查看相应的源码，这里不做重复. 5. 参考文献 AQS框架概述1 AQS框架概述2 AQS源码浅析","categories":[],"tags":[]},{"title":"CopyOnWriteList和CopyOnWriteSet","slug":"多线程/juc/并发集合/CopyOnWriteList和CopyOnWriteSet","date":"2016-12-14T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/14/多线程/juc/并发集合/CopyOnWriteList和CopyOnWriteSet/","link":"","permalink":"http://yoursite.com/2016/12/14/多线程/juc/并发集合/CopyOnWriteList和CopyOnWriteSet/","excerpt":"","text":"CopyOnWriteList和CopyOnWriteSetCOWSet的底层是通过COWList实现的， 在写操作的时候，有选择性的选择addIfAbsent版本的操作. COWList的底层实现是通过ReentrantLock来实现的，所有的写操作执行前都必须先获取到相应的RL锁，然后再进行操作.","categories":[],"tags":[]},{"title":"CountDownLatch, CyclicBarrier和Semaphore的使用","slug":"多线程/juc/AQS框架/CountDownLatch, CyclicBarrier和Semaphore的使用","date":"2016-12-12T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/12/多线程/juc/AQS框架/CountDownLatch, CyclicBarrier和Semaphore的使用/","link":"","permalink":"http://yoursite.com/2016/12/12/多线程/juc/AQS框架/CountDownLatch, CyclicBarrier和Semaphore的使用/","excerpt":"","text":"CountDownLatch, CyclicBarrier和Semaphore的使用1. CountDownLatch实现类似于“计数器”一样的功能, 一般用于某个线程等待其它一些线程完成特定工作后开启后续工作时使用. 它最重要的方法是设置计数，计数减1， 等待计数结束， 分别对应于CountDownLatch, countDown以及await. 2. CyclicBarrier回环栅栏. 它的作用类似于在各个线程执行的某个点中增加一个栅栏，各个线程执行到这个点时，会等待其它线程， 当到达这个点的线程数满足预设的条件时，才会继续执行后续的操作. 它有以下几个特点： 它是可以重复利用的，也就是说通过前一个栅栏点时，这个对象可以被重复使用，这也是它被称为“回环”的原因 它是用来协调多个线程间的执行过程的，和countDownLatch不同的是，cdl是用于某个线程等待其它线程完成后执行特定操作，而cyclicBarrier是用于协调多个线程间的操作. 3. Semaphore信号量，可以理解成可同时被获取的信号总数. 使用semaphore的时候，一般是先设置相应的信号量，表示能同时能被获取的信号量，线程在进入临界区时，必须先获取一定的信号量，执行完后也必须释放相应的信号量，以便后续的线程能进入临界区. 比较常用的方法包括： acquire/release/tryAcquire, 具体方法的使用可以参考javaDoc 示例代码 gitHub代码","categories":[],"tags":[]},{"title":"模板模式","slug":"设计模式/模板模式","date":"2016-12-08T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/08/设计模式/模板模式/","link":"","permalink":"http://yoursite.com/2016/12/08/设计模式/模板模式/","excerpt":"","text":"模板模式","categories":[],"tags":[]},{"title":"等待通知机制","slug":"多线程/等待通知机制","date":"2016-12-06T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/06/多线程/等待通知机制/","link":"","permalink":"http://yoursite.com/2016/12/06/多线程/等待通知机制/","excerpt":"","text":"等待通知机制notify, notifyAll, wait这三个方法构成了java的等待通知机制的核心，它们主要是用于线程间通信时使用. 使用这三个方法的前提是当前线程必须拥有对象的锁 wait: 当前线程进入等待状态，直到其它线程调用了对象的notify或者notifyAll方法 notify：随机选取一个正在等待的线程唤醒 notifyAll：将全部等待的线程唤醒 使用notify, notifyAll和wait方法在使用时，必须获取到相应对象的锁才能使用，否则会抛出IllegalMonitorStateException异常. 在执行完wait操作后，当前执行线程会释放对象的锁，以等待其它线程调用该对象的notify或者notifyAll方法 wait与sleep的区别 在使用wait的时候， 线程必须拥有这个对象的锁，也就是说，wait方法调用必须出现在synchronize块中，类似地，notify/notifyAll也有这样的限制. sleep方法不需要出现在synchronize块中 wait/nofity/nofityAll方法是在对象上进行调用，而sleep方法是在线程对象上进行调用 在调用wait方法后，线程会释放持有的该对象锁（但不会释放其它锁），而sleep方法会一直持有对象锁，并不会进行释放 与Condition对象的区别参考文献 http://stackoverflow.com/questions/1036754/difference-between-wait-and-sleep","categories":[],"tags":[]},{"title":"Executors","slug":"多线程/juc/线程池/Executors","date":"2016-12-03T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/03/多线程/juc/线程池/Executors/","link":"","permalink":"http://yoursite.com/2016/12/03/多线程/juc/线程池/Executors/","excerpt":"","text":"ExecutorsExecutors是并发包中提供的工具类，它可以用来创建以下这些对象: ExecutorService ScheduledExecutorService ThreadFactory Callable 1. Executor接口首先先来看看并发包中的Executor接口的结构图. Executor接口只提供了一个方法，就是execute方法，它定义了执行Runnable对象， 至于以什么样的方式执行任务，执行任务的生命周期等其它方面的操作均没有涉及. ExecutorService在executor接口的基础上，增加了对执行任务生命周期的管理，也就是说，提交到executorService接口中执行的任务，可以通过提交任务时返回的future对象，判断任务是否已经执行结束，或进行取消操作. ExecutorService又可以进一步细分为AbstractExecutorService与ScheduledExeuctorService两大类，前者代表了ExecutorService的默认实现. 后者定义了定时操作的接口. 2. ThreadFactory这个接口提供了创建线程的方法， 避免显式地调用Thread对象的创建方法， Executors中提供了默认的线程工厂实现DefaultThreadFactory， 这个实现给每个创建的线程指定了特定的名称. 3. ExecutorService 和 ScheduledExecutorServiceExecutors提供了创建ExecutorService和ScheduledExecutorService的方法， 两种类型都可以分为两类，一种是创建线程池，一种是创建单个线程. 创建的过程很简单，就是调用相应的线程池实现的构造函数，根据不同类型传入不同的构造函数参数即可, 代码如下所示. 这里值得注意的是创建单个线程的代码. 以创建单个线程的executorService为例， 可以看到在构造完threadPoolExecutor对象之后， 又用FinalizableDelegatedExecutorService做了层封装, 这个类继承自DelegatedExecutorService, 而DelegatedExecutorService的作用就是封装底层的实现，只对外暴露ExecutorService接口的方法（这算是外观模式吗？）可以看到，通过这层封装，隐藏了底层的和线程池相关的一些操作，只对外暴露了executorService的API方法, 相当于是缩小了threadPoolExecutor对象的操作能力， 这种方式在一些用具体实现完成特定功能时会很有用（比如，单个线程的ExecutorService可以认为是通用线程池的特殊情况， 这时候就可以用线程池来实现单个线程的功能，但为了防止对外暴露过多的操作，就可以使用上述的方式进行包装，以达到隐藏线程池其它方法的功能） 4. CallableExecutors中提供的创建callable的方法都使用了RunnableAdapter类，从这个类的名字中就可以看出，这个类是适配器，它接受一个runnable和一个可选的返回值，然后将它们包装成一个Callable对象. 可以看到，Executors作为工具类，并没有实现太多新的功能，它只是对已有的一些功能进行包装，如果想要深入地了解线程池的实现，还是需要看看ThreadPoolExecutor的源码才行.","categories":[],"tags":[]},{"title":"netty源码学习系列----channelHandler","slug":"IO/netty/netty源码学习系列----channelHandler","date":"2016-12-02T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/02/IO/netty/netty源码学习系列----channelHandler/","link":"","permalink":"http://yoursite.com/2016/12/02/IO/netty/netty源码学习系列----channelHandler/","excerpt":"","text":"netty源码学习系列—-channelHandlerCodec FieldLengthBasedFrameDecoder","categories":[],"tags":[]},{"title":"netty源码学习系列-----eventLoop","slug":"IO/netty/netty源码学习系列-----eventLoop","date":"2016-12-02T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/02/IO/netty/netty源码学习系列-----eventLoop/","link":"","permalink":"http://yoursite.com/2016/12/02/IO/netty/netty源码学习系列-----eventLoop/","excerpt":"","text":"netty源码学习系列—–eventLoopnetty是如何实现对于某个channel的IO事件，交由同一个线程去处理?channel持有一个eventloop，后续所有的操作都会交由这个eventllop操作，具体是在每个操作前，判断一下当前的执行线程是不是eventloop，如果是，直接执行，如果不是，则将要执行的事情放到eventloop的执行任务队列中 参考文献 NioEventLoop的运行情况","categories":[],"tags":[]},{"title":"责任链模式","slug":"设计模式/责任链模式","date":"2016-12-01T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/12/01/设计模式/责任链模式/","link":"","permalink":"http://yoursite.com/2016/12/01/设计模式/责任链模式/","excerpt":"","text":"责任链模式责任链模式由两个重要组件组成，请求(指令的产生者)以及处理器(指令的处理者)。 这个模式在很多常用的框架中都可以找到踪迹，比如netty的channelHandler， Spring Security中的Filter等等。 简单来讲，请求产生后会在处理器链中按一定的顺序传播，每个处理器的逻辑分为两部分 判断是否能处理相应的请求 如果判断能处理到达的请求，则处理，否则继续“向下”传播(即责任器链上的每个节点都有它自己的责任) 它的UML图如下：Request接口代表了请求（或者说是指令的产生者），而handler接口代表了处理器（或者说是指令的处理器），每个处理器都有对链上相邻处理器的引用，当它自己不能处理到达的请求时 ，会将请求进一步传播给相邻的处理器. 以Netty中的channelHandler为例，它是用来channel中IO事件的处理器，当IO事件产生时，channel会将这个事件交给与之关联的channelPipeline，而channelPipeline事实上就是一组前后相连的channelHandler， IO事件沿着pipeline一直传播，直到被channelHandler处理或到达pipeline的末端. 另外，值得一提的是，虽然被称为是责任链，但请求在责任器链中的传播并不一定要是线形的，有些责任器可能会有类似于“分发”器一样在的功能，在这种情况下，责任器就会是“树形”的形状. 参考文献 http://www.oodesign.com/chain-of-responsibility-pattern.html https://en.wikipedia.org/wiki/Chain-of-responsibility_pattern 示例代码 https://github.com/Essviv/designPattern/tree/master/src/main/java/com/cmcc/syw/responsibility","categories":[],"tags":[]},{"title":"状态模式","slug":"设计模式/状态模式","date":"2016-11-29T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/29/设计模式/状态模式/","link":"","permalink":"http://yoursite.com/2016/11/29/设计模式/状态模式/","excerpt":"","text":"状态模式在学习nio编程的时候，遇到需要在不同的状态间进行转换，程序也需要根据不同的状态作不同的处理，搜了下相应的设计模式，果然发现有种叫”状态模式“的非常符合自己的需要，简单地做个记录 按照惯例，还是先上UML图，从图中可以看出， 状态模式有两个重要的组成部分，一个是上下文，也就是维护状态的地方；另一个则是状态，不同的状态决定了在同一个上下文中会执行不同的操作. 状态模式允许一个对象在其内部状态发生变化时改变其行为，就好像改变了一个类的实现一样. 举个例子，信用卡在银行进行开户后，默认是处于已激活的状态，当用户进行消费后，处于透支状态，如果用户消费的额度超过了银行给的额度，则信用卡处于被冻结状态，针对这三种状态下，银行对于用户刷卡这个行为要执行的操作是不一样的. 这里银行可以被当作是状态的上下文，而银行卡的状态决定了上下文执行的具体操作. 另外，在状态模式中，有个很重要的问题，就是状态的迁移，目前的实现中有三种方式， 由外部调用类来管理状态的变换: 要求外部调用类了解所有的状态，且在增加状态的时候，需要修改客户端代码，不推荐 完全由上下文类来管理状态的变迁： 状态对外部完全不可见，仅在上下文内部维护，在增加状态的时候，不需要修改客户端的代码，推荐 由状态类自己完全变迁： 状态类之间产生依赖关系 参考文献 http://blog.csdn.net/lovesomnus/article/details/45750039 https://sourcemaking.com/design_patterns/state","categories":[],"tags":[]},{"title":"spring-test","slug":"测试/spring-test","date":"2016-11-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/25/测试/spring-test/","link":"","permalink":"http://yoursite.com/2016/11/25/测试/spring-test/","excerpt":"","text":"spring-test使用spring进行单元测试使用spring对代码进行 单元测试 时， 同其它的pojo进行单元测试是一样的，不过spring对单元测试提供了一些工具类来帮助用户更方便地进行单元测试. ReflectionTestUtils: 反射相关的系列工具方法类, 可以用于改变常量的值，调用私有方法，访问私有变量以及调用生命周期函数等等 AopTestUtils: spring aop相关的一系列工具方法类 使用spring-test进行集成测试spring的单元测试只能对单个的对象进行测试，不能对整个web, 包括像路径映射，过滤器链等机制进行验证，因此spring-test又提供了关于集成测试的支持. 它对集成测试的支持主要通过MockMvc实现，构建这个对象时可以有两种模式，分别是 使用standaloneSetup模式： 这种模式可以指定某些对象，spring只会加载与这些对象有关的信息，同时用户也可以自定义整个容器的初始化过程. 同时，这种模式也可以mock一些对象，让客户专注于测试关心的那个对象 使用webAppContextSetup模式： 这种模式通过指定配置文件，加载整个web应用的信息，因此可以对整个应用的各个部分进行验证. 同时, spring-test提供了包括上下文缓存、事务管理、自动注入等支持 示例代码 https://github.com/Essviv/spring/tree/master/src/test/java/com/cmcc/syw/controller 参考文献 spring集成测试 spring-test的概念 spring-test的官方文档 IBM","categories":[],"tags":[]},{"title":"netty总览图-核心组件","slug":"IO/netty/netty总览图-核心组件","date":"2016-11-22T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/22/IO/netty/netty总览图-核心组件/","link":"","permalink":"http://yoursite.com/2016/11/22/IO/netty/netty总览图-核心组件/","excerpt":"","text":"netty总览图-核心组件netty核心概念关系图 Bytebuf: 对java nio中ByteBuffer的抽象 每个Channel代表了一种能够用于IO操作的实体，例如socket， 文件等等 每个channel都有一个pipeline, pipeline的作用是处于和这个channel相关的所有IO事件 每个pipeline中有一系列的channelHandler， 每个channelHandler是真实处理IO事件的地方， 并把这个事件沿着Pipeline传播. ChannelHandler可大体分为两类，一类是InboundHandler，也就是处理进来的消息的处理器，另一种则是OutboundHandler， 是用来处理出去的消息的. 每个channelHandler都有一个相关联的channelHandlerContext， 这个上下文的作用就是让channelHandler可以和它的pipeline以及其它的channelHandler之间进行交互. 每个channel都会被注册到EventLoop中, eventLoop会负责处理该channel的所有IO事件， 通常情况下，每个eventLoop会管理多个channel这里可以类比下NIO的编程，这里的EventLoop类似于带有selector组件的ServerSocketChannel， 它负责多个channel的IO事件. EventLoopGroup是eventLoop的集合，它管理着所有的eventloop的生命周期 参考文献 NIO教程 http://tutorials.jenkov.com/java-nio/index.html netty教程 netty源码解析系列","categories":[],"tags":[]},{"title":"IO中的阻塞、非阻塞、同步和异步的区别","slug":"IO/java基础/IO中的阻塞、非阻塞、同步和异步的区别","date":"2016-11-22T02:20:54.000Z","updated":"2017-03-28T00:45:54.000Z","comments":true,"path":"2016/11/22/IO/java基础/IO中的阻塞、非阻塞、同步和异步的区别/","link":"","permalink":"http://yoursite.com/2016/11/22/IO/java基础/IO中的阻塞、非阻塞、同步和异步的区别/","excerpt":"","text":"IO中的阻塞、非阻塞、同步和异步的区别IO相关概念 阻塞：在发起IO操作之后，线程被阻塞，直到相应的IO操作完成才会返回 非阻塞： 在发起IO操作之后，线程不会被阻塞并且立即返回 同步： 在发起IO操作之后，在没有得到结果之前，调用都不会返回（注意，这里不返回不代表就一定阻塞了，应用也可以处于非阻塞状态），调用一旦返回了，IO操作的结果也就得到了。换句话说，就是由调用者（或应用）主动等待IO操作的结果， Reactor模式就属性这种模式 异步： 在发起IO操作之后，应用程序直接返回，并不等待IO操作的结果，而是由被调用者（通常是系统）在IO操作完成后，通过通知、回调等方式告知应用程序。 Proactor就属性这种模式 从上面的定义可以看出，同步和异步的区别在于IO的调用方是否需要主动地等待数据，在同步操作中，应用需要主动将数据从系统内核空间拷贝到应用空间，并且在这个过程中会出现block状态；而异步操作中，应用调用完IO操作后，就可以执行其它的操作了，系统在将数据拷贝到应用空间完成后，通过回调和通知等方式告知应用，应用再开始对这些数据进行相应的处理. IO模型IO模型大体上可分为以下五类： 1.阻塞式IO(BIO) 2.非阻塞式IO(NIO) 3.多路复用 4.信息驱动（不常用，略） 5.异步IO(AIO) 它们之间的比较： IO模型图: 感觉这里的IO多路复用更应该属于“同步阻塞”，但不知道为什么这里被划分为异步阻塞 一个IO操作其实分成了两个步骤：发起IO请求和实际的IO操作。同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果实际的IO读写阻塞请求进程，那么就是同步IO。阻塞IO和非阻塞IO的区别在于第一步，发起IO请求是否会被阻塞，如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 参考文献 概念比较1： IO - 同步，异步，阻塞，非阻塞 （亡羊补牢篇） 概念比较2： 大话同步/异步、阻塞/非阻塞 AIO简介： AIO简介 BIO, NIO和AIO的理解： BIO, NIO和AIO的理解 这篇文章很详细地阐述了同步与异步、阻塞与非阻塞的区别: http://www.jianshu.com/p/55eb83d60ab1 比较reactor和proactor: 比较reactor和proactor","categories":[],"tags":[]},{"title":"Runnable, Callable, Future, FutureTask的区别","slug":"多线程/Runnable, Callable, Future, FutureTask的区别","date":"2016-11-22T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/22/多线程/Runnable, Callable, Future, FutureTask的区别/","link":"","permalink":"http://yoursite.com/2016/11/22/多线程/Runnable, Callable, Future, FutureTask的区别/","excerpt":"","text":"Runnable, Callable, Future, FutureTask的区别 Runnable是thread用来执行时指定的对象，它只包含有一个方法，run方法，这个方法没有返回值，且不会抛出异常信息. Callable和runnable一样，都是executor用来执行时指定的对象，它也包含一个方法，call， 但call方法是有返回值的，且会抛出exception异常. Future是executorService在提交完任务后，用于表示未完成的任务的一个对象，它可以用来取消任务、获取任务状态以及获取任务运行结果等操作. FutureTask是runnableFuture的一个子接口，而runnableFuture实现了Runnable以及Future接口， 同时，FutureTask还包含有callable或者runnable的实例，可以说，FutureTask是一个集合体，它既可以用在thread的运行中，也可以用在executorService的运行中，还可以用来控制任务的执行和取消等操作.","categories":[],"tags":[]},{"title":"JVM的内存回收","slug":"JVM/JVM的内存回收","date":"2016-11-18T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/18/JVM/JVM的内存回收/","link":"","permalink":"http://yoursite.com/2016/11/18/JVM/JVM的内存回收/","excerpt":"","text":"JVM的内存回收JVM的内存回收需要处理以下几个问题： 哪些内存是需要回收的 什么时候回收 怎么回收 1. 哪些内存需要回收对于第1个问题而言，在JAVA中，GC回收的主要对象是堆内存，这部分内存用于存储对象实例，当实例对象不再需要时，则需要对这部分内存进行回收. 2. 如何判断对象已死？判断对象是否已死解决的是“什么时候回收”的问题。目前判断对象已死的方法主要有两种， 一种是引用计数法，一种是根搜索算法; 引用计数法引用计数法就是记录每个对象的引用数量， 每次GC进行之前，依次轮询所有对象的引用计数，对于那些计数归零的对象，就成为GC的目标对象. 这个算法逻辑简单，但有个致命的缺点，没办法解决循环引用的问题，如下图所示, 图1表示正常的循环引用回收，图2表示循环引用的情况. 根搜索算法（也被称为是可达性分析）根搜索算法通过定义一系列的根对象，在GC开始之前，依次通过这些根对象往下标记，被引用到的对象会被标记为被引用，对于那些没有被标记引用的对象，就成为GC的目标对象. 从这个算法的描述中可知，这个算法依赖于预先定义的一系列根对象(GC Root). 在JVM的实现中，定义了以下对象为GC Root: 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI引用的对象 3. GC回收算法回收算法解决的是“如何回收”的问题. 当JVM根据一定的算法获取到哪些对象不再被引用时，就需要有一定的算法对它们进行回收， 目前比较常见的GC算法有以下几种: 标记-擦除算法（Mark-Sweep)： 首先标记所有不再需要的对象，然后一次性对这些对象进行擦除，被回收的内存可以被继续使用. 这种算法的优点是实现简单，缺点是标记和擦除算法的效率都不高，且容易产生内存碎片 标记-压缩算法(Mark-Compact): 首先标记所有不再需要的对象，然后将存活的对象移向一边，最后将剩余内存清空. 复制算法(Copying)：首先将内存分成相等的两部分，每次只使用其中一部分，当这部分内存被用完时，就将剩余的存活对象复制到另一部分上，然后将这部分内存直接擦除. 这个算法的优点是实现简单，运行高效，但致命的缺点是内存浪费严重（50%）。因此只适用于对于存活率比较低的场景，这种情况下，每次需要复制的对象就比较少，拷贝的效率就会很高. 分代收集算法： 严格来讲，这个不能称为是一种GC回收算法，它只是对不同的场景将前面三种回收算法做一种组合实现而已，不过由于它针对不同场景的特点选用了不同的回收算法，因此也是最有效的方式. 目前大部分的JVM实现中都会将堆内存进一步细分为 新生代 和老生代. 新生代的特点是存在大量的“朝生夕死”的对象，因此它特别适合使用“复制”算法. 具体实现”复制”算法时，又进一步将新生代细分为Eden区和两部分Survivor(from, to)区，两者的比例默认为8:1， 每次只使用Eden区和其中一块Survivor(from)区（意味着只浪费了10%的新生代内存空间）当Eden区内存用完时，会将Eden区以及Survivor(from)区中存活的对象复制到另一个Survivor(to)区，然后将Eden区与Survivor(from)区的内存擦除. 另外，由于我们无法保证每次回收时都只有不超过10%的对象存活，当Survivor(to)区不足以保存存活对象时，需要额外的空间进行担保（通常是老生代），如果触发了担保机制，那么这些存活的对象会直接进入老生代. 从新生代使用的”复制“算法的描述中可以看出，”复制“算法特殊适合于对象存活率较低的情况，而且，如果不想浪费50%的内存空间，就需要有额外的空间进行担保. 老生代的对象存活率较高，且没有额外的空间进行担保，因此不适合使用”复制“算法. 目前的JVM实现中，老生代基本上都是使用”标记-整理“算法. 4. GC收集器（GC算法的具体实现）不同的GC收集器是针对特定的内存区域（新生代、老生代）， 使用不同的GC回收算法（见第3节）， 以不同的模式运行（并发式、独占式），在运行的过程中会产生不同的线程数（单线程、多线程）. 以下关于不同的GC回收器的学习也会从这几个方面进行阐述. 新生代串行收集器: 新生代、复制算法、独占式、单线程(+XX:UseSerialGC(串+串)) 老生代串行收集器: 老生代、标记-压缩算法 、独占式、单线程(+XX: UseSerialGC（串+串）， +XX:UseParNewGC（并+串）) 并行收集器: 新生代、复制算法、独占式、多线程(+XX:UseParNewGC（并+串）, +XX:UseConcMarkSweepGC（并+CMS）) 参考文献 http://www.cnblogs.com/smyhvae/p/4744233.html http://coderbee.net/index.php/jvm/20131031/547 https://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/ https://plumbr.eu/java-garbage-collection-handbook http://www.cnblogs.com/highriver/archive/2013/04/17/3016992.html","categories":[],"tags":[]},{"title":"Reflection in Action","slug":"JVM/反射/Reflection in Action","date":"2016-11-16T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/16/JVM/反射/Reflection in Action/","link":"","permalink":"http://yoursite.com/2016/11/16/JVM/反射/Reflection in Action/","excerpt":"","text":"Reflection in ActionReflectionReflection is the ability of a running programme to examine itself and its software environment, and to change what it does depending on what it finds. MetadataTo perform this self-examination, a program needs to have a representation of itself. This information we call metadata. In an object-oriented world, metadata is organized into objects, called metaobjects. The runtime self-examination of the metaobjects is called introspection. In general, there are three techniques that a reflection API can use to facilitate behavior change: direct metaobject modification operations for using metadata (such as dynamic method invocation) intercession, in which code is permitted to intercede in various phases of program execution. Java supplies a rich set of operations for using metadata and just a few important interces- sion capabilities. In addition, Java avoids many complications by not allowing direct metaobject modification. class object getXXXs, getXXX, getDeclaredXXXs, getDeclaredXXX: 带declared的，是获取当前类声明的所有方法, 不论是public, protected, default还是private, 不带declared的，是获取类所有的public方法，包括在超类中声明的方法. 针对原生类型、接口以及数组，java也提供了相应的方法来表示相应的类型， class类也提供了isPrimitive, isInterface, isArray等方法来鉴别 原生类型(包括void)：通过形如int.class来表示, 可以通过class对象的isPrimitive来判断某个class是否代表原生类型. 接口类型: 通过形如Collection.class来表示，可以通过class对象的isInterface来判断某个class是否代表接口类型 数组类型: 通过形如int[].class或者int[][].class来表示，可以通过class对象的isArray来进行甄别，另外，数组中的元素类型可以通过getComponentType来获取. 类的层级关系也可以通过反射得到，在class类中声明了getSuperClass, getInterface, isAssignableFrom以及isInstance方法 getSuperClass返回的是当前类对象的直接父类 getInterfaces: 如果当前的类对象是Class，则返回它实现的接口类，如果当前的类对象是接口，则返回的是它的直接父接口列表 isAssignableFrom: X.isAssignableFrom(Y)意味着 a X field can be assigned from a Y field，也就是说 X和Y是同一个类 X是Y的超类 X是Y的超接口 isInstance: 反射中的instanceOf操作符，它的作用和instanceOf是一样的 field object getFields, getField, getDeclaredField, getDeclareFields：使用方法与区别与class中对应的方法一样，带declared的方法都是获取当前对应中的所有方法，不管它是private/default/protected/public. field继承自AccessObject, 同时实现了Member接口, member接口中定义了以下四个方法 getName: 获取成员的名称 getModifiers: 获取成员的修饰符, private/default/protected/public, static, final等等 getDeclaringClass: 获取声明当前成员的类 isSynthetic: 标识当前成员是否是由编译器引入的. Modifier类提供了判断修饰符的方法， 它提供了11种修饰符的判断，同时，它的toString方法会输出修饰符的文字. 可以通过modifier判断Member接口返回的getModifier值，得到对应的修饰符信息 当某个属性为数组对象时，特别是原生对象的数组时，不能将它转化为Object[]. JAVA中提供了Array工具类对数据对象进行操作，它的主要操作包括getLength, get/set以及newInstance. 动态加载和反射构造动态加载主要是通过Class.forName来完成的，结合返回构造的方式(Class.newInstance)，可以在运行时期指定相应的类名，从而动态地改变应用的功能. 动态加载与反射构造还可以应用于设计模式中，例如外观模式、抽象工厂等模式中，通过动态加载，可以实现外观的动态加载，从而为程序提供动态地变更外观实现提供可能；与此类似，抽象工厂结合动态加载，可以实现动态地构建不同的对象；关于这部分内容，具体可参见书本的第六章.动态加载中，Class.forName需要接受类的全限定名，针对数组，均是由左方括号([)开始，并结合单个类型代码来指定，具体可查阅JVM文档. 反射构造可以通过两种方式来完成，Class.newInstance和构造函数对象Constructor. Class.newInstance: 相当于调用了类的无参数构造函数，也就是说X.class.newInstance = new X(); Contructor: 构造函数也是类的元数据对象，可以通过Class.getConstructor()并指定参数类型来获取指定的构造函数, 对于非静态的内部类，第一个参数必须显示指定为外部类的类对象(具体见javadoc) Java中的动态代理Proxy, InvacationHandler(implementation and delegation) 查看堆栈状态new Throwable()会带有一系列的堆栈对象，每个堆栈对象StackTraceElement中会含有相应的类名、方法名、文件名以及行号信息.","categories":[],"tags":[]},{"title":"JVM的虚拟机栈","slug":"JVM/JVM的虚拟机栈","date":"2016-11-16T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/16/JVM/JVM的虚拟机栈/","link":"","permalink":"http://yoursite.com/2016/11/16/JVM/JVM的虚拟机栈/","excerpt":"","text":"JVM的虚拟机栈虚拟机栈是线程的私有内存，栈中的元素被称为栈帧， 方法被调用时，就会往线程的虚拟机栈中压入新的栈帧，栈帧中包含有方法调用的相关信息，如局部变量表（包含方法参数和方法体内定义的局部变量）、操作数栈、方法返回信息等；栈顶的栈帧代表了当前正在被调用的方法，当方法返回时，栈顶的栈帧元素被弹出，从方法的调用到返回对应了栈顶元素的入栈到出栈的过程. 栈桢结构虚拟机栈中是由栈桢组成的，方法的每次调用到退出的过程对应了栈桢在虚拟机栈中的入栈到出栈的过程，当前正在被执行的方法对于栈顶的栈桢，也被称为是当前栈桢. 栈桢中包含了方法运行所需要的全部信息，主要包括局部变量表、操作数栈、动态链接以及方法出口信息等， 如下图所示 1. 局部变量表局部变量表包括方法参数以及在方法内部定义的局部变量（由于栈桢元素是线程私有的，因此如果某个方法只依赖于方法参数和局部变量的话，那它一定是线程安全的） 局部变量表是以变量槽（slot）为最小单位，JVM并没有指明每个slot占用的内存大小; 在方法执行的时候，虚拟机是通过局部变量表完成方法参数值到参数变量的传递，对于非静态方法(static）来讲，第一个槽存放的是this变量，然后是方法参数的值，接着是方法内部定义的局部变量的值 2. 操作数栈通常会听到有人说“JAVA是基于栈的执行引擎”, 这里说的栈就是操作数栈. 它是一个“后进先出” （LIFO）的栈结构， 栈中的元素为操作数，虚拟机的操作指令都是针对操作数栈中的元素来进行的。在方法刚开始执行的时候，操作数栈是空的，随着方法的执行，虚拟机会将操作指令的操作数入栈，然后执行相应的指令，再从栈中读取数据（出栈）. 例如, iadd指令是对两个操作数进行加操作，在执行这条指令的时候，虚拟机会将要相加的两个操作数进行入栈操作，然后执行iadd, iadd会将栈顶的两个元素进行相加后再将结果进行入栈. 3. 动态链接动态链接的作用是，每个栈帧都会包含指向运行时常量池中当前栈帧对应的方法的引用. 持有方法的引用 是为了支持动态链接（？） 4. 返回地址当方法被执行时，返回的方式有两种： 一种是正常的操作指令退出， 一种是因为程序异常（不管是虚拟机异常还是未捕获异常）导致的程序退出; 不管是何种方式退出， 程序都会返回到调用该方法的位置；程序退出的过程相当于栈桢出栈的过程，因此可能的操作包括恢复上层方法的局部变量表和操作数栈、把返回值压入上层调用方法的操作数栈中以及恢复程序计数器的值等","categories":[],"tags":[]},{"title":"JVM的内存模型","slug":"JVM/JVM的内存模型","date":"2016-11-16T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/16/JVM/JVM的内存模型/","link":"","permalink":"http://yoursite.com/2016/11/16/JVM/JVM的内存模型/","excerpt":"","text":"JVM的内存模型JVM中的内存管理1. 程序计数器这部分内存是线程私有的，它是用来记录当前线程执行的字节码的位置. JVM在这部分内存中没有定义任何错误类型 2. 虚拟机栈这部分内存也是线程私有的，线程每调用一个方法，都会往相应的虚拟机本中push一个栈桢（栈桢的内容包括局部变量，操作栈，方法出口信息等），当方法返回时，虚拟机栈就会pop相应的栈桢. 在线程执行的过程中，方法的调用和返回对应了虚拟机栈中的入栈和出栈的过程. JVM在这部分定义了两种异常： StackOverflowException: 当栈深度超过JVM规定的深度时，就会引起栈溢出异常 由于方法的局部变量表在编译的时候就已经确定，因此栈桢的大小也就确定了，如果JVM无法申请足够的内存创建栈桢时，则会抛出OutOfMemoryException 3. 堆内存这部分内存是JVM中最大的一部分内存，它是所有线程共享的，同时也是GC管理的主要区域；它主要是用于存储对象实例. 堆内存可进一步细分为： Eden区(E区）, Survivor From（S1区）, Survivor To(S2区）, Old区（O区），将内存分代管理主要是为方便GC管理，这部分会在后续和GC算法进一步阐述 JVM在这部分定义了OOM异常，如果在这部分无法申请新的内存来存储实例时，则会抛出OOM异常 4. 方法区方法区主要用于存储已加载的类信息，静态变量，常量以及JIT生成的代码等内容. 它也被称为是Non-Heap区（非堆） 5. 常量池Class文件中除了类的版本、方法表等内容外，还包括了在编译时期就已经确定的常量表，常量表的这部分内容在类加载后就被存储于常量池中 6. 本地方法栈本地方法栈与虚拟机栈是非常类似的，但是它存储的是native方法的信息. 同样，在本地方法栈中，JVM也定义了两种异常信息，OOM与StackOverflowException, 其含义与虚拟机栈类似. 内存分代管理与回收算法 参考文献 InfoQ 内存模型1 内存模型2（这个文章里有关于内存模型的明晰的示意图） 内存模型3 内存模型4 内存模型5 内存模型6 内存模型7","categories":[],"tags":[]},{"title":"JVM分析工具","slug":"JVM/JVM分析工具","date":"2016-11-14T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/14/JVM/JVM分析工具/","link":"","permalink":"http://yoursite.com/2016/11/14/JVM/JVM分析工具/","excerpt":"","text":"JVM分析工具JVM常用的分析工具包括： jps, stat, jmap, jstack, jinfo, jvisualvm jps列出当前运行的JVM进程，可以通过参数-m -l列出其main方法以及线程ID等信息 jinfojinfo主要是用于查询与设置当前JVM进程的参数值的，它可以实现运行时查看和修改JVM参数的功能. jstat列出某个JVM进程的内存统计信息，它的子命令包括（具体可查阅参考文献1， 每个子命令的输出字段的含义可查阅参考文献2） -gc: 堆内存的GC相关信息的统计数据 -class: 类加载信息的统计数据 -gcnew: 新生代的内存统计数据 -gcold: 老生代的内存统计数据 -gccapacity: 堆内存的大小统计数据， 包括新生代、老生代等 -gcnewcapacity: 新生代的大小统计数据 -gcoldcapacity: 老生代的大小统计数据 -gccause: 引起gc操作的原因的统计数据 -gcutil: gc的统计数据 jstack查看JVM的堆栈信息 jmap查看JVM的堆快照信息，也可以通过-dump命令将当前的堆快照信息输出到指定的文件. jvisualvm从这个名字可以看出，它其实就是将之前五个命令的输出进行了可视化显示. 应该来讲，只要掌握了前五个命令的使用，自然就掌握了jvisualvm的使用. 参考文献 Oracle document center JVM常用工具分析","categories":[],"tags":[]},{"title":"代理模式","slug":"设计模式/代理模式","date":"2016-11-10T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/10/设计模式/代理模式/","link":"","permalink":"http://yoursite.com/2016/11/10/设计模式/代理模式/","excerpt":"","text":"代理模式代理模式的关键点在于代理类与被代理类在客户端看来是“相同”的，不管这种“相同”是通过继承还是接口来定义 代理模式的UML 代理模式的实现 静态代理: 静态代理指的是在程序运行前，代理类与委托类之间的代理关系就已经确定了，它们的字节码在运行就已经存在 动态代理：动态代理是指在程序运行的过程中，动态地生成指定类的代理类，并增加一些额外的实现逻辑， 根据实现方式，动态代理又可以进一步分为 继承方式实现(cglib) 与 接口方式实现(JAVA原生支持） 动态代理的实现1. JAVA原生方式JAVA原生方式实现动态代理主要涉及到两个类, Proxy和InvocationHandler， 每一个proxy实例都有一个关联的invocationHandler，所有对proxy实例的调用最终都会委托到相关联的invocationHandler的invoke方法中调用, 具体的调用时序图如下： JAVA原生方式实现的动态代理示例代码如下： 从上面的示例代码中可以看出，原生方式实现的动态代理必须有一个前提： 委托类必须实现接口，否则无法通过这种方式进行代理. 2. CgLib的方式实现动态代理cglib使用asm动态生成字节码，因此在使用cglib时需要增加asm的依赖. 另外，cglib使用了继承的方式来实现动态代理，因此 委托类不能声明成final，否则无法通过cglib进行代理 cglib实现动态代理主要涉及到两个类，Enhancer和MethodInterceptor. Enhancer可以同时支持继承超类和实现接口两种方式来生成动态代理类， 通过设置超类和回调接口(Callback)可以实现与Proxy与InvocationHandler一样的效果. MethodInterceptor是最常用的回调接口， 它可以认为是一种AroundAdvice， 也是拦截器的一种实现， 它只有一个方法intercept， 可以在这个方法中定义相应的代理实现逻辑. 除此之外，cglib还提供了CallbackFilter接口，它是用来匹配方法与callback接口的接口，可以为不同的方法定义不同的回调实现. cglib实现的动态代理示例代码如下： 总结 JAVA原生的动态代理实现是基于接口的方式，因此被代理的类必须实现接口，否则无法通过这种方式实现动态代理 CgLib是通过继承方式实现动态代理，因此被代理的类不能是final. 另外，由于它是在字节码层面进行动态代理，因此依赖于asm库 不管是JAVA原生方式还是cglib方式实现动态代理，可以看出实现的思路均是通过回调或者拦截的方式修改被代理方法的实现逻辑来完成的（implementation and delegation） 动态代理模式也是实现框架最重要的一种模式，它也是spring框架中aop, 事务控制等特性的基础 代理模式与装饰器模式的区别在于，代理模式关注于对象的访问，而装饰器模式更关注动态地增加功能；另外，代理模式中代理类与被代理类的代理关系一般在编译时就已经确定，而装饰器模式的目标对象可以在运行时指定. 参考文献 http://wiki.jikexueyuan.com/project/java-reflection/java-dynamic.html 示例代码 代理模式与装饰器模式的区别","categories":[],"tags":[]},{"title":"适配器模式","slug":"设计模式/适配器模式","date":"2016-11-09T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/09/设计模式/适配器模式/","link":"","permalink":"http://yoursite.com/2016/11/09/设计模式/适配器模式/","excerpt":"","text":"适配器模式适配器模式的实现可分为两种， 一种称为类适配器，一种称为对象适配器 1. 类适配器UML图如下， 适配器通过实现目标接口（Target)，并通过组合的方式获取被适配对象（adaptee）的实例，从而实现适配，这种方式相对来讲更加灵活： 它不仅可以适配被适配接口(adaptee)，还可以适配被适配接口的子类（adaptee的子类）; 如果子类有需要，可以重写被适配接口的某些方法，依然可以被正常适配 虽然UML图中只给出了一个被适配对象，事实上适配器可以适配多个接口，从而实现目标接口. 适配器模式的关键点不在于它适配了多少个接口，而在于它通过提供适配器，将原来旧的接口适配到了新的接口上，与数量无关. 推荐使用这种方式实现适配器模式 2. 对象适配器UML图如下，这是适配器模式的第二种实现，它是通过实现目标接口(target)，并继承被适配对象(adaptee2)实现的. 它的优缺点如下： 实现方式简单，可以很方便地对被适配对象(adaptees)的方法进行重写. 只能适配被适配器对象(adaptee2)，无法适配被适配器对象的子类；如果子类对被适配器进行了重写，则需要重新实现适配器对象(adapter) 不推荐使用这种方式实现适配器模式 参考文献 http://design-patterns.readthedocs.io/zh_CN/latest/structural_patterns/adapter.html https://sourcemaking.com/design_patterns/adapter 示例代码示例代码","categories":[],"tags":[]},{"title":"外观模式","slug":"设计模式/外观模式","date":"2016-11-09T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/09/设计模式/外观模式/","link":"","permalink":"http://yoursite.com/2016/11/09/设计模式/外观模式/","excerpt":"","text":"外观模式","categories":[],"tags":[]},{"title":"参观者模式","slug":"设计模式/参观者模式","date":"2016-11-07T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/07/设计模式/参观者模式/","link":"","permalink":"http://yoursite.com/2016/11/07/设计模式/参观者模式/","excerpt":"","text":"参观者模式双重分派机制参考文献 http://blog.csdn.net/lovelion/article/details/7433567 http://blog.csdn.net/chenssy/article/details/12029633","categories":[],"tags":[]},{"title":"享元模式","slug":"设计模式/享元模式","date":"2016-11-07T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/11/07/设计模式/享元模式/","link":"","permalink":"http://yoursite.com/2016/11/07/设计模式/享元模式/","excerpt":"","text":"享元模式","categories":[],"tags":[]},{"title":"反射-构造函数","slug":"JVM/反射/反射-构造函数","date":"2016-10-30T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/30/JVM/反射/反射-构造函数/","link":"","permalink":"http://yoursite.com/2016/10/30/JVM/反射/反射-构造函数/","excerpt":"","text":"反射-构造函数构造函数与方法信息都有个共同的基类，Executable类，这个类中定义了以下几个构造函数和方法共有的方法： getParameterTypes: 按构造函数（或方法）参数的声明顺序，返回相应的参数类型信息 getParameterCount: 返回构造函数（或方法）参数的个数 getParameters: 返回构造函数（或方法）的参数列表 getDeclaringClass: 返回声明这个对象的类信息 getExceptionTypes: 返回构造函数（或方法）声明的异常信息 构造函数代表了类的构造函数信息，其最主要的作用是可以通过它在运行时构建类的实例： newInstance: 接受可变参数，代表构造函数的参数","categories":[],"tags":[]},{"title":"反射-类信息","slug":"JVM/反射/反射-类信息","date":"2016-10-30T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/30/JVM/反射/反射-类信息/","link":"","permalink":"http://yoursite.com/2016/10/30/JVM/反射/反射-类信息/","excerpt":"","text":"反射-类信息反射可以在运行时获取类、方法以及属性的信息 通过反射，可以在运行时获取类各方面的信息，包括类名信息、包信息、修饰符、超类信息、接口信息、方法信息、属性信息、构造函数以及注解等信息. 类名信息getName, getSimpleName(不包含包名信息), getCanonicalName, getTypeName getName返回的名称一般是用于Class.forName，用来动态地加载类信息 getCanonicalName返回的名称一般是用于import操作中，也可用于日志输出 getSimpleName不包含包信息 包信息包信息被封装在Package类中，通过这个类可以获取包信息，比如包名等 修饰符修饰符是用一个整形数字来表示，可以通过Modifier来进行解析， 包括private/protected/public, native, static, synchronized等信息 超类信息通过getSuperClass获取，获取的也是Class对象，同样可以通过反射机制获取其相应的信息 接口信息通过getInterfaces获取，注意这里只获取这个类显式声明实现的接口，对于它的超类中声明实现的接口信息，通过这个方法是无法返回的, 需要通过递归的方式来获取完整的接口信息. 方法信息通过getMethods或者getDeclaredMethods来获取，前者获取类所有的方法，包括在超类中声明的方法，后者则只会获取在当前类中声明的方法， 包括public/protected/default/private. 构造函数信息 通过getConstructors或者getDeclaredConstructors()来获取，其中getConstructor获取到所有public构造函数列表，而getDeclaredConstructors则可以获取到所有的构造函数，包括public/protect/default/private的构造函数 如果知道构造函数的参数类型及顺序， 可以通过getContructor来获取指定的构造函数. 可以通过构造函数对象初始化该类的实例, newInstance 属性信息 getFields或者getDeclaredFields来获取，两者的区别与前面相同 通过getField方法，可以指定属性名称来获取相应的属性Field对象. 获取到Field对象后，可以对get/set设置相应实例的值 注解信息getAnnotations或者getDeclaredAnnotations来获取，两者的区别与前面的相同. 注意，这里只能获取到那些Retention = RetentionPolicy.RUNTIME的注解，也就是只能获取到运行时注解. ##参考信息 http://stackoverflow.com/questions/15202997/what-is-the-difference-between-canonical-name-simple-name-and-class-name-in-jav","categories":[],"tags":[]},{"title":"反射-属性信息","slug":"JVM/反射/反射-属性信息","date":"2016-10-30T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/30/JVM/反射/反射-属性信息/","link":"","permalink":"http://yoursite.com/2016/10/30/JVM/反射/反射-属性信息/","excerpt":"","text":"反射-属性信息Field代表了属性信息，可以是类属性，也可以是实例属性 属性中定义了以下方法： getType: 获取属性的类型信息 实现了Member接口： Member接口中定义了getName, getDeclaringClass, getModifier和isSynthetic方法 get/set方法：在实例上获取/设置这个属性的值 getByte/getInt/getFloat/getString: 获取属性的值，返回指定的类型，同样，也有一系列的set方法","categories":[],"tags":[]},{"title":"反射-方法信息","slug":"JVM/反射/反射-方法信息","date":"2016-10-30T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/30/JVM/反射/反射-方法信息/","link":"","permalink":"http://yoursite.com/2016/10/30/JVM/反射/反射-方法信息/","excerpt":"","text":"反射-方法信息方法与构造函数一样，都是继承自Executable类，关于Executable类提供的方法信息可以参见构造函数 方法特有的方法信息： invoke: 传入相应的参数，并在实例上调用该方法 getReturnType: 返回返回参数的类型信息","categories":[],"tags":[]},{"title":"JAVA中的引用类型","slug":"JVM/JAVA中的引用类型","date":"2016-10-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/25/JVM/JAVA中的引用类型/","link":"","permalink":"http://yoursite.com/2016/10/25/JVM/JAVA中的引用类型/","excerpt":"","text":"JAVA中的引用类型 强引用(Strong Reference)是指平时经常用到的引用类型，如果某个对象存在强引用，那么它将不会被GC回收 软引用(Soft Reference)是指那些有用但不是必需的对象，它经常被用作缓存，当JVM内存充足时，它不会被GC回收，但如果内存不足时，它会被回收；它可以和引用队列(ReferenceQueue)进行关联，当软引用被回收时，它就进入关联的引用队列 弱引用(Weak Reference)是指不是必需的引用，在GC开始的时候，不管内存是否充足，它都将被回收；它可以和引用队列（ReferenceQueue)相关联，当弱引用被回收时，它就被加入到相关联的引用队列中 虚引用(Phantom Reference) 并不影响对象的生命周期，如果一个对象和虚引用关联，那么就跟没有和引用关联一样，它随时可能被GC回收，它必须和引用队列相关联，当GC某个对象时，如果发现它还有虚引用，则会把它加入到相应的引用队列中，可以通过判断虚引用是否出现在这个引用队列中，来确定该对象是否被回收 参考文献 参考文献","categories":[],"tags":[]},{"title":"常见的Web安全问题","slug":"安全/常见的Web安全问题","date":"2016-10-14T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/14/安全/常见的Web安全问题/","link":"","permalink":"http://yoursite.com/2016/10/14/安全/常见的Web安全问题/","excerpt":"","text":"常见的WEB安全问题1. XSS跨站脚本攻击， 解决方式就是对所有的用户进行转义编码，永远不要相信用户的输入 2. CSRF跨站请求伪造，原理图如下. 解决方式是给每个请求增加攻击者无法猜测的随机量，在接收到请求时，先校验这个随机量的有效性. 3. 固定session攻击会话固定攻击. 攻击者先登录欲攻击的网站，获取该会话的session, 并把获取到的session做为登录链接的一个参数，将构造的链接发给无辜的用户，用户点击链接登录成功后，在会话过期之前，攻击者就可以使用该session进行操作，获取登录用户的所有权限.解决方式是登录成功后，给用户重新发放一个session，废弃登录时的session. 4. 越权访问 横向越权：访问链接中带有一些ID标识，比如prdId = 5等等，攻击者就可以通过更改ID编码访问其它用户的资料，解决方式是尽量避免从前端获取相应的ID，如果无法避免，必须在后台增加相应的判断 纵向越权： 攻击者获取需要更高访问权限的链接，直接访问，解决方式是通过安全框架进行统一权限控制 5. 文件存储文件存储最主要的问题有几个， 限制文件大小，避免允许用户上传不限大小的文件 用户上传文件的目录要关闭相应的执行权限，毕竟用户上传的文件内容是不可知的 6. 短信轰炸、邮件轰炸对于短信验证码这类会给用户下发短信、邮件等操作，允许通过验证码、限制次数等方式进行人机实验，确定发起操作的不是攻击脚本，避免攻击者通过脚本短时间内发起大量操作，给用户造成困扰. 7. XFS跨框架攻击，通过iFrame的隐藏特性，在正常操作的背后隐藏相应的iFrame，执行一些不可告人的操作, 防御的措施是在web服务器上配置相应的策略","categories":[],"tags":[]},{"title":"Flyway","slug":"工具/Flyway","date":"2016-10-11T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/11/工具/Flyway/","link":"","permalink":"http://yoursite.com/2016/10/11/工具/Flyway/","excerpt":"","text":"FlywayFlyway的命令包括： migrate: 将DB升级到最新的版本 clean: 清空数据库中所有的数据，注意这条命令只能在集成环境或测试环境中执行，严禁在生产环境中执行 info: 显示当前所有升级脚本的执行情况，显示pending、fail或者是success validate: 检查当前的升级脚本的情况，包括： 之前升级过的脚本是否被修改 所有的升级脚本是否被执行 baseline: 对于已经有数据（包括结构和数据）的数据库而言，可以通过baseline命令进行基线处理，在定义了基线后，后续所有的升级都只会针对大于基线版本的升级脚本进行另外，值得注意的是，定义成基线版本的那个脚本不会被运行，原因是基线版本就是定义目前数据库中已经有的数据和结构，不需要再次执行. 当需要新建另一个数据库时，可以直接运行基本版本生成相应的数据. repair: 在升级出现错误的情况下，flyway会在meta-table中产生一条错误信息，通过repair命令可以将这条消息删除，然后继续运行相应版本的升级脚本 flyway支持多种运行模式，可以通过commandLine、java、maven插件等方式运行. 参考文档 https://flywaydb.org/documentation/","categories":[],"tags":[]},{"title":"HashMap","slug":"集合/HashMap","date":"2016-10-10T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/10/集合/HashMap/","link":"","permalink":"http://yoursite.com/2016/10/10/集合/HashMap/","excerpt":"","text":"HashMap哈希表使用的是 数组加链表的方式存储元素，具体如下： 通过hash(key)与数组长度运算，hash(key)&amp;(length-1), 获取新元素在数组中的位置 如果数组中该位置上没有元素，那么新元素直接被放置在这个位置 如果数组中该位置上已经有元素，那么新元素被放在以这个元素开始的链表上, 进入第2步 遍历链表上的所有元素，比较hash值与key值，只有两者都相同的情况下，才认为找到相应的位置，如果该位置上有值了，则可以选择替换或不进行操作； 如果一直到链表的末尾都没有找到相应的元素，则在链表末尾添加相应的元素. 查找哈希表中的元素时，过程与上面大致相同，不做进一步描述.","categories":[],"tags":[]},{"title":"WSDL","slug":"SOA/WSDL","date":"2016-10-04T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/04/SOA/WSDL/","link":"","permalink":"http://yoursite.com/2016/10/04/SOA/WSDL/","excerpt":"","text":"WSDLWSDL中包含以下几类元素 抽象元素： types: WS定义的类型，通过这种方式，WS可以最大限度的实现平台的中立性 message: WS的消息， 可以理解成传统函数中的输入输出参数 portType: WS执行的操作, 可以理解成传统函数库的一个模块或一个类， 也可以认为是接口定义 具体定义元素： binding: WS使用的通信协议， 定义消息的格式和通信细节，注意这里只是定义了协议与通信细节，并没有与具体的地址绑定 service: WS定义的服务，它将之前的绑定与实际的地址相关联，完成服务接口的完整定义. WSDL的结构12345678910111213&lt;definitions&gt; &lt;types /&gt; &lt;message /&gt; &lt;portType /&gt; &lt;binding /&gt; &lt;service /&gt;&lt;/definitions&gt; binding元素在这个例子中，portType元素把定义了端口的名称， 还定义了四个操作的名称. 相对于传统的函数库来讲，MathInterfce是函数库，而Add是输入参数为AddMessage，而输出参数为AddMessageResponse的函数. 其它的操作与此类似. 而service元素将MathInterface接口绑定到了http://localhost/math/math.asmx 这个地址. 参考文档 微软关于WSDL的说明 IBM关于WSDL中绑定类型的说明 示例代码 http://blog.csdn.net/onlyqi/article/details/7013893 cxf、axis2与spring-ws的比较 客户端自动生成代码调用 自行编码调用 疑问 怎么发布？: 1)jaxws:endpoint 2) java-ws发布 怎么获取WSDL: 直接在WS地址的后面加上?wsdl即可 绑定类型与编码类型 客户端方式与SOAP方式的区别 JAVA自带API与Axis2, cxf的api使用","categories":[],"tags":[]},{"title":"maven","slug":"工具/maven","date":"2016-10-04T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/04/工具/maven/","link":"","permalink":"http://yoursite.com/2016/10/04/工具/maven/","excerpt":"","text":"Maven生命周期maven中将整个项目构建抽象成一系列的生命周期，具体每个周期的实现交由插件实现，这点可以参照设计模式中“模板方法”的实现. maven的生命周期分为三套：clean， default以及site， 分别对应于清理、构建以及建立项目站点三个环节. 不同的生命周期又可以进一步划分为不同的阶段(phase)，在同一个生命周期内，后面的阶段依赖于前面的阶段. 不同的生命周期不会相互影响. e.g. clean周期包括pre-clean, clean和post-clean三个阶段，如果调用了clean:clean阶段，则clean:pre-clean和clean:clean都会被调用. 生命周期的不同阶段maven中三个不同的生命周期又可以进一步划分为不同的阶段. clean: pre-clean, clean, post-clean default: 校验，初始化、编译、测试、打包、集成测试、安装、部署 validate, initialize, generate-source, process-source, generate-resource, process-resource, compile, process-classes, generate-test-source, process-test-source, generate-test-resource, process-test-resource, test-compile, process-test-classes, test, prepare-package, package, pre-integration-test, integration-test, post-integration-test, verify, install, deploy site: pre-site, site, post-site, site-deploy 常见的插件 http://www.infoq.com/cn/news/2011/04/xxb-maven-7-plugin/","categories":[],"tags":[]},{"title":"maven学习笔记","slug":"工具/maven学习笔记","date":"2016-10-04T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/04/工具/maven学习笔记/","link":"","permalink":"http://yoursite.com/2016/10/04/工具/maven学习笔记/","excerpt":"","text":"Maven学习笔记构件的坐标groupId, artifactId, version 管理依赖通过构件的坐标来唯一指定123456&lt;dependency&gt; &lt;groupId&gt;&lt;/groupId&gt; &lt;artifactId&gt;&lt;/artifactId&gt; &lt;version&gt;&lt;/version&gt; //快照版本： SNAPSHOT &lt;scope&gt;&lt;/scope&gt; //可取值包括: compile, runtime, provided, test, system(不常用) &lt;/dependency&gt; 间接依赖 ===&gt; 依赖冲突 路径最短 1A ==&gt; B ==&gt; C(V1.0)（selected) A ==&gt; D ==&gt; E ==&gt; C(V2.0) 声明优先 1A ==&gt; B ==&gt; C(V1.0) (selected) A ==&gt; D ==&gt; C(V2.0) 生命周期和阶段（抽象概念， 具体实现由指定的插件目标决定）生命周期 clean: pre-clean, clean, post-clean default: process-resources, compile, process-test-resources, test-compile, test, package, install, deploy site: pre-site, site, post-site, site-deploy 阶段同一个周期内的阶段按顺序执行，不同周期的阶段没有先后顺序关系 mvn clean: 执行clean周期的pre-clean, clean两个阶段 mvn clean test: 执行clean周期的pre-clean， clean， 然后再执行default周期的process-resources, compile……test mvn clean package: 执行clean周期的pre-clean, clean，然后再执行default周期的process-resources … package 插件生命周期定义的阶段均为抽象的概念，具体的操作由插件目标来实现，maven为一些关键的阶段定义了默认的插件目标 默认绑定： maven-clean-plugin: clean ===&gt; clean 自定义绑定： 将指定坐标的构件的A目标绑定到test阶段 123456789101112131415&lt;plugin&gt; &lt;groupId&gt;&lt;/groupId&gt; &lt;artifactId&gt;&lt;/artifactId&gt; &lt;version&gt;&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; //指定绑定的阶段 &lt;goals&gt; &lt;goal&gt;A&lt;/goal&gt; //定义插件的目标 &lt;/goals&gt; &lt;/execution&gt; &lt;/excutions&gt;&lt;/plugin&gt; 聚合和继承聚合: 一次性构建多个项目123456789&lt;groupId /&gt;&lt;artifactId /&gt;&lt;version /&gt;&lt;packaging&gt;POM&lt;/packaging&gt; //聚合项目的打包方式必须为POM&lt;modules&gt; &lt;module /&gt; //第一个被聚合的项目 &lt;module /&gt; //第二个被聚合的项目&lt;/modules&gt; 继承继承的目的是为了减少重复的配置，子项目会从父项目中继承相应的配置，如果有必要，子项目也可以重写一些配置属性 1234567891011121314父POM： &lt;groupId /&gt; &lt;artifactId /&gt; &lt;version /&gt; &lt;packaging&gt;POM&lt;packaging&gt; //父工程的打包方式也必须为POM子POM &lt;artifactId /&gt; &lt;parent&gt; &lt;groupId /&gt; &lt;artifactId /&gt; &lt;version /&gt; &lt;relativePath&gt;&lt;/relativePath&gt; //父POM的路径 &lt;/parent&gt; 多环境构建： 基于属性, filter和profile实现, 通过${}访问属性 自定义属性: JAVA POM属性: ${project.baseDir}, ${project.artifactId}, ${project.build.sourceDirectory} filter资源过滤： 解析资源文件中的Maven属性 123456&lt;resources&gt; &lt;resource&gt; &lt;directory /&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt; profile针对不同的环境采用不用的属性, 命令行激活， 如： -Pdev 12345678910111213141516171819&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;msg&gt;hello world&lt;/msg&gt; &lt;/properties&gt; &lt;activation&gt; &lt;activateByDefault&gt;true&lt;/activateByDefault&gt; //默认启用的profile &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;msg&gt;Holy god!&lt;/msg&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 约定大于配置（Convention Over Configuration）1234src/main/java, src/main/resources, src/test/java, src/test/resources 参考文献 maven实战 机械工业出版社 许晓斌","categories":[],"tags":[]},{"title":"Jaxws和jaxrs","slug":"SOA/Jaxws和jaxrs","date":"2016-10-02T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/10/02/SOA/Jaxws和jaxrs/","link":"","permalink":"http://yoursite.com/2016/10/02/SOA/Jaxws和jaxrs/","excerpt":"","text":"Jaxws和jaxrsjaxws这是一个api规范，需要提供相应的运行时实现. 不过J2se中提供了jaxws的参考实现（jaxws-ri) @WebService, @WebMethod wsimport自动生成客户端代码 调用服务端的方法 实现了jaxws规范的框架包括： cxf, axis2 jaxrs用于更方便地创建RESTful服务的api, 它也是一个api规范，也需要提供运行时实现，j2se中并没有提供相应的实现，不过可以自行根据需要添加. jersey是jaxrs的参考实现. @Path, @GET/@PUT/@POST/@DELETE @PathParam, @QueryParam, @HeaderParam, @CookieParam, @MatrixParam @Consumes, @Produces, @ApplicationPath @Context, @NotNull, @Email 实现了jaxrs规范的框架包括： cxf, jersey","categories":[],"tags":[]},{"title":"mockito","slug":"测试/mockito","date":"2016-09-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/09/25/测试/mockito/","link":"","permalink":"http://yoursite.com/2016/09/25/测试/mockito/","excerpt":"","text":"mockito 调用自己的方法: doReturn(sth).when(xxx).somemethod() 返回列表中的元素: when(obj.method()).thenAnswer(AdditionalAnswers.returnsElementsOf()); 抛出异常: doThrow().when(someObject).someMethod(). 创建mock对象的方式: @InjectMock, @Mock 在verify的时候 次数可以通过以下的方式指定 ：times()/never()/atLeastOnce()/atLeast()/atMost() 另外，执行的顺序，可以通过InOrder来指定, 也可以通过createStrictMock来创建顺序有关的mock对象 12345InOrder obj = inorder(obj); obj.verify(methodA); obj.verify(methodB); * 执行的时间可以通过timeout来指定 自定义mock操作可以通过Answer接口来实现 部分mock(partially mock)可以通过spy或者doCallRealMethod来实现.1doCallRealMethod().when().someMethod() 参考文献 教程： http://www.w3ii.com/en-US/mockito/default.html 部分mock: http://heipark.iteye.com/blog/1496603 中文教程: http://blog.csdn.net/bboyfeiyu/article/details/52127551 http://blog.csdn.net/sdyy321/article/details/38757135 示例代码 https://github.com/Essviv/spring/tree/master/src/test/java/com/cmcc/syw/service/impl","categories":[],"tags":[]},{"title":"hashMap和concurrentHashMap的区别","slug":"多线程/hashMap和concurrentHashMap的区别","date":"2016-09-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/09/24/多线程/hashMap和concurrentHashMap的区别/","link":"","permalink":"http://yoursite.com/2016/09/24/多线程/hashMap和concurrentHashMap的区别/","excerpt":"","text":"hashMap和concurrentHashMap的区别 线程安全concurrentHashMap是线程安全的，而hashMap不是 同步机制hashMap执行操作时并不会执行同步，但可以通过Collections.synchronizedMap(hashMap)来得到一个与Hashtable等同的对象，对于这个对象的所有操作都会获取整个map的锁concurrentHashMap将整个map分成16个部分（默认），每次进行操作时，都只会获取其中一个部分的锁，从而同时允许多个线程进行操作 NULL值concurrentHashMap的键和值都不允许是null, 而hashMap可以有一个null键 性能hashmap的性能最好，因为它不会执行任何同步操作，而concurrentHashMap的性能略差一些","categories":[],"tags":[]},{"title":"WebService相关概念","slug":"SOA/WebService相关概念","date":"2016-09-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/09/24/SOA/WebService相关概念/","link":"","permalink":"http://yoursite.com/2016/09/24/SOA/WebService相关概念/","excerpt":"","text":"WebService相关概念webService的分类, 大体上可以分成以下三类： SOAP+WSDL(jaxws规范) REST(jaxrs规范) XML-RPC WebService的实现方式包括SOAP、REST和XML-RPC. XML-RPC也是我们通常说的RPC，已逐渐被SOAP替代 WebService与SOA的关系SOA全称是Service Oriented Architecture， 面向服务的架构. 因此可以这么理解，这是一种软件组织方式，不同的组件使用webService对外提供相应的服务，供其它组件进行调用. WS可以认为是SOA的一种实现方式，反过来说，SOA并不一定需要通过WS来实现. WebServices are self describing services that will perform well defined tasks and can be accessed through the web. Service Oriented Architecture (SOA) is (roughly) an architecture paradigm that focuses on building systems through the use of different WebServices, integrating them together to make up the whole system. 开源框架 jaxrs的实现: jersey, cxf, RESTeasy jaxws的实现： cxf, axis2 备注 axws和jaxrs都是规范，它依赖于具体的实现，在j2se中包含了jaxws的参考实现(jaxws RI), 不包含jaxrs的参考实现(jersey) 在jaxws的情景中，每一个服务都会对应于一个service， 而相应的代理被称为PORT， 在进行客户端编码时，一般是通过wsimport自动生成相应的代码，然后先获取相应的service，再由service获取相应的port，然后调用相应的方法即可. 以下这段话可能会对理解这些概念有所帮助. 在部署的时候，都是由web.xml为入口进入到webapp中，再由相应的servlet进行匹配（CxfServlet），再根据定义的服务地址进行处理. 参考文献 关于jax-ws和jax-rs的描述 SOA与WebService XML-RPC与SOAP http://www.cnblogs.com/lanxuezaipiao/archive/2013/05/11/3072436.html J2ee turtorial","categories":[],"tags":[]},{"title":"JAVA中的多线程基础知识","slug":"多线程/JAVA中的多线程基础知识","date":"2016-09-21T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/09/21/多线程/JAVA中的多线程基础知识/","link":"","permalink":"http://yoursite.com/2016/09/21/多线程/JAVA中的多线程基础知识/","excerpt":"","text":"JAVA中的多线程基础知识Thread 继承Thread对象 实现Runnable接口 线程的Sleep和Interrupt当需要挂起当前线程时，可使用Sleep方法进行挂起， 在挂起期间，可以使用interrupt方法进行中断，对于中断的处理取决于程序的实现，线程的中断状态通过Thread对象内部的成员变量进行标识，可以使用isInterrupt和interrupted两个方法进行判断，这两个方法的区别可以参阅javadoc的说明。 Join当调用join方法时，当前的线程会进入等待状态，直到被调用join方法的线程执行结束，例如，调用t.join()后，当前线程会一直等待，直接进程t执行完成，当然，等待的过程也可以通过interrupt来进行中断。 如果在主线程中执行以下的操作，有一点值得注意的是，当执行t1.join时，主线程会等待t1线程执行完毕，但这个操作并不影响t2线程的继续执行. 换句话说，执行t1.join之后，主线程等待，而t2线程仍然在执行. 1234t1.start();t2.start();t1.join();t2.join(); 锁类型对象锁和类锁是独立的， 在方法上加synchonized获取的是对象锁，而在静态方法上加synchronized获取的是类锁，两者可以同时被不同的线程获取到; 另外，对方法加synchronized可以认为是对代码块加synchronized的一种简便方式，具体请参阅“synchronized关键字解析”一文 如果某个线程已经拥有了某个锁，那么其它的线程就不能再拥有这个锁;但是这个线程本身可以再次获取这个锁，也就是重入锁机制(reentrant lock) 原子操作以下两种操作可以认为是原子操作，另外cocurrency包中也提供了一些原子类型 对所有引用类型及大部分原生类型的读写操作是原子性的 对所有声明为volatile的变量的读写是原子性的（包括double, long) 多线程中常见的问题 死锁： 线程A获取了对象M的锁，并试图获取对象N的锁；同时，线程B获取了对象N的锁，又试图获取对象M的锁；根据锁机制，线程A和B会同时被阻塞进入等待状态，并且这种等待是不会停止的，因此称为死锁 饥饿： 如果某个线程（A）长期的占用某个对象锁，而另一个线程（B）又需要频繁地调用这个对象的另一个同步方法，那么很有可能这个线程（B）会被经常地阻塞，这种状态就称作饥饿 活锁： 线程A需要响应线程B的事件，而线程B又需要响应线程A的事件，这样它们两个线程虽然没有被阻塞，却一直忙于响应对方的事件从而没办法往下继续 wait操作调用了对象的wait操作之后，当前线程（A）就自动释放对象锁，并处于等待状态；当另一个线程（B）获取到该对象锁并调用notifyAll通知正在等待该锁的所有线程，当前线程（A）会重新获得对象锁，并进行一些相应的操作，相应的例子可参阅这里的“生产者-消费者”的实现 不可变对象 不对外提供任何set方法 所有的成员变量都声明成private和final， 声明成private是不允许从外部进行访问和修改，声明成final是不允许从内部进行修改 将类声明成final，以此来防止子类继承并重写类方法 如果成员变量中有引用，应在构造函数中避免直接存储外部提供的引用，应该使用深拷贝的方式来创建新的对象并存储; 同样，当返回内部引用对象时，应避免直接返回内部对象，而应该通过拷贝对象返回 具体可参考http://docs.oracle.com/javase/tutorial/essential/concurrency/imstrat.html","categories":[],"tags":[]},{"title":"消息发布的确认","slug":"消息队列/rabbitMQ/消息发布的确认","date":"2016-09-13T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/09/13/消息队列/rabbitMQ/消息发布的确认/","link":"","permalink":"http://yoursite.com/2016/09/13/消息队列/rabbitMQ/消息发布的确认/","excerpt":"","text":"消息发布的确认在RMQ中，消息发布的确认有两种方式，一种是AMQP标准的方式，一种是RMQ扩展的方式 1. 事务机制通过事务的机制来保证每次消息的发布是成功的，如示例代码所示, 但这个方法最大的不足是它必须等待broker处理完后才能继续，导致这种方式的效率非常低，大概比没有启用事务要低250%左右。 123channel.txSelect();channel.basicPublish();channel.txCommit(); //or channel.txRollback(); 2. 确认机制除了事务机制外，RMQ还提供了一种确认机制，它通过broker的确认来实现。通过将通道切换成confirm模式来进行确认，如下代码所示，它的效率要比事务机制高得多 123channel.addConfirmListener();channel.confirmSelect();channel.basicPublish(); 3. 确认机制和事务机制不能同时使用4. 消息确认的时机对于无法路由到任何队列的消息来讲，它将直接进行确认，对于可以路由的消息来讲，直到所有的队列都接收到消息后才会进行消息确认；对于持久化队列来讲，接收到消息意味着持久化已经完成或者已经被全部消费；对于镜像队列而言，接收到消息意味着所有的镜像队列都已经收到相应的消息，如下图所示.由于RMQ内部是通过批量序列化的方式来进行持久化的，因此对于持久化队列而言，消息确认的延迟可能会非常长 参考文档 消息发布的确认 消息发布确认的介绍","categories":[],"tags":[]},{"title":"策略模式","slug":"设计模式/策略模式","date":"2016-09-10T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/09/10/设计模式/策略模式/","link":"","permalink":"http://yoursite.com/2016/09/10/设计模式/策略模式/","excerpt":"","text":"策略模式策略模式最重点的特点是完成一个任务的方法有多种策略，客户端可以根据需要选择合适的策略来进行. 不同的策略间可以相互替换, 典型的应用包括排序、搜索等实现 它的UML图如下： 策略模式与模板模式的区别从模板模式的UML图中可以看出，模板模式定义了方法的模板实现 ，而将一些修改化的实现方式通过抽象方法的方式委托给相应的子类来实现.","categories":[],"tags":[]},{"title":"mybatis中的批量操作","slug":"数据库/mybatis中的批量操作","date":"2016-08-30T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/08/30/数据库/mybatis中的批量操作/","link":"","permalink":"http://yoursite.com/2016/08/30/数据库/mybatis中的批量操作/","excerpt":"","text":"mybatis中的批量操作1. 语法mybatis中关于批量操作的支持主要来自foreach标签，foreach支持的属性包括以下几点： collection: 集合的变量名称， 类似于JAVA的for循环中的集合 item: 循环变量的名称，类似于JAVA的for循环中的临时变量名称，后续可以这个变量名称访问到每次循环的变量对象 index: 循环变量的下标 open: 循环开始前，在开始增加的表达式 close: 循环结束后，在末尾增加的表达式 seperator: 每个循环之间要增加的表达式 12345678910111213141516举例： where id in &lt;foreach collection=&quot;records&quot; item=&quot;record&quot; open=&quot;(&quot; close=&quot;)&quot; seperator=&quot;,&quot;&gt; #&#123;record.id&#125; &lt;/foreach&gt;解析这段表达式得到的结果为： where id in (id1, id2, id3,……)在这里，open属性指定在循环开始前增加左括号, close属性指定在循环结束后增加右括号，而seperator指定在每次循环间增加逗号，因此形如上面的表达式 2. 操作利用mybatis的foreach标签可以实现批量操作，主要分为： 2.1 批量插入123456789101112131415161718192021例子1： insert into table(col1, col2, col3) values &lt;foreach collection=&quot;records&quot; item=&quot;record&quot; seperator=&quot;,&quot;&gt; (#&#123;record.col1&#125;, #&#123;record.col2&#125;, #&#123;record.col3&#125; ) &lt;/foreach&gt;解析为： insert into table(col1, col2, col3) values (record1.col1, record1.col2, record1.col3), (record2.col1, record2.col2, record2.col3), (record3.col1, record3.col2, record3.col3)注意这里的左右括号不能通过open和close属性进行指定，因为open和close属性指定的是在整个循环开始和结束后要增加的表达式，而批量插入操作需要在每次循环表达式前后加上括号，错误代码示例如下： 12345678910111213141516171819例子2： insert into table(col1, col2, col3) values &lt;foreach collection=&quot;records&quot; item=&quot;record&quot; seperator=&quot;,&quot; open=&quot;(&quot; close=&quot;)&quot;&gt; #&#123;record.col1&#125;, #&#123;record.col2&#125;, #&#123;record.col3&#125; &lt;/foreach&gt;解析为： insert into table(col1, col2, col3) values (record1.col1, record1.col2, record1.col3, record2.col1, record2.col2, record2.col3, record3.col1, record3.col2, record3.col3) 2.1.1 批量插入自动生成ID在使用mybatis时，如果是插入单条记录时，可以使用useGeneratedKeys和keyProperty属性来获取新增记录的自增ID，如果在批量插入时也需要获取所有新增记录的自增ID，则需要满足以下两点: mybatis的版本不低于3.3.1， 从这个版本开始，mybatis才支持批量插入记录时获取记录的自增ID 入参的集合名称必须取名为“collection”、“list”、“array” 1234567891011&lt;insert id=&quot;batchInsert&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot;&gt;insert into table(col1, col2, col3) values &lt;foreach collection=&quot;list&quot; item=&quot;record&quot; seperator=&quot;,&quot;&gt; (#&#123;record.col1&#125;, #&#123;record.col2&#125;, #&#123;record.col3&#125; ) &lt;/foreach&gt;&lt;/insert&gt; 2.2 批量更新利用mybatis来实现记录的批量更新操作时，需要区分两种情况： 所有记录更新成相同的值 所有记录更新成不同的值 2.2.1 更新成相同的值这种情况相对来讲比较简单，只要对单个更新操作稍微做点修改即可完成, 示例代码如下： 123456789101112131415161718192021222324update table set col1 = #&#123;value1&#125;, col2 = #&#123;value2&#125;where id in &lt;foreach collection=&quot;ids&quot; item=&quot;id&quot; open=&quot;(&quot; close=&quot;)&quot; seperator=&quot;,&quot;&gt; #&#123;id&#125; &lt;/foreach&gt;====&gt; update table set col1=#&#123;value1&#125;, col2=#&#123;value2&#125;where id in (id1, id2, id3...) 2.2.2 更新成不同的值这种情况下，对于不同的记录需要对某些字段更新不同的值. 这里主要利用了mysql中的case/when/then子句的功能来实现， case/when/then的语法可参见这里. 利用mybatis实现这个操作的语法如下： 1234567891011121314151617181920212223242526272829303132333435update table set col1 = CASE &lt;foreach collection=&quot;records&quot; item=&quot;record&quot; close=&quot;ELSE `col1` END&quot;&gt; WHEN id = #&#123;record.id&#125; THEN #&#123;record.col1&#125; &lt;/foreach&gt;where id in &lt;foreach collection=&quot;records&quot; item=&quot;record&quot; open=&quot;(&quot; close=&quot;)&quot; seperator=&quot;,&quot;&gt; #&#123;record.id&#125; &lt;/foreach&gt;====&gt;update table set col1 = CASE WHEN id = #&#123;record1.id&#125; THEN #&#123;record1.col1&#125; WHEN id = #&#123;record2.id&#125; THEN #&#123;record2.col1&#125; WHEN id = #&#123;record3.id&#125; THEN #&#123;record3.col1&#125; ELSE `col1` ENDwhere id in (id1, id2, id3) 这里有几个需要说明的地方： close属性的值： 由于 case的语法指定，如果某个记录不符合任何一个when的情况，会默认把它的相应属性设置为null， 因此这里需要加上else子句，来保证在不符合任何一个when的情况，保留原字段的值 where子句： 指定更新的范围是指定的记录范围 参考文档 http://zacard.net/2016/02/18/mybatis3-multiple-rows-write-bace-id/","categories":[],"tags":[]},{"title":"Cookie的属性","slug":"Web/Cookie的属性","date":"2016-08-26T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/08/26/Web/Cookie的属性/","link":"","permalink":"http://yoursite.com/2016/08/26/Web/Cookie的属性/","excerpt":"","text":"Cookie的属性Cookie在WEB开发中具有重要的意义，它有以下的属性，现解析如下： secure： 当secure=true时，表示该cookie只能通过安全通道（即https）传输给服务器端， 当通道为http时，这个cookie不会由浏览器传输回服务器端; 通过这个标识，能保证cookie不会经由不安全的通道发往服务器端，意即在传输的过程中是保证安全的；但是，在浏览器端仍然可以看到cookie的值，如果需要也可以对cookie进行加密处理 path: 表示在访问哪些路径时，客户端必须把这个cookie传输回服务端. 如果设置了cookie的path属性为/contextPath/A， 那么当访问/contextPath/A以及所有它的子目录时，浏览器都会自动带上这个cookie; 相反地，如果访问的是/contextPath/B, 那么浏览器就不会带上这个cookie domain: 功能和path类似，但它指定的是域名范围的地址 expire: 设置cookie的有效期","categories":[],"tags":[]},{"title":"Spring学习之IoC","slug":"spring/spring-ioc-2","date":"2016-07-12T13:45:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/07/12/spring/spring-ioc-2/","link":"","permalink":"http://yoursite.com/2016/07/12/spring/spring-ioc-2/","excerpt":"","text":"配置细节 由于配置文件中提供的参数类型都是string类型的，而实际的参数类型有可能是任何类型，因此两者之间必然存在相应的转化，这是通过ConversionService来完成的. p命名空间可以很方便地通过属性来指定属性值 c命名空间可以用来很方便地通过属性指定构造函数的参数值 depends-on可以用来显式地指定依赖关系，在使用bean之前，它所依赖的所有bean都必须完成初始化操作. 如果需要表达对多个bean的依赖关系，可以通过逗号，分号以及空格分隔. 1234&lt;bean id=&quot;beanOne&quot; class=&quot;ExampleBean&quot; depends-on=&quot;manager,accountDao&quot; /&gt;&lt;bean id=&quot;manager&quot; class=&quot;ManagerBean&quot; /&gt;&lt;bean id=&quot;accountDao&quot; class=&quot;x.y.jdbc.JdbcAccountDao&quot; /&gt; 默认情况下，容器在初始化时，会默认初始化所有的singleton对象，这样如果这些对象的配置有问题，在容器初始化的时候就会被及时发现，而不是等到容器运行了很长时间后才被发现。如果希望容器在需要使用单例对象时才生成相应的单例对象，可以设置它的lazy-initialized属性，这样，容器就只会在这个对象第一次被请求的时候才去生成这个对象. 前面提到过，在spring框架中，每个bean对象的生命周期是不一样的，这个生命周期通过scope属性来表示，可以是singleton, prototype以及其它一些选择. 之前也提到过这个问题，如果在singleton对象中需要引用另一个prototype的对象，这个对象的注入时机是在singleton对象初始化的时候完成，也就是说，这个注入只会完成一次. 如果希望单例对象在每次请求时都获取新的prototype对象，spring提供了两种方式： 实现ApplicationContextAware接口： 通过这个接口，单例对象可以获取到ApplicationContext对象，即容器对象，这样当它需要prototype对象时，只需要通过容器获取一次即可. 但这个方法让业务层代码感知到容器的存在，有一定的侵入性. 需要通过方法注入的方式来完成: 通过指定lookup-method属性，可以将某个在容器中托管的对象映射给方法，也就是说，方法的返回对象被指定的容器对象替换. Spring框架是通过CGLib动态代理的方式来实现相应的机制的. 具体的示例代码如下所示： 12345678910111213141516171819202122public abstract class CommandManager &#123; public Object process(Object commandState) &#123; // grab a new instance of the appropriate Command interface Command command = createCommand(); // set the state on the (hopefully brand new) Command instance command.setState(commandState); return command.execute(); &#125; // okay... but where is the implementation of this method? protected abstract Command createCommand();&#125;&lt;!-- a stateful bean deployed as a prototype (non-singleton) --&gt;&lt;bean id=&quot;command&quot; class=&quot;fiona.apple.AsyncCommand&quot; scope=&quot;prototype&quot;&gt; &lt;!-- inject dependencies here as required --&gt;&lt;/bean&gt;&lt;!-- commandProcessor uses statefulCommandHelper --&gt;&lt;bean id=&quot;commandManager&quot; class=&quot;fiona.apple.CommandManager&quot;&gt; &lt;lookup-method name=&quot;createCommand&quot; bean=&quot;command&quot;/&gt;&lt;/bean&gt; Bean的范围对象的Scope属性定义了该对象的生命周期，关于这个之前已经说过很多，本节再对scope属性进行详细的描述. 总得来讲，对象的scope属性有以下几种： Scope 描述 Singleton 单例对象，容器中只存在一个对象，这是spring对象默认的scope值 prototype 原型对象，每次请求容器时，容器都将生成新的对象实例 request 单次请求范围有效，也就是说在每次请求时，容器都会生成新的对象实例，这个范围只在web应用中有效 Session 会话范围有效，也就是说在开始新的会话时，容器会生成新的对象实例，并在会话期间保持不变，同样，这个范围也只在web应用中有效 application 在servletContext范围有效，注意这里是servletContext范围唯一，而单例对象是在容器范围内唯一，这个范围也只在web应用中有效 globalSession 略 webSocket 略 singleton单例对象在容器范围保持唯一，它的示意图如下，也就是说，当容器请求单例对象时，总是返回同一个对象. 同时它也是spring中默认的scope值. prototype原型对象，从它的命名上就可以看出，它是作为对象的原型来使用，相当于是创建对象的模板. 当向容器请求原型对象时，容器总是返回一个新的原型对象，示意图如下. 和其它scope类型不同的是，spring容器并没有完整地管理prototype对象的生命周期，当容器创建好原型对象后，它就将原型对象完全交付给客户端，而不管它后续的所有生命周期。这也就意味着，虽然spring容器会对所有对象执行初始化操作(postConstruct或者initialize)，但它并不一定会执行相应的回收操作（preDestroy或者destructor)，原型对象的析构操作必须由客户端自行完成. 如果需要由容器来完成相应的回收操作，那么必须通过实现BeanPostProcessor接口来完成. 自定义生命周期Spring框架中提供了许多扩展点，供用户在需要的时候扩展实现自定义的行为，其中一个就是生命周期函数. 生命周期函数的扩展可以通过以下方式来进行： 实现InitializingBean和DisposobleBean接口：spring团队不建议使用这种方式来扩展，因为它将业务代码和框架代码进行不必要的耦合 使用@PostConstruct与@PreDestroy注解：这是推荐的作法，在容器构造完对象后，会调用postConstruct注解的方法进行初始化操作；同样地，在容器析构对象之前，会调用preDestroy注解的方法执行相应的操作. 这种方式对应于XML配置时的init-method属性和destroy-method属性. 参考文献官方文档：官方文档","categories":[],"tags":[{"name":"spring Ioc","slug":"spring-Ioc","permalink":"http://yoursite.com/tags/spring-Ioc/"}]},{"title":"Spring学习之IoC","slug":"spring/spring-ioc-1","date":"2016-07-05T13:45:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/07/05/spring/spring-ioc-1/","link":"","permalink":"http://yoursite.com/2016/07/05/spring/spring-ioc-1/","excerpt":"","text":"简介Spring框架中提供了很全面的功能，其中最基础的模块当属于容器的IoC以及AOP功能，以及它的事务管理机制. 在接下来的几篇文章中，将就这三个方面展开详细的阐述. IoCIoC也可以称为是DI，也就是依赖注入的意思，它的主要作用是由容器生成应用程序所需要的bean对象，并维护它们的生命周期以及相互间的依赖关系，而不是由bean自身来管理和维护它与其它对象之间的依赖关系. Spring中提供了BeanFactory接口来管理对象，同时也提供了ApplicationContext接口来提供更丰富的功能，包括AOP、事件发布、消息源处理等等功能，它是BeanFactory的子接口，但功能更丰富，因此,ApplicationContext接口也就是我们平时所说的容器. Spring容器的主要作用可以通过下图展示，在下图中，一系列的对象以及相应的配置文件在容器中完成组装，在容器初始化完成后，一个完整可用的应用程序就形成了，它内部的各种对象间的依赖关系也全部建立，而这些都是由容器根据配置文件自动组装完成的. 配置元数据配置信息也称为元数据， 从上述的描述可知，spring容器要自动完成bean对象的组装，需要接受相应的配置信息. 在spring框架中，配置信息的形式可以有很多种，包括： 传统的xml配置文件，多个配置文件可以通过import语句导入，注意这里使用的路径总是相对于目前的xml文件而言，也就是说它只接受相对路径，前置的”/“会被忽略 注解方式 代码方式(spring3.0引入). 示例以下的代码完整地展示了容器的配置、初始化及使用过程，大体上所有使用容器的步骤都可以分为这几个部分： 12345678910111213141516171819202122232425262728//配置信息，services.xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;...&quot; class=&quot;...&quot;&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt; &lt;bean id=&quot;...&quot; class=&quot;...&quot;&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt; &lt;!-- more bean definitions go here --&gt;&lt;/beans&gt;//初始化及使用ApplicationContext context = new ClassPathXmlApplicationContext(new String[] &#123;&quot;services.xml&quot;, &quot;daos.xml&quot;&#125;);// retrieve configured instancePetStoreService service = context.getBean(&quot;petStore&quot;, PetStoreService.class);// use configured instanceList&lt;String&gt; userList = service.getUsernameList(); Bean对象的定义Bean对象在spring容器是通过BeanDefinition来定义的，它可以认为是容器创建Bean对象时的“菜单”，里面记录了完整的类名、类的依赖关系、生命周期方法以及其它属性等信息，有了这些信息，容器就可以在合适的时机初始化相应的对象. 具体来讲，bean对象的定义包括以下内容： 属性名 描述 class 类的完整名称 name 类的名称，可以作为类的标识，可以指定多个，用逗号分开 scope 作用域，这个会在后续的章节中进行详细阐述 constructor arguments 构造方法参数 properties 各种属性 autowiring mode 自动注入模式 lazy-initializing mode 延迟初始化模式，如果bean对象是延迟初始化模式，那么在容器初始化的时候，并不会去初始化这个bean，直到后续有请求需要用到这个bean时才会执行初始化操作 initializing method 初始化方法 destruction method 析构方法 除此之外，spring还允许注册在容器外生成的对象，这种方式是通过ApplicationContext来获取BeanFactory，然后再调用registerBeanDefinition方法来完成对象的注册. 对象标识对象的标识可以由一个ID或者多个name组合而成，同时也可以通过alias属性为bean对象设置别名. 在需要引用对象的地方，可以通过相应的标识进行引用.（ref或者idref) 如果在定义bean对象的时候没有显式地指定名称，那么spring框架将会默认给它提供一个，默认的对象名将遵循java规范，将类名的第一个字母小写，而后遵循camelCase原则. 12&lt;bean name=&quot;nameA,nameB,nameC&quot; id=&quot;idA&quot; /&gt;&lt;alias name=&quot;nameA&quot; alias=&quot;aliasA&quot; /&gt; 对象的初始化对象的初始化有两种方式, 在这两种方式中，如果需要提供相应的构造函数参数，都可以通过来指定： 直接定义bean对象. 这种方法有点类似于使用new操作符，spring框架直接调用对象的构造函数完成对象的初始化. 通过工厂方法来完成. 这种方法又可以进一步细分为两种： 通过静态类的工厂方法. 通过class与来指定工厂方法，工厂方法的返回值类型即为创建对象的实际类型，注意返回的类型并不一定需要与静态类的类型保持一致 通过实例的工厂方法. 这种情况下不需要指定class，而是通过与来指定工厂方法，同样地，工厂方法的返回值类型即为创建对象的实际类型. 123456789101112//静态类工厂方法&lt;bean id=&quot;clientService&quot; class=&quot;examples.ClientService&quot; factory-method=&quot;createInstance&quot;/&gt;//实例的工厂方法&lt;bean id=&quot;serviceLocator&quot; class=&quot;examples.DefaultServiceLocator&quot; /&gt;&lt;!-- the bean to be created via the factory bean --&gt;&lt;bean id=&quot;clientService&quot; factory-bean=&quot;serviceLocator&quot; factory-method=&quot;createClientServiceInstance&quot;/&gt; 依赖注入构造函数注入这种方式就是指依赖关系是通过构造函数的参数传入的，在使用的时候，可以使用进行指定. 在不引起歧义的情况下，容器会自动根据提供的参数类型传给构造函数，比如当所有参数的类型都不一样时，就不存在歧义 当存在类型转化或者会引起歧义的情况时，可以通过type指定具体类型以及index来指定参数在构造函数中的参数位置来进一步确定参数间的匹配. 123456789101112131415161718192021222324252627282930//没有歧义，不需要再额外指定参数&lt;beans&gt; &lt;bean id=&quot;foo&quot; class=&quot;x.y.Foo&quot;&gt; &lt;constructor-arg ref=&quot;bar&quot;/&gt; &lt;constructor-arg ref=&quot;baz&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;bar&quot; class=&quot;x.y.Bar&quot;/&gt; &lt;bean id=&quot;baz&quot; class=&quot;x.y.Baz&quot;/&gt;&lt;/beans&gt;//参数的匹配有歧义，需要额外指定匹配参数,不指定的话，则无法知道“7500000”与“42”哪个参数该匹配到yearspublic class ExampleBean &#123; // Number of years to calculate the Ultimate Answer private int years; // The Answer to Life, the Universe, and Everything private String ultimateAnswer; public ExampleBean(int years, String ultimateAnswer) &#123; this.years = years; this.ultimateAnswer = ultimateAnswer; &#125;&#125;&lt;bean id=&quot;exampleBean&quot; class=&quot;examples.ExampleBean&quot;&gt; &lt;constructor-arg type=&quot;int&quot; value=&quot;7500000&quot;/&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;42&quot;/&gt;&lt;/bean&gt; setter方法注入setter方法注入就是通过调用相应属性的set方法来完成，没有太多的内容，不作阐述. 如何选择既然有两种方式可以完成依赖关系的注入，那么肯定就会有这样的疑问，什么情况下该用哪种方式来完成依赖呢? 这里引用一个描述来回答这个问题： 使用构造函数来注入那些必需的依赖关系，而对于那些不强制要求的依赖关系，使用setter依赖来完成 参考文献官方文档:官方文档","categories":[],"tags":[{"name":"spring Ioc","slug":"spring-Ioc","permalink":"http://yoursite.com/tags/spring-Ioc/"}]},{"title":"ServletContext与ApplicationContext的区别","slug":"spring/spring-differerce-between-application-context-and-servlet-context","date":"2016-07-02T14:25:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/07/02/spring/spring-differerce-between-application-context-and-servlet-context/","link":"","permalink":"http://yoursite.com/2016/07/02/spring/spring-differerce-between-application-context-and-servlet-context/","excerpt":"","text":"Spring中的概念在阅读Spring源码或相关的文献时，经常会遇到WebApplicationContext, ApplicationContext, ServletContext以及ServletConfig等名词，这些名词都很相近，但适用范围又有所不同，对理解源码及spring内部实现造成混淆，因此有必要对这些概念进行一些比较. 为了后续比较的方便，首先我们先来澄清这几个名词的概念 ServletContext: 这个是来自于servlet规范里的概念，它是servlet用来与容器间进行交互的接口的组合，也就是说，这个接口定义了一系列的方法，servlet通过这些方法可以很方便地与自己所在的容器进行一些交互，比如通过getMajorVersion与getMinorVersion来获取容器的版本信息等. 从它的定义中也可以看出，在一个应用中(一个JVM)只有一个ServletContext, 换句话说，容器中所有的servlet都共享同一个ServletContext. ServletConfig: 它与ServletContext的区别在于，servletConfig是针对servlet而言的，每个servlet都有它独有的serveltConfig信息，相互之间不共享. ApplicationContext: 这个类是Spring实现容器功能的核心接口，它也是Spring实现IoC功能中最重要的接口，从它的名字中可以看出，它维护了整个程序运行期间所需要的上下文信息， 注意这里的应用程序并不一定是web程序，也可能是其它类型的应用. 在Spring中允许存在多个applicationContext，这些context相互之间还形成了父与子，继承与被继承的关系，这也是通常我们所说的，在spring中存在两个context,一个是root context，一个是servlet applicationContext的意思. 这点后面会进一步阐述. WebApplicationContext: 其实这个接口不过是applicationContext接口的一个子接口罢了，只不过说它的应用形式是web罢了. 它在ApplicationContext的基础上，添加了对ServletContext的引用，即getServletContext方法. 如何配置ServletContext从前面的论述中可以知道, ServletContext是容器中所有servlet共享的配置，它在应用中是全局的 根据servlet规范的规定，可以通过以下配置来进行配置，其中Context-Param指定了配置文件的位置，ContextLoaderListener定义了context加载时的监听器，因此，在容器启动时，监听器会自动加载配置文件，执行servletContext的初始化操作. 12345678&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:conf/applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; ServletConfigServletConfig是针对每个Servlet进行配置的，因此它的配置是在servlet的配置中，如下所示， 配置使用的是init-param, 它的作用就是在servlet初始化的时候，加载配置信息，完成servlet的初始化操作 123456789101112&lt;servlet&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/mvc-dispatcher-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/servlet&gt; 关于applicationContext的配置，简单来讲，在servletContext中配置的context-param参数, 会生成所谓的root application context, 而每个servlet中指定的init-param参数中指定的对象会生成servlet application context, 而且它的parent就是servletContext中生成的root application context, 因此在servletContext中定义的所有配置都会被继承到servlet中， 这点在后续的源码阐述中会有更直观的体现. 源码分析首先先来看ServletContext中的配置文件的加载过程. 这个过程是由ContextLoaderListener对象来完成的，因此我们找到相应的源码，去掉一些日志及不相关的源码后如下： 第一步是判断是否存在rootApplicationContext，如果存在直接抛出异常结束 第二步是创建context对象，并在servletContext中把这个context设置为名称为ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE的属性. 到这里其实已经解释了ApplicationContext与servletContext的区别，它不过是servletContext中的一个属性值罢了，这个属性值中存有程序运行的所有上下文信息 由于这个applicationContext是全局的应用上下文信息，在spring中就把它取名为’root application context’. 12345678910111213141516public WebApplicationContext initWebApplicationContext(ServletContext servletContext) &#123; if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) &#123; &#125; try &#123; // Store context in local instance variable, to guarantee that // it is available on ServletContext shutdown. if (this.context == null) &#123; this.context = createWebApplicationContext(servletContext); &#125; servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); return this.context; &#125;&#125; 接着再来看DispatcherServlet的源码，作为servlet，根据规范它的配置信息应该是在Init方法中完成，因此我们找到这个方法的源码即可知道servletConfig以及servlet application context的初始化过程: 第一步是从servletConfig中获取所有的配置参数， ServletConfigPropertyValues的构造函数中会遍历servletConfig对象的所有初始化参数，并把它们一一存储在pvs中 第二步就是开始初始servlet，由于dispatcherServlet是继承自FrameworkServlet，因此这个方法在FrameworkServlet中找到，可以看到，在initServletBean中又调用了initWebApplicationContext方法，在这个方法中，首先获取到rootContext， 接着就开始初始化wac这个对象，在创建这个wac对象的方法中，传入了rootContext作为它的parent，也就是在这里，两者之间的父子关系建立，也就形成了我们平时常说的继承关系. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677@Overridepublic final void init() throws ServletException &#123; // Set bean properties from init parameters. PropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties); // Let subclasses do whatever initialization they like. initServletBean();&#125;//遍历获取servletConfig的所有参数public ServletConfigPropertyValues(ServletConfig config, Set&lt;String&gt; requiredProperties) throws ServletException &#123; while (en.hasMoreElements()) &#123; String property = (String) en.nextElement(); Object value = config.getInitParameter(property); addPropertyValue(new PropertyValue(property, value)); if (missingProps != null) &#123; missingProps.remove(property); &#125; &#125;&#125;//初始化webApplicationContextprotected final void initServletBean() throws ServletException &#123; try &#123; this.webApplicationContext = initWebApplicationContext(); &#125;&#125;//具体的初始化操作实现protected WebApplicationContext initWebApplicationContext() &#123; WebApplicationContext rootContext = WebApplicationContextUtils.getWebApplicationContext(getServletContext()); WebApplicationContext wac = null; if (this.webApplicationContext != null) &#123; // A context instance was injected at construction time -&gt; use it wac = this.webApplicationContext; if (wac instanceof ConfigurableWebApplicationContext) &#123; ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) wac; if (!cwac.isActive()) &#123; // The context has not yet been refreshed -&gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) &#123; // The context instance was injected without an explicit parent -&gt; set // the root application context (if any; may be null) as the parent cwac.setParent(rootContext); &#125; configureAndRefreshWebApplicationContext(cwac); &#125; &#125; &#125; if (wac == null) &#123; // No context instance was injected at construction time -&gt; see if one // has been registered in the servlet context. If one exists, it is assumed // that the parent context (if any) has already been set and that the // user has performed any initialization such as setting the context id wac = findWebApplicationContext(); &#125; if (wac == null) &#123; // No context instance is defined for this servlet -&gt; create a local one //就是在这个方法中，servlet application context与root application context的继承关系正式建立 wac = createWebApplicationContext(rootContext); &#125; if (this.publishContext) &#123; // Publish the context as a servlet context attribute. String attrName = getServletContextAttributeName(); getServletContext().setAttribute(attrName, wac); &#125; return wac;&#125;//就是在这个方法中，servlet application context与root application context的继承关系正式建立protected WebApplicationContext createWebApplicationContext(WebApplicationContext parent) &#123; return createWebApplicationContext((ApplicationContext) parent);&#125; 参考文献 Servlet与JSP： Head first to Servlet and JSP JavaDoc: DispatcherServlet FrameworkServlet ContextLoaderListener","categories":[],"tags":[{"name":"Spring ServletContext ServletConfig ApplicationContext","slug":"Spring-ServletContext-ServletConfig-ApplicationContext","permalink":"http://yoursite.com/tags/Spring-ServletContext-ServletConfig-ApplicationContext/"}]},{"title":"SpringMVC学习(6)","slug":"spring/spring-mvc-config","date":"2016-07-02T11:37:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/07/02/spring/spring-mvc-config/","link":"","permalink":"http://yoursite.com/2016/07/02/spring/spring-mvc-config/","excerpt":"","text":"配置SpringMVC在之前的阐述中提到，springMVC框架中提供了很多特殊的对象来实现整个MVC流程的处理（详见概述）. 这一节详细阐述如何分别通过代码和配置的方式在springMVC中自定义这些对象的行为. 启用SpringMVC框架启用SpringMVC框架的方法很简单，如下所示，只需要一行注解代码或者一行配置即可完成. 启用了springMVC框架后，spring自动完成了以下这些事情： 注册RequestMappingHandlerMapping对象 注册RequestMappingHandlerAdapter对象 注册ExceptionHandlerExceptionResolver对象 设置了HttpMessageConverters，具体的实现包括： ByteArrayHttpMessageConverter StringHttpMessageConverter ResourceHttpMessageConverter SourceHttpMessageConverter FormHttpMessageConverter MappingJackson2HttpMessageConverter: 如果在类路径中找到ackson 2，则自动注册这个类 1234567//代码方式@Configuration@EnableWebMVCpublic class WebConfig&#123;&#125;//配置方式, dispatcherServlet.xml&lt;mvc:annotation-driven /&gt; 类型转换和格式化操作如果需要自定义类型转换和格式化，可以通过重写相应的方法或者配置conversionService来完成 1234567891011121314151617181920212223242526272829303132//代码方式@Configuration@EnableWebMVCpublic class WebConfig extends WebMvcConfigurerAdapter&#123; @Override public void addFormatters(FormatterRegistry registry) &#123; // Add formatters and/or converters &#125;&#125;//配置方式&lt;mvc:annotation-driven conversion-service=&quot;conversionService&quot;/&gt;&lt;bean id=&quot;conversionService&quot; class=&quot;org.springframework.format.support.FormattingConversionServiceFactoryBean&quot;&gt; &lt;property name=&quot;converters&quot;&gt; &lt;set&gt; &lt;bean class=&quot;org.example.MyConverter&quot;/&gt; &lt;/set&gt; &lt;/property&gt; &lt;property name=&quot;formatters&quot;&gt; &lt;set&gt; &lt;bean class=&quot;org.example.MyFormatter&quot;/&gt; &lt;bean class=&quot;org.example.MyAnnotationFormatterFactory&quot;/&gt; &lt;/set&gt; &lt;/property&gt; &lt;property name=&quot;formatterRegistrars&quot;&gt; &lt;set&gt; &lt;bean class=&quot;org.example.MyFormatterRegistrar&quot;/&gt; &lt;/set&gt; &lt;/property&gt;&lt;/bean&gt; 拦截器可以通过重写addInterceptors方法或者配置元素来对所有请求或者部分请求设置拦截器： 1234567891011121314151617181920212223//代码方式@Overridepublic void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new LocaleInterceptor()); registry.addInterceptor(new ThemeInterceptor()).addPathPatterns(&quot;/**&quot;).excludePathPatterns(&quot;/admin/**&quot;); registry.addInterceptor(new SecurityInterceptor()).addPathPatterns(&quot;/secure/*&quot;);&#125;//配置方式&lt;mvc:interceptors&gt; &lt;bean class=&quot;org.springframework.web.servlet.i18n.LocaleChangeInterceptor&quot;/&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/**&quot;/&gt; &lt;mvc:exclude-mapping path=&quot;/admin/**&quot;/&gt; &lt;bean class=&quot;org.springframework.web.servlet.theme.ThemeChangeInterceptor&quot;/&gt; &lt;/mvc:interceptor&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=&quot;/secure/*&quot;/&gt; &lt;bean class=&quot;org.example.SecurityInterceptor&quot;/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 内容协商管理器在介绍SpringMVC的RESTful支持(视图解析)时曾提过，spring框架可以支持按照请求后缀名或者消息头返回相应格式的内容，实现的主要方法就是配置ContentNegotiatingViewResolver. 而将请求的后缀或消息头转化成相应的媒体类型就是由ContentNegotiateManager来完成，配置这个管理器的方法同样也有通过代码和配置文件两种方式： springMVC中, 可以根据需要给RequestMappingHandlerMapping、RequestMappingHandlerAdapter以及ExceptionHandlerExceptionResolver提供相同的内容协商器，也可以根据需要提供各自的协商器，具体根据需要进行确定. 12345678910111213141516//代码方式@Overridepublic void configureContentNegotiation(ContentNegotiationConfigurer configurer) &#123; configurer.mediaType(&quot;json&quot;, MediaType.APPLICATION_JSON);&#125;//配置方式&lt;mvc:annotation-driven content-negotiation-manager=&quot;contentNegotiationManager&quot;/&gt;&lt;bean id=&quot;contentNegotiationManager&quot; class=&quot;org.springframework.web.accept.ContentNegotiationManagerFactoryBean&quot;&gt; &lt;property name=&quot;mediaTypes&quot;&gt; &lt;value&gt; json=application/json xml=application/xml &lt;/value&gt; &lt;/property&gt;&lt;/bean&gt; 在没有使用SpringMVC环境的场景时： 如果需要使用RequestMappingHandlerMapping, 必须生成一个ContentNegotiationManager实例并把它配置到处理器映射对象中，以完成请求的映射 如果需要使用RequestMappingHandlerAdapter或者ExceptionHandlerExceptionResolver， 也必须生成一个ContentNegotiationManager的实例来完成内容类型的协商 视图控制器视图控制器的作用很简单，它不提供相应的业务处理逻辑，只是将请求映射成相应的视图，它的配置如下: 12345678//代码方式@Overridepublic void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(&quot;/&quot;).setViewName(&quot;home&quot;);&#125;//配置方式&lt;mvc:view-controller path=&quot;/&quot; view-name=&quot;home&quot;/&gt; 资源配置资源配置主要是针对静态资源的处理，具体是由ResourceHttpRequestHandler类进行处理，它可以根据请求头里的信息决定返回304还是200. 配置信息主要是配置哪些路径的请求交由这个类进行处理，以及资源的位置. 具体如下: 12345678//代码方式@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler(&quot;/resources/**&quot;).addResourceLocations(&quot;/public-resources/&quot;);&#125;//配置方式&lt;mvc:resources mapping=&quot;/resources/**&quot; location=&quot;/public-resources/&quot;/&gt; 消息转化器消息转化器的作用是将请求消息体和响应消息体的内容与对应的类型之间进行转换，配置样例如下: 12345678910111213141516171819202122//代码方式@Overridepublic void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) &#123; Jackson2ObjectMapperBuilder builder = new Jackson2ObjectMapperBuilder() .indentOutput(true) .dateFormat(new SimpleDateFormat(&quot;yyyy-MM-dd&quot;)) .modulesToInstall(new ParameterNamesModule()); converters.add(new MappingJackson2HttpMessageConverter(builder.build())); converters.add(new MappingJackson2XmlHttpMessageConverter(builder.xml().build()));&#125;//配置方式&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class=&quot;org.springframework.http.converter.json.MappingJackson2HttpMessageConverter&quot;&gt; &lt;property name=&quot;objectMapper&quot; ref=&quot;objectMapper&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.xml.MappingJackson2XmlHttpMessageConverter&quot;&gt; &lt;property name=&quot;objectMapper&quot; ref=&quot;xmlMapper&quot;/&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 参考文献官方文档：官方文档","categories":[],"tags":[{"name":"SpringMVC config","slug":"SpringMVC-config","permalink":"http://yoursite.com/tags/SpringMVC-config/"}]},{"title":"Spring学习(5)","slug":"spring/spring-mvc-code-based-servlet-container-config","date":"2016-07-02T09:24:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/07/02/spring/spring-mvc-code-based-servlet-container-config/","link":"","permalink":"http://yoursite.com/2016/07/02/spring/spring-mvc-code-based-servlet-container-config/","excerpt":"","text":"基于代码的Servlet容器配置大部分情况下，使用Spring是采用基于配置的方式，通常情况下是通过web.xml文件对容器的行为进行配置. 从servlet3.0开始，spring提供了基于代码的配置，以下是个例子: 1234567891011121314public class MyWebApplicationInitializer implements WebApplicationInitializer &#123; @Override public void onStartup(ServletContext container) &#123; XmlWebApplicationContext appContext = new XmlWebApplicationContext(); appContext.setConfigLocation(&quot;/WEB-INF/spring/dispatcher-config.xml&quot;); ServletRegistration.Dynamic registration = container.addServlet(&quot;dispatcher&quot;, new DispatcherServlet(appContext)); registration.setLoadOnStartup(1); registration.addMapping(&quot;/&quot;); &#125;&#125; WebApplicationInitializer的实现会自动被检测到并且被用于初始化容器的配置. 除此之外, spring还提供了一种AbstractDispatcherServletInitializer抽象类来提供更简洁的方式对容器进行初始化, 这也是spring推荐的使用方式. 使用AbstractDispatcherServletInitializer进行初始化还可以分为使用代码和使用XML配置文件的方式： 注意：这里说的是初始化DispatcherServlet的配置，而上面说的是利用代码方式初始化Servlet容器，两者不要混淆. 123456789101112131415161718192021222324252627282930313233343536373839404142//使用代码方式配置public class MyWebAppInitializer extends AbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return null; &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class[] &#123; MyWebConfig.class &#125;; &#125; @Override protected String[] getServletMappings() &#123; return new String[] &#123; &quot;/&quot; &#125;; &#125;&#125;//使用XML方式配置public class MyWebAppInitializer extends AbstractDispatcherServletInitializer &#123; @Override protected WebApplicationContext createRootApplicationContext() &#123; return null; &#125; @Override protected WebApplicationContext createServletApplicationContext() &#123; XmlWebApplicationContext cxt = new XmlWebApplicationContext(); cxt.setConfigLocation(&quot;/WEB-INF/spring/dispatcher-config.xml&quot;); return cxt; &#125; @Override protected String[] getServletMappings() &#123; return new String[] &#123; &quot;/&quot; &#125;; &#125;&#125; 另外，AbstractDispatcherServletInitializer抽象类还提供了关于filter，isAsyncSupport等配置的支持，具体可以参阅其文档，这里就不做过多阐述. 查阅AbstractDispatcherServletInitializer的源码可以发现，它是典型的模板模式的实现，将对WebApplicationInitializer的实现进行抽象，但是整个方法的实现过程没有太多变化. 12345678910111213141516171819202122232425262728293031323334public void onStartup(ServletContext servletContext) throws ServletException &#123; super.onStartup(servletContext); registerDispatcherServlet(servletContext);&#125;protected void registerDispatcherServlet(ServletContext servletContext) &#123; String servletName = getServletName(); Assert.hasLength(servletName, &quot;getServletName() may not return empty or null&quot;); WebApplicationContext servletAppContext = createServletApplicationContext(); Assert.notNull(servletAppContext, &quot;createServletApplicationContext() did not return an application &quot; + &quot;context for servlet [&quot; + servletName + &quot;]&quot;); DispatcherServlet dispatcherServlet = new DispatcherServlet(servletAppContext); ServletRegistration.Dynamic registration = servletContext.addServlet(servletName, dispatcherServlet); Assert.notNull(registration, &quot;Failed to register servlet with name &apos;&quot; + servletName + &quot;&apos;.&quot; + &quot;Check if there is another servlet registered under the same name.&quot;); registration.setLoadOnStartup(1); registration.addMapping(getServletMappings()); registration.setAsyncSupported(isAsyncSupported()); Filter[] filters = getServletFilters(); if (!ObjectUtils.isEmpty(filters)) &#123; for (Filter filter : filters) &#123; registerServletFilter(servletContext, filter); &#125; &#125; customizeRegistration(registration);&#125; 参考文献官方文档： 基于代码配置Servlet容器","categories":[],"tags":[{"name":"springMVC code-based container config","slug":"springMVC-code-based-container-config","permalink":"http://yoursite.com/tags/springMVC-code-based-container-config/"}]},{"title":"SpringMVC学习(4)","slug":"spring/spring-mvc-fileUpload-exceptionHandle","date":"2016-06-29T10:54:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/06/29/spring/spring-mvc-fileUpload-exceptionHandle/","link":"","permalink":"http://yoursite.com/2016/06/29/spring/spring-mvc-fileUpload-exceptionHandle/","excerpt":"","text":"文件上传Spring中对于文件上传的支持是通过MultipartResolver接口来实现的，默认情况下，spring关于文件上传的支持是关闭的，如果需要，需要在上下文中配置相应的multipartResolver对象，并指定它的名字为“multipartResolver”. spring框架中自带了两种multipartResolver的实现， 配置的样例如下： CommonsMultipartResolver: 使用这个解析器需要引用o.s.web.multipart包 StandardServletMultipartResolver: spring内部提供的multipartResolver的标准实现 1234567&lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;!-- one of the properties available; the maximum file size in bytes --&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;100000&quot;/&gt;&lt;/bean&gt; 在配置了multipartResolver之后，后续所有的请求都会被解析，如果判断出该请求是文件上传请求，则会调用multipartResolver的resolveMultipart方法，将request包装成MultipartHttpServletRequest. 在表单中使用multipartResolver在表单中使用multipartResolver分为两个步骤， 示例代码如下, 可以看出，在控制器的实现中基本没有什么变化，只是将原来的HttpServletRequest包装成了MultipartHttpServletRequest，这步是在请求进入DispatcherServlet的doDispatch方法时被调用的（后续会对DispatcherServlet的doDispatch方法做源码分析)： 指定表单的enctype为“multipart/form-data” 在控制器相应的处理方法中，通过MultipartFile或者MultipartHttpServletRequest获取相应的请求对象，并获取上传的文件 1234567891011121314151617181920212223242526272829//表单内容&lt;html&gt; &lt;body&gt; &lt;form action=&quot;/form&quot; enctype=&quot;multipart/form-data&quot; method=&quot;post&quot;&gt; &lt;input type=&quot;input&quot; name=&quot;name&quot; /&gt; &lt;input type=&quot;file&quot; name=&quot;file&quot; /&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; value=&quot;submit&quot;/&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt;//控制器实现@Controllerpublic class FileUploadController &#123; @PostMapping(&quot;/form&quot;) public String handleFormUpload(@RequestParam(&quot;name&quot;) String name, @RequestParam(&quot;file&quot;) MultipartFile file) &#123; if (!file.isEmpty()) &#123; byte[] bytes = file.getBytes(); // store the bytes somewhere return &quot;redirect:uploadSuccess&quot;; &#125; return &quot;redirect:uploadFailure&quot;; &#125;&#125; 在编码客户端中使用MultipartResolver通过代码向服务端上传文件时，绝大部分的逻辑和上述通过表单上传是一致的，但是通过代码上传文件时，可以一次性上传多个文件内容，并且上传的文件内容格式可以互不相同，下面的代码展示了这样的上传样例: 12345678910111213141516171819202122232425POST /someUrlContent-Type: multipart/mixed--edt7Tfrdusa7r3lNQc79vXuhIIMlatb7PQg7VpContent-Disposition: form-data; name=&quot;meta-data&quot;Content-Type: application/json; charset=UTF-8Content-Transfer-Encoding: 8bit&#123; &quot;name&quot;: &quot;value&quot;&#125;--edt7Tfrdusa7r3lNQc79vXuhIIMlatb7PQg7VpContent-Disposition: form-data; name=&quot;file-data&quot;; filename=&quot;file.properties&quot;Content-Type: text/xmlContent-Transfer-Encoding: 8bit... File Data ...//控制器的实现@PostMapping(&quot;/someUrl&quot;)public String onSubmit(@RequestPart(&quot;meta-data&quot;) MetaData metadata, @RequestPart(&quot;file-data&quot;) MultipartFile file) &#123; // ...&#125; 在这种情况下，可以通过@RequestPart或者@RequestParam来指定获取哪部分的数据，并且可以通过HttpMessageConverter自动完成相应的类型转换，其它的逻辑与表单完全一致. 异常处理在springMVC中，当请求在被处理的过程中，如果出现了异常情况，异常情况会交由HandlerExcetionResolver接口处理. 在SpringMVC框架中，可以通过三种方式进行异常处理: 实现HandlerExceptionResolver接口: 这个接口定义了resolveException方法来处理在发生异常的情况下返回的ModelAndView对象 使用SimpleMappingExceptionResolver实现: 这个实现提供了异常类型到视图类的映射关系 使用@ExceptionHandler注解: 这个注解的作用是当异常产生的时候，调用有这个注解的方法来处理异常. 它可以指定要处理的异常类型，默认为方法参数的异常类型. @ExceptionHandler可以只作用于某个Controller类中的方法，也可以通过ControllerAdvise注解作用于多个控制器类. 在需要使用多个HandlerExceptionResolver的场合，可以通过HandlerExceptionResolverComposite类进行组合. @ExceptionHandler注解在SpringMVC中，使用ExceptionHandlerExceptionResolver来处理@ExceptionHandler注解的异常信息. 它特别适合于不需要返回错误视图，只是简单地返回错误代码及错误说明的场景, 例如在RESTful接口的使用中，就可以使用这个注解对异常信息进行处理. 以下是示例代码， 当请求/exception地址时会抛出运行时异常，这个运行时异常会被@ExceptionHandler注解的方法处理，最终返回响应码为400，响应信息为“Bad Request.”: 123456789101112131415@RequestMapping@Controllerpublic class ExceptionHandlerController &#123; @RequestMapping(&quot;/exception&quot;) public String throwException() &#123; throw new RuntimeException(); &#125; @ExceptionHandler(value = RuntimeException.class) @ResponseBody public String handleException(HttpServletResponse response) &#123; response.setStatus(HttpServletResponse.SC_BAD_REQUEST); return &quot;Bad request.&quot;; &#125;&#125; 标准的spring异常在Spring进行处理的过程中，可能会产生许多类型的异常信息，使用SimpleMappingExceptionResolver可以将这些异常信息映射成相应的错误视图，但是有的时候可能希望将这些异常信息映射成相应的错误代码, spring中提供了DefaultHandlerExceptionResolver来实现这个功能. DefaultHandlerExceptionResolver默认被注册到spring中, 它当一些标准的spring异常类型转换成相应的错误代码，如BindException转化成400， HttpMediaTypeNotSupportedException转化成415等等，具体的对应关系可以查阅参考文献. @ResponseStatus在Spring中自定义异常类时，可以使用@ResponseStatus注解, 它可以指定相应的错误代码和错误信息，当处理器抛出这种类型的异常信息时，spring会自动将它转化成相应的错误代码和错误信息. 在spring内部，使用ResponseStatusExceptionResolver进行这个注解的处理，默认情况下spring就会注册这个解析器 除此之外，Servlet也支持将异常信息通过错误码和异常类型映射成相应的处理器进行处理. 参考文献官方文档: 官方文档","categories":[],"tags":[{"name":"SpringMVC fileUpload exceptionHandle","slug":"SpringMVC-fileUpload-exceptionHandle","permalink":"http://yoursite.com/tags/SpringMVC-fileUpload-exceptionHandle/"}]},{"title":"SpringMVC学习(3)","slug":"spring/spring-mvc-handler-mapping","date":"2016-06-28T12:43:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/06/28/spring/spring-mvc-handler-mapping/","link":"","permalink":"http://yoursite.com/2016/06/28/spring/spring-mvc-handler-mapping/","excerpt":"","text":"处理器映射在前面关于SpringMVC处理流程的描述中提到，当用户向服务器发起请求时，spring将请求通过handlerMapping映射成具体的handler，并带上一系列的拦截器，后续的处理由该处理器和拦截器来完成. 在使用注解@RequestMapping的时候，spring会自动使用RequestMappingHandlerMapping这个类来进行处理，它会自动找出所有controller类中使用@RequestMapping注解的地方. 在springMVC中，所有继承自AbstractHandlerMapping的实现都有以下这些属性: 属性名 描述 interceptors 和当前handler关联的所有拦截器列表，请求会先由interceptor进行拦截处理，最后到达handler defaultHandler 默认的处理器，当没有匹配到合适的拦截器时使用 order 用于多个handlerMapping之间的排序时使用 alwaysUseFullPath 如果设置为true,那么在查找的时候会使用完整的路径进行匹配；否则只使用相对路径进行匹配. e.g. 如果某个servlet使用/testing/*， 这个值设置为true， 那么匹配的将是/testing/viewPage.html, 否则就是/viewPage.html 拦截器spring中使用拦截器机制在对请求进行处理之前执行一些特定的操作， 这些拦截器由HandlerInterceptor来定义， 这个接口定义了三个方法，如果想自定义拦截器，可以通过继承HandlerInterceptorAdapter类来实现： preHandler: 在请求到达处理器之前被调用，返回boolean类型的值，如果为true，意味着请求通过，交由后续的拦截器或处理器进行一步处理；如果为false，说明请求不通过，或响应已由本拦截器输出 postHandler: 在处理器返回相应的响应结果之后被调用 , 用于做一些后续的处理操作 afterCompletion: 在整个请求结束之后被调用 以下这段代码展示了如何配置interceptor信息： 1234567&lt;beans&gt; &lt;bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping&quot;&gt; &lt;property name=&quot;interceptors&quot;&gt; &lt;bean class=&quot;example.MyInterceptor&quot;/&gt; &lt;/property&gt; &lt;/bean&gt;&lt;beans&gt; 视图解析几乎所有的MVC框架都会提供相应的视图解析机制，而SpringMVC中使用ViewResolver和View类来完成相应的功能， 其中ViewResolver是用于将控制器返回的逻辑视图解析成相应的视图, 而View类则完成数据的准备和实际的渲染工作. SpringMVC中自带了一些视图解析器的实现, 以下是相应的说明，后续还给出了视图解析器的配置样例: 视图解析器名称 描述 AbstractCachingViewResolver 视图解析器的抽象实现，完成视图缓存的功能，所有需要缓存视图的视图解析器都可以从这个类派生 XmlViewResolver 由XML文件中的配置来定义逻辑视图到实际视图的对应关系，默认的xml文件位于/WEB-INF/views.xml中 UrlBasedViewResolver 基于URL路径的视图解析机制，如果实际的视图资源与逻辑视图之间有严格的对应关系，或者逻辑视图是实际视图的某个特定部分时，就可以使用这个解析器. 这个解析器还可以定义路径的前后缀信息 InternalResourceViewResolver 工具类，它是UrlBasedViewResolver和InternalResourceView的组合 VelocityViewResolver、FreeMarkerViewResolver 两者都是基于模板语言的视图解析器，都继承自UrlBasedViewResolver，对应的视图类分别是VelocityView和FreeMarkerView ContentNegotiatingViewResolver 这个解析器自己并不解析视图，而是将解析工作委托给配置好的视图解析器列表来进行解析，可以根据请求地址的后缀或者Accept头信息返回相应的视图内容 123456&lt;bean id=&quot;viewResolver&quot; class=&quot;org.springframework.web.servlet.view.UrlBasedViewResolver&quot;&gt; &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot;/&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;&lt;/bean&gt; 解析器级联SpringMVC中支持将解析器级联，通过Order接口对各个解析器进行排序，当有请求进来时则对它一一进行解析. 以下的样例代码展示了同时配置多个视图解析器: 123456789101112131415&lt;bean id=&quot;jspViewResolver&quot; class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot;/&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;excelViewResolver&quot; class=&quot;org.springframework.web.servlet.view.XmlViewResolver&quot;&gt; &lt;property name=&quot;order&quot; value=&quot;1&quot;/&gt; &lt;property name=&quot;location&quot; value=&quot;/WEB-INF/views.xml&quot;/&gt;&lt;/bean&gt;&lt;!-- in views.xml --&gt;&lt;beans&gt; &lt;bean name=&quot;report&quot; class=&quot;org.springframework.example.ReportExcelView&quot;/&gt;&lt;/beans&gt; 重定向视图在视图解析器解析得到相应的视图类之后，由视图类进行后续的处理. 对于InternalResourceView来讲，内部使用RequestDispatcher进行相应的forward操作; 对于FreeMarkerView及VelocityView来讲，由它们直接输入相应的视图内容. 但是有时候可能会需要将视图重定向，比如经典的“Post-Redirect-Get”场景. 在Spring中提供了两种方式来进行重定向操作： 使用RedirectView: 这种方式直接由处理器返回RedirectView的实例，因此重定向的操作直接由这个类完成，但这种做法将重定向操作与控制器紧密耦合，即控制器感知到业务在进行重定向操作，不推荐 使用redirect:前缀: 这种做法在返回的逻辑视图前加上相应的前缀，对于控制器层而言，它和其它的逻辑视图一样；但对于UrlBasedViewResolver来讲，带有这个前缀的逻辑视图意味着要进行重定向操作. 在重定向过程中，可以RedirectAttribute将当前请求的一些属性传递给目标URL. 使用forward：前缀: 使用这个前缀时，UrlBasedViewResolver会在内部生成InternalResourceView，并把逻辑视图中除了该前缀外的其它部分包装到view中，然后调用RequestDispatcher.forward方法进行处理. ContentNegotiatingViewResolver（CNVR)正如前面所说的那样，CNVR自己并不进行视图解析工作，它把这部分工作委托给相应的ViewResolver进行. CNVR支持以下两种策略进行解析： 根据请求的后缀进行解析，比如fred.xml返回xml视图，而fred.pdf返回pdf视图 根据请求的Accept头信息, 但是这种方式在使用浏览器时比较局限，比如在使用FireFox浏览器时，它的Accept头总是被设置为Accept: text/html,application/xhtml+xml,application/xml;q=0.9,/;q=0.8 CNVR获取视图的整个过程如下： CNVR中的每个视图解析器都提供了一些View对象，这些View对象都提供了相应的ContentType属性，这个属性表示该View类能提供的内容类型。在视图解析的第一个步骤，就是将请求的内容类型（Content-Type)，与这些view的ContentType进行匹配，由第一个满足条件的View来进行处理 如果没有视图解析器（关联的View类）能够提供与请求类型相兼容的类型，那么交由CNVR的defaultViews中提供的view进行匹配，由第一个满足匹配条件的view进行处理 以下给出了CNVR的配置样例， 当请求.html时，视图解析器就会根据text/html进行查找，InternalResourceViewResolver提供的View满足这个要求，因此就由这个解析器进行后续的处理; 当请求.atom类型时，视图解析器根据application/atom+xml类型进行查找，匹配到BeanNameViewResolver; 当请求的是.json类型时，视图解析器无法提供相应类型的内容，于是CNVR开始匹配defaultViews属性中匹配的view类，匹配到MappingJackson2JsonView. 123456789101112131415161718&lt;bean class=&quot;org.springframework.web.servlet.view.ContentNegotiatingViewResolver&quot;&gt; &lt;property name=&quot;viewResolvers&quot;&gt; &lt;list&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.BeanNameViewResolver&quot;/&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=&quot;defaultViews&quot;&gt; &lt;list&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.json.MappingJackson2JsonView&quot;/&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id=&quot;content&quot; class=&quot;com.foo.samples.rest.SampleContentAtomView&quot;/&gt; 如果CNVR中没有配置相应的viewResolvers属性，那么它将使用上下文中配置的所有viewResolver. 参考文档 官方参考文档: 官方文档","categories":[],"tags":[{"name":"SpringMVC handlerMapping","slug":"SpringMVC-handlerMapping","permalink":"http://yoursite.com/tags/SpringMVC-handlerMapping/"}]},{"title":"SpringMVC学习(1)","slug":"spring/spring-introduction","date":"2016-06-21T13:00:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/06/21/spring/spring-introduction/","link":"","permalink":"http://yoursite.com/2016/06/21/spring/spring-introduction/","excerpt":"","text":"Spring MVCSpringMVC是Spring框架中自带的MVC实现，它的实现是围绕DispatcherServlet来展开的（后续会对DispatcherServlet的源码进行解读)。DispatcherServlet是一种前端控制器的实现，所有的请求进行一些预处理后，通过它分发给相应的处理器，处理器处理后的结果再返回给前端控制器，由它派发给相应的视图解析器，最后完成响应. SpringMVC中默认的处理器是由@Controller和@RequestMapping标签来实现的. Spring3.0之后，还增加了对RESTful风格的请求的支持. DispatcherServlet正如前方所说的那样，DispatcherServlet是一种前端控制器的实现，它的结构如图所示, 同时它也是标准的JavaEE的servlet实现. 在SpringMVC中，ApplicationContext是有作用域范围的， 每一个DispatcherServlet都有它的webApplicationContext，这些webApplicationContext都继承了root webApplicationContext中定义的所有bean. 通常情况下, rootApplicationContext中包含了基础的bean定义，这些bean在所有的servlet以及context中共享, rootApplicationContext通常由web.xml中的contextConfigLocation定义. DispatcherServlet中特殊的Bean对象在DispatcherServlet中定义了很多特殊类型的对象用来完成处理请求、渲染视图等操作，并且SpringMVC中还定义一系列默认实现，这些默认实现都配置在org.springframework.web.servlet包下的DispatcherServlet.properties文件中. 一旦程序中配置了其中某种类型的实现，这些默认的实现都将会被替代. 下表给出了DispatcherServlet依赖的一些bean类型，这些bean类型也构成了SpringMVC的处理框架, 如下图所示. 类型 描述 HandlerMapping HandlerMapping将请求映射成相应的处理器和一系列的前置、后置处理器 HandlerAdapter HandlerAdapter将各种各样的Handler适配成统一的接口供DispatcherServlet调用，它是一种适配器模式的应用 HandlerExceptionResolver 它将处理过程中的异常映射成视图，以允许一些更精确的异常处理 ViewResolver 它将逻辑视图转化成实际的视图类型","categories":[],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yoursite.com/tags/SpringMVC/"}]},{"title":"SpringMVC学习(2)","slug":"spring/spring-mvc-controller","date":"2016-06-21T13:00:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/06/21/spring/spring-mvc-controller/","link":"","permalink":"http://yoursite.com/2016/06/21/spring/spring-mvc-controller/","excerpt":"","text":"ControllerController提供了service接口中定义的业务的访问途径，它接受用户的输入，并将用户请求委托给service层进行处理，最终将处理结果以视图的形式返回给用户。从Spring2.5以来，提供了注解的方式来实现controller，这些注解包括@Controller, @RequestMapping, @RequestParam, @ModelAttribute，使用这些注解，程序中并不需要实现特定的接口，极大地方便了程序的实现。 @Controller和@RequestMapping@Controller注解意味着被注解类的角色为controller，即MVC中的“C”角色. 配合@RequestMapping注解，SpringMVC会自动扫描这些注解并将相应的请求地址映射到这些类和方法中，举个例子： 123456789101112131415161718192021222324252627@Controller@RequestMapping(\"/appointments\")public class AppointmentsController &#123; @RequestMapping(method = RequestMethod.GET) public Map&lt;String, Appointment&gt; get() &#123; return appointmentBook.getAppointmentsForToday(); &#125; @RequestMapping(path = \"/&#123;day&#125;\", method = RequestMethod.GET) public Map&lt;String, Appointment&gt; getForDay(@PathVariable @DateTimeFormat(iso=ISO.DATE) Date day, Model model) &#123; return appointmentBook.getAppointmentsForDay(day); &#125; @RequestMapping(path = \"/new\", method = RequestMethod.GET) public AppointmentForm getNewForm() &#123; return new AppointmentForm(); &#125; @RequestMapping(method = RequestMethod.POST) public String add(@Valid AppointmentForm appointment, BindingResult result) &#123; if (result.hasErrors()) &#123; return \"appointments/new\"; &#125; appointmentBook.addAppointment(appointment); return \"redirect:/appointments\"; &#125;&#125; 这个代码片断中多次使用了@RequestMapping注解. 第一次是对类进行注解，它意味着类中所有的处理方法路径都是相对于这个路径而言的，在这个例子中，也就是都是相对于/appointments路径. 第二个注解出现在get方法上，同时还增加了method参数，这意味着这个方法在原来类注解的基础上，增加了请求方法的限制，这里只能匹配get方法的请求. 第三个注解出现在getForDay中，它也只能匹配get方法，同时它还使用了URI模板，后续会对URI模板进行深入的探讨. 除此之外，getNewForm方法还对请求路径做了进一步的限制，它只匹配/appointments/new，并且只匹配get方法. 另外，类层级的@RequestMapping注解并不是必须的，如果类没有被它注解，意味着方法中所有的路径都是绝对路径，而不是相对路径. 在Spring3.1之前，@RequestMapping默认先由DefaultAnnotationHandlerMapping处理，再由DefaultAnnotationHandlerAdapter进一步缩小匹配的范围. 在Spring3.1以后，spring提供了新的实现，RequestMappingHandlerMapping和RequestMappingHandlerAdapter，处理器的选择由RequestMappingHandlerMapping直接完成. Spring4.3以后，对@RequestMapping提供了几个变体版本，针对不同的请求方法，提供了相应的mapping注解，比如@GetMapping, @PostMapping, @PutMapping等等，有需要可以查阅相关的文档，这里不做进一步详述. URI模板在使用RequestMapping注解的过程中，可以使用URI模板很方便地获取部分URL地址. URI模板中的变量可以通过@PathVariable注解来获取，如下所示, 当请求/owners/fred地址时，ownerId的值就会被设置成fred. 当@PathVariable注解被用于Map类型的变量时，所有的URI模板变量会自动被填充到map变量中: 123456@GetMapping(\"/owners/&#123;ownerId&#125;\")public String findOwner(@PathVariable String ownerId, Model model) &#123; Owner owner = ownerService.findOwner(ownerId); model.addAttribute(\"owner\", owner); return \"displayOwner\";&#125; 除了变量，还可以在URI模板中使用正则表达式. 具体的语法为{varName: regex}，其中第一部分为定义的变量，第二部分为正则表达式 如下所示，当请求/spring-web/spring-web-3.0.5.jar时，symbolicName会被设置成spring-web, version被映射成3.0.5，而extension被映射成.jar: 1234@RequestMapping(\"/spring-web/&#123;symbolicName:[a-z-]+&#125;-&#123;version:\\\\d\\\\.\\\\d\\\\.\\\\d&#125;&#123;extension:\\\\.[a-z]+&#125;\")public void handle(@PathVariable String version, @PathVariable String extension) &#123; // ...&#125; 当某个请求地址匹配多个URI模板时，匹配的规则按以下进行: 拥有较少URI变量和通配符的URI模板被优先匹配，比如/hotels/{hotel}/有1个变量和1个通配符，因此它比/hotels/{hotel}/*优先匹配 如果变量和通配符数量相等，路径长的被优先匹配，比如/foo/bar比/foo/优先匹配 如果变量和通配符数量相等且长度相等，拥有较长通配符个数的优先匹配， 比如/hotels/{hotel}比/hotels/*优先匹配 除此之外，还有两条例外: /**拥有最低的匹配次序 前置的通配符拥有更低的匹配次序，例如/public/path3/{a}/{b}/{c}比/public/**优先匹配 矩阵变量Spring还支持在URI请求中带上相应的变量，这些变量就被称为矩阵变量(matrix variable). 在spring中，矩阵变量可以有以下三种形式： /cars;color=red;year=2012 /cars;color=red,green,blue;year=2012 /cars;color=red;color=green;color=blue;year=2012 如果要在请求中访问矩阵变量的值，可以使用@MatrixVariable注解来获取. 这个注解还支持指定相应的变量名和矩阵变量名来进一步精确地获取其中的值. @RequestMapping注解方法@RequestMapping注解被用在方法上时，支持许多类型的输入参数，包括以下这些： 类型 描述 类型转换 Request和Response对象 可以选择特定的请求和响应类型，比如HttpServletRequest和HttpServletResponse N/A Session对象 HttpSession类型，表示会话对象 N/A InputStream, OutputStream, Reader, Writer 表示请求和响应的输入输出流对象 N/A HttpMethod 表示当前请求方法对象 N/A 注解参数 包括@PathVariable, @MatrixVariable, @RequestBody, @RequestParam, @RequestAttribute, @RequestHeader注解, 请求中的属性或参数都会被自动转化成注解所标注的参数类型 其中@RequestBody注解使用的是HttpMessageConverter接口来进行转换，其它的注解则由 WebDataBinder和Formatter来完成||HttpEntity|包括请求参数和请求头信息|类型转换由HttpMessageConverter完成||Model, Map, ModelMap|增强视图的模型内容|N/A| 支持的返回类型包括： 类型 描述 类型转换 ModelAndView 包括返回的模型和视图对象 N/A Model, Map 返回的模型对象，视图类由默认的RequestToViewNameTranslator来进行解析得到 N/A View 返回的视图对象，模型对象可以由参数中的Model类型的参数来提供 N/A String 返回的逻辑视图，可以由相应的ViewResolver接口解析得到实际的视图 N/A void 这种情况下，响应的内容由程序直接通过Response对象输出，或者由RequestToViewNameTranslator解析得到 N/A HttpEntity 包括响应头和响应消息体的内容 消息体的内容由HttpMessageConverter完成类型转换 HttpHeaders 表示当前响应不包含消息体，只有响应头 N/A @RequestBody和@ResponceBody@RequestBody和@ResponceBody分别代表了请求和响应的消息体，当参数被RequestBody注解，或者响应的对象被ResonseBody注解时，Spring会自动根据convesionService的配置转化成相应的对象或消息体. 事实上，在spring中消息体到对象或者由对象到响应消息体之间的转换全部由HttpMessageConverter完成，包括RequestBody、ResponseBody以及HttpEntity中的消息体. RequestMappingHandlerAdapter自动注册了以下几个converters,如果需要可以自行定义和配置converter ByteArrayHttpMessageConverter StringHttpMessageConverter FormHttpMessageConverter SourceHttpMessageConverter @RestController当需要在spring中实现RESTful类型的接口时，可以使用@RestController. 它是@Controller和@ResponseBody两个注解的组合，可以很方便地实现RESTful风格的接口 方法参数与类型转换请求中的参数都是字符串类型的，当它们转换成其它类型时，就需要使用类型转换，这些参数包括请求参数，请求头，cookie信息以及path variable变量. 在Spring中，提供了WebDataBinder来实现相应的类型转换. 通过注册Formatter接口的实现来自定义类型转换的过程. 类型转换的过程可以通过两种方式进行： 使用@InitBinder注解 使用WebBindingInitializer @InitBinder注解使用@InitBinder注解可以将方法定义为类型转换的实现，它定义了将请求参数转换成相应类型的具体方法，通过registerCustomEditor或者addCustomFormatter来实现注册. 它接受的参数同@RequestMapping基本相同，而且不能有返回值. 这种方式只在声明@InitBinder的controller类中有用. 123456789101112131415@Controllerpublic class MyFormController &#123; @InitBinder protected void initBinder(WebDataBinder binder) &#123; SimpleDateFormat dateFormat = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); dateFormat.setLenient(false); binder.registerCustomEditor(Date.class, new CustomDateEditor(dateFormat, false)); //spring4.2后支持的方式 binder.addCustomFormatter(new DateFormatter(&quot;yyyy-MM-dd&quot;)); &#125; // ...&#125; WebBindingInitializer通过WebBindingInitializer可以将类型转换的配置放到RequestMappingAdapter， 通过修改默认的配置自定义类型转换的过程. 123456&lt;bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter&quot;&gt; &lt;property name=&quot;cacheSeconds&quot; value=&quot;0&quot;/&gt; &lt;property name=&quot;webBindingInitializer&quot;&gt; &lt;bean class=&quot;org.springframework.samples.petclinic.web.ClinicBindingInitializer&quot;/&gt; &lt;/property&gt;&lt;/bean&gt; 异步请求处理从Servlet3.0规范开始就定义了异步请求处理的方法. Spring框架也从3.2开始支持3.0规范. 在Spring中，可以用两种方式来实现对请求的异步处理： Callable: 请求到达服务器后，服务器直接返回callable对象，并且servlet的处理线程退出，从而可以接着处理后续进来的请求。后续的处理由threadPoolTaskExecutor中的线程接管，当工作线程处理完成后，结果通过callable回调给servlet容器的线程，再由这个线程返回到客户端. DeferredResult： 整个处理的过程与Callable基本一致，唯一不同的是，Callable的结果由容器管理的工作线程完成后交还给servlet容器响应. 但deferredResult的响应结果则由其它的任意线程进行设置，通过它的setResult方法，任何方法都可以将处理的结果设置到deferredResult中 12345678910111213141516171819202122232425262728293031@RequestMapping(&quot;query&quot;)@ResponseBodypublic Callable&lt;Person&gt; asyn() &#123; return () -&gt; &#123; //延迟两秒响应 Thread.sleep(2000); return buildPerson(); &#125;;&#125;@RequestMapping(&quot;queryDefered&quot;)@ResponseBodypublic DeferredResult&lt;Person&gt; asynDeferredResult() &#123; DeferredResult&lt;Person&gt; deferredResult = new DeferredResult&lt;&gt;(5000L, buildPerson(&quot;Essviv&quot;)); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; deferredResult.setResult(buildPerson()); &#125; &#125;).start(); return deferredResult;&#125; 异步处理流程异步请求处理的整个过程包括： 控制器返回callable或者deferredResult SpringMVC开始在工作线程中处理请求，对于Callable，工作线程由容器管理；对于deferredResult，工作线程由任意线程实现 DispatcherServer及所有的过滤器线程，但是response仍然打开着，等待进一步响应 Callable返回相应的响应并把响应重新分发给dispatchServlet DispatcherServlet被重新唤起，并将callable的内容输出到response中 在异步处理的时候，如果出现异常，异常处理的方式与同步处理表现一致. 在DeferredResult中，也可以通过setErrorResult来设置异常信息 配置方法那么，在spring中如何配置异步处理请求呢? 简单来讲，分为两步： 设置servlet的版本为3.0 在servlet及相应的filter配置中加上true 在controller中返回callable或者deferredResult 参考文献Controller的官方文档： 官方文档","categories":[],"tags":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yoursite.com/tags/SpringMVC/"}]},{"title":"XStream学习(3)","slug":"xstream-converter","date":"2016-06-15T13:24:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/06/15/xstream-converter/","link":"","permalink":"http://yoursite.com/2016/06/15/xstream-converter/","excerpt":"","text":"转换器我们从最简单的例子开始吧,创建一个简单的对象，设置别名，然后输出： 12345678910111213141516171819202122package com.thoughtworks.xstream.examples;public class Person &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125;//设置别名xStream.alias(&quot;person&quot;, Person.class);//输出结果&lt;person&gt; &lt;name&gt;Guilherme&lt;/name&gt;&lt;/person&gt; 创建转换器接下来我们要开始创建Person类的转换器，转换器要实现Converter接口. 这个转换器必须要完成以下三个功能： 支持Person类的转换 将Person类转换成XML（序列化） 将XML转换成Person（反序列化） 以下是Person类转换器的代码，在序列化的过程中，可以使用startNode/endNode来声明新的节点;在反序列化的过程中，可以使用moveDown/moveUp在结点树中遍历；在创建完转换器的代码后，可以将它注册到XStream中，并观察它的输出: 123456789101112131415161718192021222324252627282930313233343536373839package com.thoughtworks.xstream.examples;import com.thoughtworks.xstream.converters.Converter;import com.thoughtworks.xstream.converters.MarshallingContext;import com.thoughtworks.xstream.converters.UnmarshallingContext;import com.thoughtworks.xstream.io.HierarchicalStreamReader;import com.thoughtworks.xstream.io.HierarchicalStreamWriter;public class PersonConverter implements Converter &#123; public boolean canConvert(Class clazz) &#123; return clazz.equals(Person.class); &#125; public void marshal(Object value, HierarchicalStreamWriter writer, MarshallingContext context) &#123; Person person = (Person) value; writer.startNode(&quot;fullname&quot;); writer.setValue(person.getName()); writer.endNode(); &#125; public Object unmarshal(HierarchicalStreamReader reader, UnmarshallingContext context) &#123; Person person = new Person(); reader.moveDown(); person.setName(reader.getValue()); reader.moveUp(); return person; &#125;&#125;//注册转换器xStream.registerConverter(new PersonConverter());//输出结果&lt;person&gt; &lt;fullname&gt;Guilherme&lt;/fullname&gt;&lt;/person&gt; 另一种转换器如果只是想把某个对象转化成字符串，那么有一种简单的实现方式, 实现AbstractSingleValueConverter接口. 1234567891011121314151617181920package com.thoughtworks.xstream.examples;import com.thoughtworks.xstream.converters.basic.AbstractSingleValueConverter;public class PersonConverter extends AbstractSingleValueConverter &#123; public boolean canConvert(Class clazz) &#123; return clazz.equals(Person.class); &#125; public Object fromString(String str) &#123; Person person = new Person(); person.setName(string); return person; &#125;&#125;//输出结果&lt;person&gt;Guilherme&lt;/person&gt; 参考文献XStream的官方转换器文档: 官方文档","categories":[],"tags":[{"name":"XStream 转换器","slug":"XStream-转换器","permalink":"http://yoursite.com/tags/XStream-转换器/"}]},{"title":"XStream学习(2)","slug":"xstream-annotation","date":"2016-06-14T13:15:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/06/14/xstream-annotation/","link":"","permalink":"http://yoursite.com/2016/06/14/xstream-annotation/","excerpt":"","text":"注解在上一章中，我们学习了如何使用XStream的别名机制来更好的控制输出，但是有时候这种控制略显烦琐，因此XStream也提供了相应的注解支持. 本章主要展示了如何使用XStream提供的注解机制来更简单有效地控制相应的输出. 首先我们先定义消息模式，并输出最基本的XML格式： 1234567891011121314151617181920212223242526package com.thoughtworks.xstream;public class RendezvousMessage &#123; private int messageType; public RendezvousMessage(int messageType) &#123; this.messageType = messageType; &#125;&#125;//输出代码package com.thoughtworks.xstream;public class Tutorial &#123; public static void main(String[] args) &#123; XStream stream = new XStream(); RendezvousMessage msg = new RendezvousMessage(15); System.out.println(stream.toXML(msg)); &#125;&#125;//输出结果&lt;com.thoughtworks.xstream.RendezvousMessage&gt; &lt;messageType&gt;15&lt;/messageType&gt;&lt;/com.thoughtworks.xstream.RendezvousMessage&gt; 类别名和属性别名注解XStream提供了@XStreamAlias注解，它同时提供了alias方法和aliasField方法提供的功能，但XStream并不会自动读取这个注解，必须通过processAnnotation方法显式地指定XStream读取这个注解. 12345678910111213141516171819202122@XStreamAlias(&quot;message&quot;)class RendezvousMessage &#123; @XStreamAlias(&quot;type&quot;) private int messageType; public RendezvousMessage(int messageType) &#123; this.messageType = messageType; &#125;&#125;//输出代码public static void main(String[] args) &#123; XStream stream = new XStream(); xstream.processAnnotations(RendezvousMessage.class); RendezvousMessage msg = new RendezvousMessage(15); System.out.println(stream.toXML(msg)); &#125;//输出结果&lt;message&gt; &lt;type&gt;15&lt;/type&gt;&lt;/message&gt; 隐式集合注解现在让我们来试试如何使用注解完成隐式集合的功能，首先为消息模式添加列表属性，最终得到的输出结果为: 12345678910111213141516171819202122232425@XStreamAlias(&quot;message&quot;)class RendezvousMessage &#123; @XStreamAlias(&quot;type&quot;) private int messageType; private List&lt;String&gt; content; public RendezvousMessage(int messageType, String ... content) &#123; this.messageType = messageType; this.content = Arrays.asList(content); &#125; &#125;//输出结果&lt;message&gt; &lt;type&gt;15&lt;/type&gt; &lt;content class=&quot;java.util.Arrays$ArrayList&quot;&gt; &lt;a class=&quot;string-array&quot;&gt; &lt;string&gt;firstPart&lt;/string&gt; &lt;string&gt;secondPart&lt;/string&gt; &lt;/a&gt; &lt;/content&gt;&lt;/message&gt; 这显然不是我们想要的输出结果，XStream提供了@XStreamImplicit注解来提供和addImplicitCollection对应的功能.在加上这个注解后，输出的结果变成了: 12345678910111213141516171819202122@XStreamAlias(&quot;message&quot;)class RendezvousMessage &#123; @XStreamAlias(&quot;type&quot;) private int messageType; @XStreamImplicit private List&lt;String&gt; content; public RendezvousMessage(int messageType, String... content) &#123; this.messageType = messageType; this.content = Arrays.asList(content); &#125;&#125;//输出结果&lt;message&gt; &lt;type&gt;15&lt;/type&gt; &lt;a class=&quot;string-array&quot;&gt; &lt;string&gt;firstPart&lt;/string&gt; &lt;string&gt;secondPart&lt;/string&gt; &lt;/a&gt;&lt;/message&gt; 离期望的输出近了一点，但还不是最终的样子，我们期望那个’a‘不要出现，同时期望能够给每个元素取个名字，比如part. XStream为XStreamImplicit注解了相应的属性设置，itemFieldName可以用来设计集合中每个元素的名称，将它设置为part后的输出结果为: 12345678910111213141516171819202122@XStreamAlias(&quot;message&quot;)class RendezvousMessage &#123; @XStreamAlias(&quot;type&quot;) private int messageType; @XStreamImplicit(itemFieldName=&quot;part&quot;) private List&lt;String&gt; content; public RendezvousMessage(int messageType, String... content) &#123; this.messageType = messageType; this.content = Arrays.asList(content); &#125;&#125;//输出结果&lt;message&gt; &lt;type&gt;15&lt;/type&gt; &lt;part&gt;firstPart&lt;/part&gt; &lt;part&gt;secondPart&lt;/part&gt;&lt;/message&gt; 变换器注解首先我们先为消息模型增加个时间字段，并查看下输出的结果: 123456789101112131415161718192021222324@XStreamAlias(&quot;message&quot;)class RendezvousMessage &#123; @XStreamAlias(&quot;type&quot;) private int messageType; @XStreamImplicit(itemFieldName=&quot;part&quot;) private List&lt;String&gt; content; private Date time; public RendezvousMessage(int messageType, String... content) &#123; this.messageType = messageType; this.content = Arrays.asList(content); &#125;&#125;//输出结果&lt;message&gt; &lt;type&gt;15&lt;/type&gt; &lt;part&gt;firstPart&lt;/part&gt; &lt;part&gt;secondPart&lt;/part&gt; &lt;time&gt;2016-06-14 14:02:08.305 UTC&lt;/time&gt;&lt;/message&gt; 如果我们希望将time属性输出成系统的毫秒数该怎么办呢？XStream为我们提供了@XStreamConverter注解来解决这个问题，它的作用是自定义某个类的转化器.另外，@XStreamConverter注解还可以通过注解的属性给相应的转化器输入构造函数，具体可以查看注解的javadoc说明.以下的例子首先定义了Date类型的转化器DateConverter，并设置time使用该转化器，最后的输出结果为: 12345678910111213141516171819202122232425262728293031323334public class DateConverter implements Converter &#123; @Override public void marshal(Object source, HierarchicalStreamWriter writer, MarshallingContext context) &#123; Date date = (Date) source; writer.setValue(String.valueOf(date.getTime())); &#125; @Override public Object unmarshal(HierarchicalStreamReader reader, UnmarshallingContext context) &#123; String value = null; reader.moveDown(); value = reader.getValue(); reader.moveUp(); return new Date(NumberUtils.toLong(value)); &#125; @Override public boolean canConvert(Class type) &#123; return type.equals(Date.class); &#125;&#125;@XStreamConverter(DateConverter.class)private Date time;//输出结果&lt;message&gt; &lt;type&gt;15&lt;/type&gt; &lt;part&gt;firstPart&lt;/part&gt; &lt;part&gt;secondPart&lt;/part&gt; &lt;time&gt;1465913336042&lt;/time&gt;&lt;/message&gt; 属性注解在有些场景下，可能希望将对象的某个字段显示成结点的属性而不是子结点，XStream提供了@XStreamAsAttribute来实现属性注解的功能. 1234567@XStreamAlias(&quot;type&quot;)@XStreamAsAttributeprivate int messageType;//输出结果&lt;message type=&quot;15&quot;&gt;&lt;/message&gt; 在另一些场景下，可能希望将对象的某个字段作为结点的值,而将其它全部字段作为结点的属性输出. XStream提供了ToAttributedValueConverter类来实现这个功能，它指定某个字段作为结点的值，其它字段作为属性输出但是，这里有个前提，由于结点的属性只能是字符类型，因此那些作为属性输出的字段必须能够转化成字符类型. 如果某个字段不能完成这种转换，必须通过显式指定SingleValueConverter接口实现. 1234567891011121314151617181920212223242526@XStreamAlias(&quot;message&quot;)@XStreamConverter(value=ToAttributedValueConverter.class, strings=&#123;&quot;content&quot;&#125;)class RendezvousMessage &#123; @XStreamAlias(&quot;type&quot;) private int messageType; //这里的list并不能自动转化成字符类型，因此必须显式地指定转化器，否则输出会报错 @XStreamConverter(SomeImplementOfSingleValueConverter.class) private List&lt;String&gt; content; @XStreamConverter(value=BooleanConverter.class, booleans=&#123;false&#125;, strings=&#123;&quot;yes&quot;, &quot;no&quot;&#125;) private boolean important; @XStreamConverter(SingleValueCalendarConverter.class) private Calendar created = new GregorianCalendar(); public RendezvousMessage(int messageType, boolean important, String... content) &#123; this.messageType = messageType; this.important = important; this.content = Arrays.asList(content); &#125;&#125;//输出&lt;message type=&quot;15&quot; important=&quot;no&quot; created=&quot;1154097812245&quot;&gt;This is the message content.&lt;/message&gt; 忽略字段有些时候，对象的部分属性并不需要输出到XML中，这时候可以通过XStream提供的@XStreamOmitField注解来完成忽略输出的功能. 自动检测注解在上面的描述中我们提到，在设置了类的注解后，调用代码中必须显式地调用processAnnotation方法来通知XStream来处理这些注解，这种处理有时候略显麻烦. XStream还提供了自动检测注解的方法autodetectAnnotations. 但是，如果调用了processAnnotation方法，那么自动检测的功能就自动被关闭了. 另外，XStream自动检测还有一些弊端，具体可以查阅“参考文献”. 参考文献XStream官方注解文档: 注解文档","categories":[],"tags":[{"name":"XStream 注解","slug":"XStream-注解","permalink":"http://yoursite.com/tags/XStream-注解/"}]},{"title":"XStream学习(1)","slug":"xstream-alias","date":"2016-06-14T13:15:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/06/14/xstream-alias/","link":"","permalink":"http://yoursite.com/2016/06/14/xstream-alias/","excerpt":"","text":"XStream概览XStream是用来将对象与XML进行互相转换的第三方库. 它的主要特点包括： 简单易用. 无需映射. 性能. 简洁的XML. … 错误信息的输出. 支持与JSON格式的转换. 别名假设我们定义了以下的XML格式, 需要通过XStream进行读写： 123456789101112&lt;blog author=&quot;Guilherme Silveira&quot;&gt; &lt;entry&gt; &lt;title&gt;first&lt;/title&gt; &lt;description&gt;My first blog entry.&lt;/description&gt; &lt;/entry&gt; &lt;entry&gt; &lt;title&gt;tutorial&lt;/title&gt; &lt;description&gt; Today we have developed a nice alias tutorial. Tell your friends! NOW! &lt;/description&gt; &lt;/entry&gt;&lt;/blog&gt; 首先，我们需要根据XML格式定义以下两个对象模型: 12345678910111213141516171819202122232425262728293031323334353637383940package com.thoughtworks.xstream;public class Blog &#123; private Author writer; private List entries = new ArrayList(); public Blog(Author writer) &#123; this.writer = writer; &#125; public void add(Entry entry) &#123; entries.add(entry); &#125; public List getContent() &#123; return entries; &#125;&#125;package com.thoughtworks.xstream;public class Author &#123; private String name; public Author(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125;&#125;package com.thoughtworks.xstream;public class Entry &#123; private String title, description; public Entry(String title, String description) &#123; this.title = title; this.description = description; &#125;&#125; 接着就可以通过XStream来进行XML格式的输出： 12345678910public static void main(String[] args) &#123; Blog teamBlog = new Blog(new Author(&quot;Guilherme Silveira&quot;)); teamBlog.add(new Entry(&quot;first&quot;,&quot;My first blog entry.&quot;)); teamBlog.add(new Entry(&quot;tutorial&quot;, &quot;Today we have developed a nice alias tutorial. Tell your friends! NOW!&quot;)); XStream xstream = new XStream(); System.out.println(xstream.toXML(teamBlog));&#125; 最终我们得到的输出是这样的, 似乎看上去和我们想要的结果有点不一样： 1234567891011121314151617&lt;com.thoughtworks.xstream.Blog&gt; &lt;writer&gt; &lt;name&gt;Guilherme Silveira&lt;/name&gt; &lt;/writer&gt; &lt;entries&gt; &lt;com.thoughtworks.xstream.Entry&gt; &lt;title&gt;first&lt;/title&gt; &lt;description&gt;My first blog entry.&lt;/description&gt; &lt;/com.thoughtworks.xstream.Entry&gt; &lt;com.thoughtworks.xstream.Entry&gt; &lt;title&gt;tutorial&lt;/title&gt; &lt;description&gt; Today we have developed a nice alias tutorial. Tell your friends! NOW! &lt;/description&gt; &lt;/com.thoughtworks.xstream.Entry&gt; &lt;/entries&gt;&lt;/com.thoughtworks.xstream.Blog&gt; 类别名首先我们需要把类似于’com.thoughtworks.xstream.Blog’这样的包名给去掉，XStream给我们提供了alias方法来实现类的别名功能: 12xstream.alias(&quot;blog&quot;, Blog.class);xstream.alias(&quot;entry&quot;, Entry.class); 现在再看来看看我们的输出, 现在它变成了以下这样，离我们期望的结果似乎近了一点： 1234567891011121314151617&lt;blog&gt; &lt;writer&gt; &lt;name&gt;Guilherme Silveira&lt;/name&gt; &lt;/writer&gt; &lt;entries&gt; &lt;entry&gt; &lt;title&gt;first&lt;/title&gt; &lt;description&gt;My first blog entry.&lt;/description&gt; &lt;/entry&gt; &lt;entry&gt; &lt;title&gt;tutorial&lt;/title&gt; &lt;description&gt; Today we have developed a nice alias tutorial. Tell your friends! NOW! &lt;/description&gt; &lt;/entry&gt; &lt;/entries&gt;&lt;/blog&gt; 属性别名现在我们希望把writer属性改成author，同样地，XStream提供了aliasField来实现类属性的别名设置, 现在的输出变成了： 12345678910111213141516171819xstream.aliasField(&quot;author&quot;, Blog.class, &quot;writer&quot;);&lt;blog&gt; &lt;author&gt; &lt;name&gt;Guilherme Silveira&lt;/name&gt; &lt;/author&gt; &lt;entries&gt; &lt;entry&gt; &lt;title&gt;first&lt;/title&gt; &lt;description&gt;My first blog entry.&lt;/description&gt; &lt;/entry&gt; &lt;entry&gt; &lt;title&gt;tutorial&lt;/title&gt; &lt;description&gt; Today we have developed a nice alias tutorial. Tell your friends! NOW! &lt;/description&gt; &lt;/entry&gt; &lt;/entries&gt;&lt;/blog&gt; 隐式集合再来看看entries的输出，XStream引入了“隐式集合”的概念，当遇到不需要显示集合根结点的情况时，可以将它映射成隐式集合.在上述的例子中，entries是个列表，默认输出时，会将entries作为集合的根结点，有时候这种输出并不是我们期望的，那么如何将它去掉呢？XStream中提供了addImplicitCollection方法来解决这个问题， 再次输出的结果为： 1234567891011121314151617xstream.addImplicitCollection(Blog.class, &quot;entries&quot;);&lt;blog&gt; &lt;author&gt; &lt;name&gt;Guilherme Silveira&lt;/name&gt; &lt;/author&gt; &lt;entry&gt; &lt;title&gt;first&lt;/title&gt; &lt;description&gt;My first blog entry.&lt;/description&gt; &lt;/entry&gt; &lt;entry&gt; &lt;title&gt;tutorial&lt;/title&gt; &lt;description&gt; Today we have developed a nice alias tutorial. Tell your friends! NOW! &lt;/description&gt; &lt;/entry&gt;&lt;/blog&gt; 属性别名有时候我们可能会希望将类的某个字段输出成结点的属性，而不是它的子结点，比如在上述的例子中，可以将writer字段输出成属性. XStream提供了useAttributeFor方法将类的字段作为结点属性输出 12stream.useAttributeFor(Blog.class, &quot;writer&quot;);xstream.aliasField(&quot;author&quot;, Blog.class, &quot;writer&quot;); 但是，如果要将writer输出成结点的属性，还需要完成一个转换. 那就是Author类如何转换成String值，因为结点的属性值只能是字符类型. XStream提供了SingleValueConverter接口来实现类与字符类型之间的转换功能. 因此只要能提供一个converter能将author转化成字符类型，就可以顺利将writer字段作为结点的属性输出. 定义完转化器之后，将它注册到XStream中，就可以得到相应的输出: 12345678910111213141516171819202122232425262728293031class AuthorConverter implements SingleValueConverter &#123; public String toString(Object obj) &#123; return ((Author) obj).getName(); &#125; public Object fromString(String name) &#123; return new Author(name); &#125; public boolean canConvert(Class type) &#123; return type.equals(Author.class); &#125;&#125;//将新定义的转化器注册到XStream中xstream.registerConverter(new AuthorConverter());//输出&lt;blog author=&quot;Guilherme Silveira&quot;&gt; &lt;entry&gt; &lt;title&gt;first&lt;/title&gt; &lt;description&gt;My first blog entry.&lt;/description&gt; &lt;/entry&gt; &lt;entry&gt; &lt;title&gt;tutorial&lt;/title&gt; &lt;description&gt; Today we have developed a nice alias tutorial. Tell your friends! NOW! &lt;/description&gt; &lt;/entry&gt;&lt;/blog&gt; 包名别名有的时候我们可以希望为包名设置别名，XStream提供了aliasPackage来设置包名的别名 1234567891011121314151617181920xstream.aliasPackage(&quot;my.company&quot;, &quot;org.thoughtworks&quot;);//输出&lt;my.company.xstream.Blog&gt; &lt;author&gt; &lt;name&gt;Guilherme Silveira&lt;/name&gt; &lt;/author&gt; &lt;entries&gt; &lt;my.company.xstream.Entry&gt; &lt;title&gt;first&lt;/title&gt; &lt;description&gt;My first blog entry.&lt;/description&gt; &lt;/my.company.xstream.Entry&gt; &lt;my.company.xstream.Entry&gt; &lt;title&gt;tutorial&lt;/title&gt; &lt;description&gt; Today we have developed a nice alias tutorial. Tell your friends! NOW! &lt;/description&gt; &lt;/my.company.xstream.Entry&gt; &lt;/entries&gt;&lt;/my.company.xstream.Blog&gt; 参考文献XStream别名官方文档: 别名","categories":[],"tags":[{"name":"XStream 别名","slug":"XStream-别名","permalink":"http://yoursite.com/tags/XStream-别名/"}]},{"title":"markdown","slug":"doc/markdown","date":"2016-05-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/25/doc/markdown/","link":"","permalink":"http://yoursite.com/2016/05/25/doc/markdown/","excerpt":"","text":"#Markdown ##段落和换行 段落前后要有一个以上的空行 换行可以通过在行尾添加两个以上的空格来实现 这是一个新的段落 这个地方不会出现断行 但这个地方会出现断行 ##标题 Setext: ===和— atx: #号 ##引用引用可以通过“&gt;”来实现 这是个引用的段落这还是个引用的段落 ##列表列表可以通过加号、星号和减号来实现 加号选项1 加号选项2 星号选项1 星号选项2 星号选项3 加号选项3 减号选项1 减号选项2 减号选项3 ##代码代码可以通过反单引号(`)来实现 public static void main(String[] args) throws IOException { final String markdownFilename = &quot;/markdown.txt&quot;; final String htmlFilename = &quot;C:\\\\Users\\\\Lenovo\\\\Desktop\\\\markdown.html&quot;; File file = new File(Markdown.class.getResource(markdownFilename).getFile()); String html = new PegDownProcessor(Extensions.ALL).markdownToHtml(FileUtils.readFileToString(file)); FileUtils.writeStringToFile(new File(htmlFilename), html); System.out.println(&quot;OK&quot;); } ##分隔线分隔线可以通过在一行中超过三个以上的星号，减号或底线来完成 下面会有一条横线， 是用星号画出来的 下面也会有一条横线，是用底线画出来的 下面还会有一条横线，是用减号画出来的##链接 [an example](hyperlink)百度 谷歌 [an example][id][id]: hyperlink百度 谷歌 ##图片图片引用的格式： ![alt text](path) ##强调强调可以通过在文字前后加星号或者下划线来完成 某某很帅某某真的很帅","categories":[],"tags":[]},{"title":"JAXB","slug":"SOA/JAXB","date":"2016-05-23T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/23/SOA/JAXB/","link":"","permalink":"http://yoursite.com/2016/05/23/SOA/JAXB/","excerpt":"","text":"JAXB架构 标签 @XmlRootElement: 根元素 @XmlElement: 用于setter方法 @XmlAttribute: 表示将这个字段作为元素的属性 @XmlType: propOrder属性的名称 @XmlJavaTypeAdapter: 用于复杂的java类型，或者当Jaxb输出的格式不是理想的输出时，就可以通过自定义adapter的方式定义输出的内容与格式 @XmlAccessorType: 指定用于生成XML的元素有哪些，默认是public_member，可以指定的包括field, property, public_member, none. 代码 JaxbContext: 提供了jaxb的API入口，不管是marshaller和unmarshaller，均可以由它产生 Marshaller/Unmarshaller: 可以认为是编码与解码器，由jaxbContext生成，可以设置相应的属性（如格式化输出等）,并且提供了由java对象与xml表达之间的转换操作. XmlAdapter: 这个接口提供了java类与xml格式输出的自定义输出接口，marshal与unmarshal分别定义了输入输出.XmlAdapter接口定义了在内存中如何通过valueType来表示boundType. 参考文献 https://www.javacodegeeks.com/2015/04/%E7%94%A8%E4%BA%8Ejava%E5%92%8Cxml%E7%BB%91%E5%AE%9A%E7%9A%84jaxb%E6%95%99%E7%A8%8B.html 示例代码 https://github.com/Essviv/spring/tree/master/src/main/java/com/cmcc/syw/jaxb","categories":[],"tags":[]},{"title":"RabbitMQ的安装","slug":"消息队列/rabbitMQ/RabbitMQ的安装","date":"2016-05-17T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/17/消息队列/rabbitMQ/RabbitMQ的安装/","link":"","permalink":"http://yoursite.com/2016/05/17/消息队列/rabbitMQ/RabbitMQ的安装/","excerpt":"","text":"RabbitMQ的安装 安装RMQ后，需要启用后台管理插件 rabbitmq-plugins list: 查看插件列表 rabbitmq-plugins enable plugins-name: 启用某个插件 rabbitmq-plugins disable plugins-name: 禁用某个插件 后台管理默认的端口为15672， 默认的用户名为guest, 密码为guest， 并且它具有所有的操作权限 可以通过rabbmitmqctl命令来操作用户，并给指定的用户赋相应的角色和权限","categories":[],"tags":[]},{"title":"JAVA-IO学习","slug":"IO/java-io-model","date":"2016-05-07T07:44:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/07/IO/java-io-model/","link":"","permalink":"http://yoursite.com/2016/05/07/IO/java-io-model/","excerpt":"","text":"IO相关概念 阻塞：在发起IO操作之后，线程被阻塞，直到相应的IO操作完成才会返回 非阻塞： 在发起IO操作之后，线程不会被阻塞并且立即返回 同步： 在发起IO操作之后，在没有得到结果之前，调用都不会返回（注意，这里不返回不代表就一定阻塞了，应用也可以处于非阻塞状态），调用一旦返回了，IO操作的结果也就得到了。换句话说，就是由调用者（或应用）主动等待IO操作的结果， Reactor模式就属性这种模式 异步： 在发起IO操作之后，应用程序直接返回，并不等待IO操作的结果，而是由被调用者（通常是系统）在IO操作完成后，通过通知、回调等方式告知应用程序。 Proactor就属性这种模式 从上面的定义可以看出，同步和异步的区别在于IO的调用方是否需要主动地等待数据，在同步操作中，应用需要主动将数据从系统内核空间拷贝到应用空间，并且在这个过程中会出现block状态；而异步操作中，应用调用完IO操作后，就可以执行其它的操作了，系统在将数据拷贝到应用空间完成后，通过回调和通知等方式告知应用，应用再开始对这些数据进行相应的处理. IO模型IO模型大体上可分为以下五类： 阻塞式IO(BIO) 非阻塞式IO(NIO) 多路复用 信息驱动（不常用，略） 异步IO(AIO) 它们之间的比较： IO模型图: 感觉这里的IO多路复用更应该属于“同步阻塞”，但不知道为什么这里被划分为异步阻塞 一个IO操作其实分成了两个步骤：发起IO请求和实际的IO操作。同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果实际的IO读写阻塞请求进程，那么就是同步IO。阻塞IO和非阻塞IO的区别在于第一步，发起IO请求是否会被阻塞，如果阻塞直到完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 参考文献 概念比较1： IO - 同步，异步，阻塞，非阻塞 （亡羊补牢篇） 概念比较2： 大话同步/异步、阻塞/非阻塞 AIO简介： AIO简介 BIO, NIO和AIO的理解： BIO, NIO和AIO的理解","categories":[],"tags":[{"name":"java AIO BIO NIO","slug":"java-AIO-BIO-NIO","permalink":"http://yoursite.com/tags/java-AIO-BIO-NIO/"}]},{"title":"JAVA-IO学习","slug":"IO/java-nio-2","date":"2016-05-07T05:40:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/07/IO/java-nio-2/","link":"","permalink":"http://yoursite.com/2016/05/07/IO/java-nio-2/","excerpt":"","text":"buffer1.属性: capacity, position, limit, mark capacity: 缓冲区的容量大小 position: 当前缓冲区的游标位置，也就是下一个读或写的位置 limit: 缓冲区读写的上限位置，代表了可读写的最多数据量，在写模式，这个值一般和capacity一样 mark: 缓冲区的标记位置，mark()方法将缓冲区当前的游标位置记录下来，后续可以通过reset()方法将游标重置到这个位置上 2.分类 缓冲区的分类比较简洁，基本上可以按数据类型进行划分，比如ByteBuffer, CharBuffer, DoubleBuffer, IntBuffer等等，但是有一个是特别值得注意的， MappedByteBuffer. 具体的使用场景和方法可以参见TODO. 3.操作 put/get: 两个方法都有两种变体. 一种是基于相对位置的（即不带参数的）,这种方式会改变buffer当前的游标位置，另一种是基于绝对位置的，这种方式不会改变游标的当前位置. allocate, wrap： 获取buffer的两种方式，一种是直接分配相应大小的缓冲区，另一种是将现有的数组进行包装，注意，这种情况下，wrap得到的缓冲区当中的数组即为传给wrap函数的数组，意思就是如果修改了这个数组的值，那么buffer的值也就被修改了. 反之亦然. flip, rewind, clear: 这些操作都将position的值置为0， flip将limit设置成当前position的值，所以它一般用来从写模式切换成读模式; rewind将position的值置为0，但它不会改变limit； clear将position置为0，并且将limit置为capacity，因此它经常用来从读模式切换回写模式. remaining, hasRemaining: 获取和判断从当前位置到缓冲区上界的元素数量. compact: 回收已经读取过的缓冲区数据，保留未被读取的缓冲区数据，也就是保留position~limit之间的数据，将它们复制到数组开始部分，并将position置于下一个能够读写的位置上，将limit置于capacity的位置. mark/reset: 标记和恢复当前游标的位置 4.视图缓冲区 视图缓冲区和原来的缓冲区共享数据元素. duplicate: 复制一份缓冲区，两者拥有独立的position, limit, capacity属性，但共享同一个数组，也就是说，对其中一个缓冲区的修改会反映到另一个缓冲区中 asReadOnlyBuffer: 创建缓冲区的只读视图，除了不能执行写操作，以及readOnly返回true之外，其它的都和原来的缓冲区保持一致. 5.字节顺序 big-endian: 大端字节序，最高字节（most significant byte)存储于低位地址，最低字节（least significant byte)存储于高位地址 little-endian: 小端字节序，最高字节存储于高位地址，最低字节存储于低位地址 channel channel–&gt;buffer, buffer–&gt;channel 多路复用的概念 channel与stream的不同： channel是双向的，而stream是单向的 channel可以是异步的 channel读写的目标都是buffer channel可以通过Files等对象获取得到 channel的类型可以分为两大类： 一类为FileChannel， 一类为SocketChannel, SocketChannel又进一步细分为SocketChannel, ServerSocketChannel, DatagramChannel selector NIO: channel &amp; buffer NIO: non-blocking read &amp; write selector: monitor multiple channels selectionKey: SelectableChannel注册到selector时，将返回相应的selectionKey，它是两者间关系的管理工具 SelectableChannel: 可以被注册到selector中的一种通道，所有的socket通道都属于这种类型， 相反，fileChannel不属于这种类型. 参考文献 JAVA NIO： JAVA NIO O’Reilly%20-%20O’Reilly%20-%20Java%20NIO.pdf) JAVA NIO Turtorial: Jenkov NIO Turtorial","categories":[],"tags":[{"name":"java nio selector","slug":"java-nio-selector","permalink":"http://yoursite.com/tags/java-nio-selector/"}]},{"title":"JAVA-IO学习之NIO.2(一)","slug":"IO/java基础/JAVA-IO学习之NIO.2(一)","date":"2016-05-07T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/07/IO/java基础/JAVA-IO学习之NIO.2(一)/","link":"","permalink":"http://yoursite.com/2016/05/07/IO/java基础/JAVA-IO学习之NIO.2(一)/","excerpt":"","text":"JAVA-IO学习之NIO.2(一）buffer属性 capacity: 缓冲区的容量大小 position: 当前缓冲区的游标位置，也就是下一个读或写的位置 limit: 缓冲区读写的上限位置，代表了可读写的最多数据量，在写模式，这个值一般和capacity一样 mark: 缓冲区的标记位置，mark()方法将缓冲区当前的游标位置记录下来，后续可以通过reset()方法将游标重置到这个位置上 分类缓冲区的分类比较简洁，基本上可以按数据类型进行划分，比如ByteBuffer, CharBuffer, DoubleBuffer, IntBuffer等等，但是有一个是特别值得注意的， MappedByteBuffer. 具体的使用场景和方法可以参见TODO. 操作 put/get: 两个方法都有两种变体. 一种是基于相对位置的（即不带参数的）,这种方式会改变buffer当前的游标位置，另一种是基于绝对位置的，这种方式不会改变游标的当前位置. allocate, wrap： 获取buffer的两种方式，一种是直接分配相应大小的缓冲区，另一种是将现有的数组进行包装，注意，这种情况下，wrap得到的缓冲区当中的数组即为传给wrap函数的数组，意思就是如果修改了这个数组的值，那么buffer的值也就被修改了. 反之亦然. flip, rewind, clear: 这些操作都将position的值置为0， flip将limit设置成当前position的值，所以它一般用来从写模式切换成读模式; rewind将position的值置为0，但它不会改变limit； clear将position置为0，并且将limit置为capacity，因此它经常用来从读模式切换回写模式. remaining, hasRemaining: 获取和判断从当前位置到缓冲区上界的元素数量. compact: 回收已经读取过的缓冲区数据，保留未被读取的缓冲区数据，也就是保留position~limit之间的数据，将它们复制到数组开始部分，并将position置于下一个能够读写的位置上，将limit置于capacity的位置. mark/reset: 标记和恢复当前游标的位置 视图缓冲区视图缓冲区和原来的缓冲区共享数据元素. duplicate: 复制一份缓冲区，两者拥有独立的position, limit, capacity属性，但共享同一个数组，也就是说，对其中一个缓冲区的修改会反映到另一个缓冲区中 asReadOnlyBuffer: 创建缓冲区的只读视图，除了不能执行写操作，以及readOnly返回true之外，其它的都和原来的缓冲区保持一致. 字节顺序 big-endian: 大端字节序，最高字节（most significant byte)存储于低位地址，最低字节（least significant byte)存储于高位地址 little-endian: 小端字节序，最高字节存储于高位地址，最低字节存储于低位地址 channel channel–&gt;buffer, buffer–&gt;channel 多路复用的概念 channel与stream的不同： channel是双向的，而stream是单向的 channel可以是异步的 channel读写的目标都是buffer channel可以通过Files等对象获取得到 channel的类型可以分为两大类： 一类为FileChannel， 一类为SocketChannel, SocketChannel又进一步细分为SocketChannel, ServerSocketChannel, DatagramChannel selector NIO: channel &amp; buffer NIO: non-blocking read &amp; write selector: monitor multiple channels selectionKey: SelectableChannel注册到selector时，将返回相应的selectionKey，它是两者间关系的管理工具 SelectableChannel: 可以被注册到selector中的一种通道，所有的socket通道都属于这种类型， 相反，fileChannel不属于这种类型. 参考文献 JAVA NIO： JAVA NIO O’Reilly%20-%20O’Reilly%20-%20Java%20NIO.pdf) JAVA NIO Turtorial: Jenkov NIO Turtorial","categories":[],"tags":[]},{"title":"自勉","slug":"quota","date":"2016-05-04T10:00:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/04/quota/","link":"","permalink":"http://yoursite.com/2016/05/04/quota/","excerpt":"","text":"When nothing seems to help, I go look at a stonecutter hammering away at his rock perhaps a hundred times without as much as a crack showing in it. Yet at the hundred and first blow it will split into two, and I know it was not that blow that did it, but all that had gone before.","categories":[],"tags":[]},{"title":"JAVA-IO学习之NIO","slug":"IO/java基础/JAVA-IO学习之NIO","date":"2016-05-01T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/01/IO/java基础/JAVA-IO学习之NIO/","link":"","permalink":"http://yoursite.com/2016/05/01/IO/java基础/JAVA-IO学习之NIO/","excerpt":"","text":"JAVA-IO学习之NIONIOJAVA的NIO部分相对来讲比较简单，它把过去那些旧的IO实现进行了新的封装，将与文件相关的操作封装到以下几个类中： Paths: 用于获取Path对象的工具类，可以通过指定文件名，URI等方式来获取Path对象 Path: 文件的语法表示，也就是说，这个对象只是个纯JAVA意义上的路径，它包含了和路径相关的一些操作，比如获取文件名，相对路径转换和解析等操作，但这些操作绝大部分和实际的文件没有关系（除了toRealPath), 具体的操作可以参见javadoc Files: 这是个工具类，它封装了与目录及文件相关的所有操作，它不但提供了文件的增删改查操作，还提供了相应的属性操作以及创建临时文件等操作，除此之外，它还提供了五种读取文件的方式，见下图，从左到右，操作的复杂度逐步上升. 另外，Files类还提供了关于文件夹的操作，包括创建、删除、遍历、临时目录等操作， 具体可以参见javaDoc 最后，JAVA的nio框架还增加了文件夹的监听服务，通过将某个要监视的目录注册到WatchService中，就可以实现对这个目录的增删改操作的监视功能，在整个监听服务中，有几个比较重要的接口： WatchService: 监听服务的核心接口，它用来提供相应的监听服务，所有实现了Watchable接口的类都可以通过这个接口进行注册监听 WatchKey: 注册目录的监听服务后，系统会返回相应的watchKey, 每个watchKey都有三种状态，刚注册完后处于ready状态，当有事件发生时，状态更改为signale， 当被关闭或者取消时，它的状态更改为invalid. 注意：当处理完接收到的事件时，必须将watchKey通过reset方法重新置于ready的状态, 否则它不能继续接收相应的事件. WatchEvent: 代表了监听的事件，每个事件都包括相应的类别信息，上下文信息，以及个数信息 官方文档中推荐使用WatchService的方法如下： 12345678910111213141516171819202122232425Path dir = ...;try &#123; WatchKey key = dir.register(watcher, ENTRY_CREATE, ENTRY_DELETE, ENTRY_MODIFY);&#125; catch (IOException x) &#123; System.err.println(x);&#125; for (;;) &#123; // retrieve key WatchKey key = watcher.take(); // process events for (WatchEvent&lt;?&gt; event: key.pollEvents()) &#123; : &#125; // reset the key boolean valid = key.reset(); if (!valid) &#123; // object no longer registered &#125; &#125; Glob在JAVA的NIO操作中，有些需要用到glob表达式，这里简单地罗列下glob语法的意义： *: match any number of characters(including none) **: works like * but cross directory boundry ?: match exactly one character {sun, moon, star}: collection of subpattern, match sun, moon or star. [0-9, aoei]: convey a set of single character, and when hyphen is used, a range of characters NOTE: use \\ to escape special character 参考文献官方文档：官方文档 示例代码：GitHub","categories":[],"tags":[]},{"title":"JAVA-IO学习","slug":"IO/java-io-nio","date":"2016-05-01T01:48:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/05/01/IO/java-io-nio/","link":"","permalink":"http://yoursite.com/2016/05/01/IO/java-io-nio/","excerpt":"","text":"NIOJAVA的NIO部分相对来讲比较简单，它把过去那些旧的IO实现进行了新的封装，将与文件相关的操作封装到以下几个类中： Paths: 用于获取Path对象的工具类，可以通过指定文件名，URI等方式来获取Path对象 Path: 文件的语法表示，也就是说，这个对象只是个纯JAVA意义上的路径，它包含了和路径相关的一些操作，比如获取文件名，相对路径转换和解析等操作，但这些操作绝大部分和实际的文件没有关系（除了toRealPath), 具体的操作可以参见javadoc Files: 这是个工具类，它封装了与目录及文件相关的所有操作，它不但提供了文件的增删改查操作，还提供了相应的属性操作以及创建临时文件等操作，除此之外，它还提供了五种读取文件的方式，见下图，从左到右，操作的复杂度逐步上升. 另外，Files类还提供了关于文件夹的操作，包括创建、删除、遍历、临时目录等操作， 具体可以参见javaDoc 最后，JAVA的nio框架还增加了文件夹的监听服务，通过将某个要监视的目录注册到WatchService中，就可以实现对这个目录的增删改操作的监视功能，在整个监听服务中，有几个比较重要的接口： WatchService: 监听服务的核心接口，它用来提供相应的监听服务，所有实现了Watchable接口的类都可以通过这个接口进行注册监听 WatchKey: 注册目录的监听服务后，系统会返回相应的watchKey, 每个watchKey都有三种状态，刚注册完后处于ready状态，当有事件发生时，状态更改为signale， 当被关闭或者取消时，它的状态更改为invalid. 注意：当处理完接收到的事件时，必须将watchKey通过reset方法重新置于ready的状态, 否则它不能继续接收相应的事件. WatchEvent: 代表了监听的事件，每个事件都包括相应的类别信息，上下文信息，以及个数信息 官方文档中推荐使用WatchService的方法如下： 12345678910111213141516171819202122232425Path dir = ...;try &#123; WatchKey key = dir.register(watcher, ENTRY_CREATE, ENTRY_DELETE, ENTRY_MODIFY);&#125; catch (IOException x) &#123; System.err.println(x);&#125; for (;;) &#123; // retrieve key WatchKey key = watcher.take(); // process events for (WatchEvent&lt;?&gt; event: key.pollEvents()) &#123; : &#125; // reset the key boolean valid = key.reset(); if (!valid) &#123; // object no longer registered &#125; &#125; Glob在JAVA的NIO操作中，有些需要用到glob表达式，这里简单地罗列下glob语法的意义： *: match any number of characters(including none) **: works like * but cross directory boundry ?: match exactly one character {sun, moon, star}: collection of subpattern, match sun, moon or star. [0-9, aoei]: convey a set of single character, and when hyphen is used, a range of characters NOTE: use \\ to escape special character 参考文献官方文档：官方文档 示例代码：GitHub","categories":[],"tags":[{"name":"java nio","slug":"java-nio","permalink":"http://yoursite.com/tags/java-nio/"}]},{"title":"对称加密、非对称加密及数字证书","slug":"encrption","date":"2016-04-28T13:04:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/28/encrption/","link":"","permalink":"http://yoursite.com/2016/04/28/encrption/","excerpt":"","text":"对称加密对称加密算法是指加密和解密过程使用同一个密钥的算法，或者加密密钥可以由解密密钥计算得到（反过来也一样，解密密钥也可以由加密密钥计算得到），对称加密算法计算量小，因此效率更高，但它的缺点是密钥的管理困难，特别是当需要进行数据传输的参与者很多的时候，密钥的管理将是一个噩梦. 非对称加密顾名思义，非对称加密就是指加密和解密过程使用的不是同一个密钥的算法. 因此，非对称加密的密钥都是以密钥对的形式出现的，发送给别人的密钥称为是公钥(public key), 自己保留的密钥称为是私钥(private key). 根据加密时使用的密钥的不同可以将非对称加密的使用场景分为两种： 加密传输： 如果A想将消息发送给B，但不想被其它人看到，那么A可以使用B的公钥对这段消息进行加密，因为只有B持有他自己的私钥，因此这段被加密过的密文只能由B通过它的私钥解密得到，保证了消息只能由B看到 签名：所谓签名的意思就是某个人声称这段消息是由他发出的，比如说，如果A想向B发送一封邮件，同时他想表明这封邮件是由他发出的，那么A就可以使用他的私钥对这封邮件的内容进行签名，然后将这段密文发给B，B用A的公钥对这段密文进行解密，如果解密成功，说明这封邮件确实是由A发出的. 当然，由于非对称加密算法的效率不高，对一大段内容进行加密可能需要花费比较多的时间，因此在实际的操作中，会先对这段内容通过摘要算法计算得到相应的摘要，再用私钥对这个摘要信息进行加密，从而形成签名，这也是数字签名中实现的内容. 数字签名在通过网络传输信息时，首先使用哈希算法计算得到明文信息的摘要(digest), 然后使用私钥对这段摘要进行加密，并把这段密文和要传输的明文信息一起传输给接收者，这个过程就称为数字签名. 从签名的过程可以看出，它主要包括两个步骤： 计算明文信息的摘要 使用私钥对摘要进行加密 当接收者收到相应的内容和签名信息时，他要做的就是验证签名，首先利用相同的摘要算法对明文信息计算得到摘要信息，再用发送者的公钥解密签名信息得到另一个摘要信息，比较计算得到和解密得到的摘要信息是否一致，以此判断这个签名是由发送者签注的。整个验签的过程也分为三个过程： 计算明文信息的摘要信息 使用公钥对接收内容中的签名进行解密 比较步骤1和2中的摘要信息是否一致 数字证书数字签名解决了消息来源的可靠性问题，但这基于一个前提，就是消息的接收者所持有的公钥确实是属于消息发送者的，如果这个公钥在不知情的情况下被替换了，那么还是存在收到冒充者发送的消息的可能性. 数字证书就是用于解决这个问题的. 现在面临的问题是接收者无法确定自己持有的公钥是否真的来自发送者，数字证书的解决方法就是引入可信任的第三方，首先这个第三方必须是可信任的，再由这个可信任的第三方为发送者的公钥做“担保”，那么这个公钥就是可信任的. 具体的步骤是这样的： 消息发送者将公钥及其它的信息发送给可信任的第三方(CA) CA组织在进行必须的校验后，对发送者给它的消息及公钥进行数字签名，形成数字证书颁发给发送者 发送者将数字证书发给接收者 接收者拿到数字证书后，首先对CA的数字签名进行验签，验签通过后就可以获取到发送者的公钥，这里的公钥就可以认为是由CA组织担保过的，是可信任的 那么问题来了，接收者怎么确定数字证书中的签名所使用的公钥就是可信任的呢？这里就引入了“证书链”的概念，按照上述的思路一步步地进行上溯，直到找到根证书. 根证书就是自签名或者根本没有签名的证书，安装某个根证书就意味着信任来自这个根证书，也就意味着信息由这个根证书签名过的所有证书. 在实际的操作中，浏览器通常会和某些根证书组织合作，安装浏览器的时候会自动安装这些根证书. HTTPS理解了对称加密、非对称加密以及数字证书的机理后，再来看HTTPS就比较简单了. 简单来讲，HTTPS就是在应用层和传输层之间加了SSL/TLS层，在服务端和客户端建立会话前，必须先建立安全通道，之后两者之间所有的数据传输都必须通过这个安全通道来进行. 在建立会话时，服务端和客户端通过非对称加密算法协商密钥，协商完密钥后，后续所有的数据传输都使用这个密钥通过对称加密完成. 整个过程被称为“四次握手”，如下所述： 客户端向服务端发送client_random以及客户端支持的对称加密算法列表 服务端收到客户端的请求后，向客户端发送server_random，选定的对称加密算法，以及服务端的数字证书 客户端首先验证数字证书的真实性，验证通过后，就使用数字证书中的公钥对premaster_num(客户端随机产生)进行加密传输 服务端收到加密的消息后，使用私钥进行解密，得到客户端传来的premaster_num, 并通过client_random, server_random和premaster_num计算得到对称加密中要使用的密钥，到这里为止，服务端和客户端完成了密钥的协商. 在后续的数据传输中，服务端都将使用步骤2中的对称加密算法，以及步骤4中计算得到的密钥对要传输的数据进行加密 客户端同样可以根据client_random, server_random以及premaster_num计算得到对称加密算法的密钥，并用它对服务端发来的加密数据进行解密，并在发送数据给服务端前进行加密 可以看到，在密钥协商的过程中，使用的是非对称加密的方法，最大限度地保证了密钥的随机性和保密性，而在数据传输的时候，使用的是则是对称加密，可以有效地提高加密解密的效率 参考文献 HTTPS详解： HTTPS详解 数字证书的基础知识: 数字证书的基础知识 What’s a digital signature: What’s a digital signature","categories":[],"tags":[{"name":"对称加密 非对称加密","slug":"对称加密-非对称加密","permalink":"http://yoursite.com/tags/对称加密-非对称加密/"}]},{"title":"对称加密、非对称加密及数字证书","slug":"安全/对称加密、非对称加密及数字证书","date":"2016-04-28T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/28/安全/对称加密、非对称加密及数字证书/","link":"","permalink":"http://yoursite.com/2016/04/28/安全/对称加密、非对称加密及数字证书/","excerpt":"","text":"对称加密、非对称加密及数字证书对称加密对称加密算法是指加密和解密过程使用同一个密钥的算法，或者加密密钥可以由解密密钥计算得到（反过来也一样，解密密钥也可以由加密密钥计算得到），对称加密算法计算量小，因此效率更高，但它的缺点是密钥的管理困难，特别是当需要进行数据传输的参与者很多的时候，密钥的管理将是一个噩梦. 非对称加密顾名思义，非对称加密就是指加密和解密过程使用的不是同一个密钥的算法. 因此，非对称加密的密钥都是以密钥对的形式出现的，发送给别人的密钥称为是公钥(public key), 自己保留的密钥称为是私钥(private key). 根据加密时使用的密钥的不同可以将非对称加密的使用场景分为两种： 加密传输： 如果A想将消息发送给B，但不想被其它人看到，那么A可以使用B的公钥对这段消息进行加密，因为只有B持有他自己的私钥，因此这段被加密过的密文只能由B通过它的私钥解密得到，保证了消息只能由B看到 签名：所谓签名的意思就是某个人声称这段消息是由他发出的，比如说，如果A想向B发送一封邮件，同时他想表明这封邮件是由他发出的，那么A就可以使用他的私钥对这封邮件的内容进行签名，然后将这段密文发给B，B用A的公钥对这段密文进行解密，如果解密成功，说明这封邮件确实是由A发出的. 当然，由于非对称加密算法的效率不高，对一大段内容进行加密可能需要花费比较多的时间，因此在实际的操作中，会先对这段内容通过摘要算法计算得到相应的摘要，再用私钥对这个摘要信息进行加密，从而形成签名，这也是数字签名中实现的内容. 数字签名在通过网络传输信息时，首先使用哈希算法计算得到明文信息的摘要(digest), 然后使用私钥对这段摘要进行加密，并把这段密文和要传输的明文信息一起传输给接收者，这个过程就称为数字签名. 从签名的过程可以看出，它主要包括两个步骤： 计算明文信息的摘要 使用私钥对摘要进行加密 当接收者收到相应的内容和签名信息时，他要做的就是验证签名，首先利用相同的摘要算法对明文信息计算得到摘要信息，再用发送者的公钥解密签名信息得到另一个摘要信息，比较计算得到和解密得到的摘要信息是否一致，以此判断这个签名是由发送者签注的。整个验签的过程也分为三个过程： 计算明文信息的摘要信息 使用公钥对接收内容中的签名进行解密 比较步骤1和2中的摘要信息是否一致 数字证书数字签名解决了消息来源的可靠性问题，但这基于一个前提，就是消息的接收者所持有的公钥确实是属于消息发送者的，如果这个公钥在不知情的情况下被替换了，那么还是存在收到冒充者发送的消息的可能性. 数字证书就是用于解决这个问题的. 现在面临的问题是接收者无法确定自己持有的公钥是否真的来自发送者，数字证书的解决方法就是引入可信任的第三方，首先这个第三方必须是可信任的，再由这个可信任的第三方为发送者的公钥做“担保”，那么这个公钥就是可信任的. 具体的步骤是这样的： 消息发送者将公钥及其它的信息发送给可信任的第三方(CA) CA组织在进行必须的校验后，对发送者给它的消息及公钥进行数字签名，形成数字证书颁发给发送者 发送者将数字证书发给接收者 接收者拿到数字证书后，首先对CA的数字签名进行验签，验签通过后就可以获取到发送者的公钥，这里的公钥就可以认为是由CA组织担保过的，是可信任的 那么问题来了，接收者怎么确定数字证书中的签名所使用的公钥就是可信任的呢？这里就引入了“证书链”的概念，按照上述的思路一步步地进行上溯，直到找到根证书. 根证书就是自签名或者根本没有签名的证书，安装某个根证书就意味着信任来自这个根证书，也就意味着信息由这个根证书签名过的所有证书. 在实际的操作中，浏览器通常会和某些根证书组织合作，安装浏览器的时候会自动安装这些根证书. HTTPS理解了对称加密、非对称加密以及数字证书的机理后，再来看HTTPS就比较简单了. 简单来讲，HTTPS就是在应用层和传输层之间加了SSL/TLS层，在服务端和客户端建立会话前，必须先建立安全通道，之后两者之间所有的数据传输都必须通过这个安全通道来进行. 在建立会话时，服务端和客户端通过非对称加密算法协商密钥，协商完密钥后，后续所有的数据传输都使用这个密钥通过对称加密完成. 整个过程被称为“四次握手”，如下所述： 客户端向服务端发送client_random以及客户端支持的对称加密算法列表 服务端收到客户端的请求后，向客户端发送server_random，选定的对称加密算法，以及服务端的数字证书 客户端首先验证数字证书的真实性，验证通过后，就使用数字证书中的公钥对premaster_num(客户端随机产生)进行加密传输 服务端收到加密的消息后，使用私钥进行解密，得到客户端传来的premaster_num, 并通过client_random, server_random和premaster_num计算得到对称加密中要使用的密钥，到这里为止，服务端和客户端完成了密钥的协商. 在后续的数据传输中，服务端都将使用步骤2中的对称加密算法，以及步骤4中计算得到的密钥对要传输的数据进行加密 客户端同样可以根据client_random, server_random以及premaster_num计算得到对称加密算法的密钥，并用它对服务端发来的加密数据进行解密，并在发送数据给服务端前进行加密 可以看到，在密钥协商的过程中，使用的是非对称加密的方法，最大限度地保证了密钥的随机性和保密性，而在数据传输的时候，使用的是则是对称加密，可以有效地提高加密解密的效率 参考文献 HTTPS详解： HTTPS详解 数字证书的基础知识: 数字证书的基础知识 What’s a digital signature: What’s a digital signature","categories":[],"tags":[]},{"title":"java-IO学习","slug":"IO/java-io-basic","date":"2016-04-27T11:44:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/27/IO/java-io-basic/","link":"","permalink":"http://yoursite.com/2016/04/27/IO/java-io-basic/","excerpt":"","text":"JAVA的IO框架可大致分为三个部分：IO(也可以认为是BIO), NIO, NIO2. 这里只介绍IO的部分，其它两部分会在后续的学习中阐述. JAVA的IO部分又可以简单地分为以下几个部分: InputStream/OutputStream: 所有针对二进制字节流的操作都继承于这两个类 Reader/Writer: 这两个类是针对字符的读写操作设计的. Scanner/Formatter: 这两个类分别是用来格式化读取和输出时使用的，可以通过指定相应的格式来获取或输出数据 DataInput/DataOutput: 这两个接口分别是用于读取和输出java基础类型，它可以将基础类型以二进制流的形式输入输出到相应的流中 ObjectInput/ObjectOutput: 这两个接口与上述两个接口类似，不过它输入输出的目标是java对象，使用这两个接口时，要注意的是，输入输出的对象必须实现Serializable接口，否则会抛出异常 关于JAVA基础的IO部分基本上只有这点内容，相对来讲比较简单，但是值得一提的是，在这部分的接口设计中，使用到了装饰器模式，可以结合这部分的源码来理解装饰器模式的原理与应用, 下图是装饰器模式的UML 从上面的UML图中可以看出，装饰器模式的实现关键点有两个： 装饰器与被装饰对象实现了同一个接口 装饰器对象持有被装饰对象的引用 查看InputStream的类图可以发现，有个叫FilterInputStream的实现类，它继承了InputStream，并且在构造函数中持有一个inputStream的实例对象，可以看出，这里这个FilterInputStream的角色就是装饰器，而被持有的inputStream的实例对象就是被装饰对象，它们共同实例了装饰器模式. 进一步查看FilterInputStream的类图可以发现，许多带有“装饰”功能的inputStream类都继承自它，比如GzipInputStream, BufferedInputStream等等. 同样地，对于OutputStream, Reader, Writer等等接口也都可以看到相应的设计思路 练习代码可参见： 练习代码","categories":[],"tags":[{"name":"java io decorator","slug":"java-io-decorator","permalink":"http://yoursite.com/tags/java-io-decorator/"}]},{"title":"Git学习备忘","slug":"git-learning-memo","date":"2016-04-27T04:38:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/27/git-learning-memo/","link":"","permalink":"http://yoursite.com/2016/04/27/git-learning-memo/","excerpt":"","text":"写在前面这篇文档不是git命令的学习文档，git的基础命令及相应的语法和使用可以通过git help subcommand很方便地查到. 这里主要是将自己在学习git过程中遇到的一些问题记录下来，以备后续备忘使用. 名词解释 HEAD: git内部使用HEAD来指示当前所在分支的最新提交 master: 从远程仓库拉取代码时，git会默认在本地创建一个master分支，并用它来跟踪远程仓库中origin/master分支的内容 origin: 从远程创建拉取代码时，git会默认将远程仓库的地址设置为origin，也可以通过git remote add手工加入其它的远程仓库地址 Rebase在git内部中使用分支是个很常见的做法，使用分支必然意味着需要将不同的分支内容进行合并. 在git中提供了两种合并的方法，一种是merge， 一种是rebase. merge的使用方法比较简单，这里不做阐述，这是主要是简单记录下rebase的使用方法. 查阅rebase的文档可以发现，它的使用方法有下面三种: rebase –onto A B C(rebase –onto newBase Upstream Branch)这是最完整的命令形式，它的作用是切换到branch分支，并找到这个分支中不存在于upstream中的那些提交，将这些提交一一地在newBase中重放. 举个例子，可以看到，在进行rebase操作之前，分支b2是提交是在b1提交的基础上，在执行了rebase操作后，b2分支中的5b9686以及16f966两次被rebase到master分支的f71fe18的提交上, 并且HEAD指针指向b1分支. 1234567891011121314151617181920&gt; git lg* 5b9686c1fb2dbb1ef95fb36b47254bbf66225b83 (HEAD -&gt; b2) 7* 16f9663f77c6c58447e2f7d7f2b4f129fc1f1b05 6* 9947edd2cbafc34cc24d0182a8118e900ee043d9 (b1) 5* 479e44cf3d5e0e20f82ecd84f597d73c47b69919 3| * f71fe18e70ea2e2b2ae04ec405ea2e57b03be496 (master) 4|/ * 88a3b40bea4b9a4c0971ba4e08efb92491c2c4a3 2* 95f16a83315b86a4b0228310626ddcab69aefa96 1&gt; git rebase --onto master b1 b2&gt; git lg* c87c8e21df58e064b5b6e23def4efc9ead57bec6 (HEAD -&gt; b2) 7* aa84807e80971f8d51930a5c6d9dbf055bceff2a 6* f71fe18e70ea2e2b2ae04ec405ea2e57b03be496 (master) 4| * 9947edd2cbafc34cc24d0182a8118e900ee043d9 (b1) 5| * 479e44cf3d5e0e20f82ecd84f597d73c47b69919 3|/ * 88a3b40bea4b9a4c0971ba4e08efb92491c2c4a3 2* 95f16a83315b86a4b0228310626ddcab69aefa96 1 rebase B C这个命令省略了–onto参数，它默认将Upstream分支当作rebase分支, 从下面的例子可以看出，这个命令首先将分支切换到b1，并找到不在b2中的所有提交, 这里即20c108和f6a00b两次提交，然后把这两个提交在b2分支上进行重放. 最后得到一条线性的提交树 12345678&gt; git rebase b2 b1* 20c108c57a31783bdd9b794d9ad9549bbdc9a5e3 (HEAD -&gt; b1) 5* f6a00b0ee7905b937843747ee95ab73b891aef32 3* c87c8e21df58e064b5b6e23def4efc9ead57bec6 (b2) 7* aa84807e80971f8d51930a5c6d9dbf055bceff2a 6* f71fe18e70ea2e2b2ae04ec405ea2e57b03be496 (master) 4* 88a3b40bea4b9a4c0971ba4e08efb92491c2c4a3 2* 95f16a83315b86a4b0228310626ddcab69aefa96 1 rebase B这个命令格式省略了branch参数, 也就是说它在进行rebase操作之前，并不会进行分支切换，而是直接在当前分支进行操作. 最后的结果就是，计算出当前分支中没有在upstream分支中的提交对象，并将它们一一在upstream分支中回放. 使用rebase要注意的事项使用rebase可以使提交历史更加清晰明了，但使用它有个前提，就是不能对已经推到远程仓库的提交信息进行rebase, 否则其它的合作者在重新拉取仓库时会遇到很难搞的一些问题. Git的内部存储机制git除了对外提供简洁友好的用户命令之外，对内部它还有一套底层的接口来实现对象的存储. git内部存储的所有信息都放在.git目录下，目录的结构如下所示, 其中branches在高版本的git中已弃用，config中保存了项目相关的一些配置, description记录了gitWeb需要使用的一些信息，hooks记录了客户端以及服务端的一些hook配置，info中记录了全局配置的忽略跟踪的一些文件(.gitignore),除此之外，就剩下四个比较重要的文件和目录，分别是HEAD, index, objects和refs. 其中HEAD记录了当前分支的最新提交信息，index中记录了暂存区的信息，objects目录中记录了库中所有的对象，具体的存储形式在后续中会提到，而refs中又有heads, tags，以及remotes三个子目录，分别对应记录了分支，标签以及远程仓库的提交信息. object在git中,所有的对象都被存储为blob的形式，具体的存储过程如下： 获取相应的内容(content) 增加相应的头信息(header) 获取内容和头信息的sha1(sha1) 使用zlib压缩内容(zlib_content) 存储 1234567891011121314151617181920212223242526272829#引用库require 'digest/sha1'require 'zlib'require 'fileutils'#blob内容content = \"hello world!\"#blob头信息header = \"blob #&#123;content.length&#125;\\0\"#blob存储的消息store = header + content#blob消息的sha1sha1 = Digest::SHA1.hexdigest(store)#blob消息的zlibzlib_content = Zlib::Deflate.deflate(store)#写到文件中path = '.git/objects/' + sha1[0, 2] + '/' + sha1[2, 38]FileUtils.mkdir_p(File.dirname(path))File.open(path, 'w')&#123;|f|f.write zlib_content&#125;#校验git cat-file -p bc7774a7b18deb1d7bd0212d34246a9b1260ae17 hash-object上面的ruby脚本简单地展示了git内部创建blob对象的过程，事实上，git也提供了hash-object命令用于很方便地创建git节点，在git内部也是使用这个命令创建各个对象的blob 12345&gt; echo &quot;hello world!&quot; &gt;&gt; test.txt&gt; git hash-object -w test.txta0423896973644771497bdc03eb99d5281615b51&gt; git cat-file -p a0423896973644771497bdc03eb99d5281615b51hello world! cat-file这个命令号称是git用来检测内部对象的“瑞士军刀”. 它可以用来查询对象的存储信息，具体的输出根据不同的类型会有不同的信息，当然它也可以用来查询存储对象的类型信息, 在git中存储的对象类型分为四种，分别是blob, tree, commit和tag. 12345&gt; git cat-file -p a0423896973644771497bdc03eb99d5281615b51hello world!&gt; git cat-file -t a0423896973644771497bdc03eb99d5281615b51blob update-index这个命令是将相应的文件增加到暂存区，它还可以更新暂存里的文件内容，在执行完这条命令后，文件的blob对象就已经存储到git的objects中了. 1&gt; git update-index --add test.txt write-tree在将文件加到git的暂存区后，就可以使用write-tree命令了。write-tree命令是将暂存区中存储的对象写成一个树对象，并返回相应的SHA1标识. 同样地，生成的tree对象也存储在.git的objects中 通过cat-file查询树对象可以发现，树对象中存储了相应对象的类型，地址信息，及其文件名和读写权限信息(100644) 12345&gt; git write-tree5d56cf9b9843c20d7b29bf6374501f4f48841210&gt; git cat-file -p 5d56cf9b9843c20d7b29bf6374501f4f48841210100644 blob a0423896973644771497bdc03eb99d5281615b51 test.txt commit-tree在使用write-tree生成相应的树对象之后，就可以使用commit-tree命令来生成相应的commit对象了.顾名思义，这里的commit对象就是使用git commit时会生成的对象. 在使用commit-tree时，必要指定要提交的树对象的标识，即由write-tree命令返回的sha1标识，另外，它还可以通过-p参数指定父提交对象，这样就形成了使用git log时显示的提交历史树. 通过cat-file来查询commit-tree对象，可以看到对象中存储了提交信息，作者信息，提交者信息以及相应的树对象地址. 123456789&gt; echo &apos;first commit&apos; | git commit-tree 5d56cf9b9843c20d7b29bf6374501f4f488412104f69a44b7b55cd5dd4dcb872af5b0ac5e793de9b&gt; git cat-file -p 4f69a44b7b55cd5dd4dcb872af5b0ac5e793de9btree 5d56cf9b9843c20d7b29bf6374501f4f48841210author essviv &lt;514912821@qq.com&gt; 1461726403 +0800committer essviv &lt;514912821@qq.com&gt; 1461726403 +0800first commit update-ref在学习git的过程，经常会提到分支是git有别于其它VCS的“杀手锏”，因为在git中创建分支是个非常简单快速的过程, 而update-ref就是用来完成这个功能的. 在.git/refs目录下可以看到两个子目录，分别是heads和tags, 其中heads目录记录了各个分支的头结点的信息, 而tags则记录了tag信息，以下的例子就通过update-ref很简单地创建了个test分支，可以看到，在git中创建个分支简单到只需要在refs/heads/中创建个相应的文件，并在文件中写入41个字符（40个sha1标识+1个换行符). 1&gt; echo &apos;4f69a44b7b55cd5dd4dcb872af5b0ac5e793de9b&apos; &gt;&gt; test symbolic-ref除了分支信息外，git中还通过HEAD指针来指示当前所在分支的最新提交对象，这个信息就存储在.git/HEAD中，可以从HEAD文件的内容中看到，这个文件里存储的就是到refs/heads中某个文件的引用而已. 可以想像，在git中使用git checkout进行分支切换的时候，只需要将HEAD的中的内容指定相应的refs/heads中的分支结点，然后更新工作区的内容即可. 12&gt; cat HEADref: refs/heads/test All-in-one这里通过上述的命令简单地构造git的提交信息，完成通过git用户命令就可以完成的内容，进一步加深对git内部存储的理解. 创建文件test，并产生一些文件内容 使用update-index –add将它加入到暂存区 使用write-tree获取相应的树对象 使用commit-tree获取相应的提交对象C1 修改文件test内容，并增加新的文件new，加上一些内容 使用update-index将它们加入到暂存区 使用write-tree获取相应的树对象 使用commit-tree获取相应的提交对象C2，并将它的父提交对象设置为C1 重复前面四个步骤，获取提交对象C3，并将它的父对象设置为C2 使用update-ref在refs/heads中创建master分支，并将它指向C1 使用symbolic-ref将HEAD对象指定master 使用git log来查看刚刚创建的提交记录树 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&gt; echo “first commit” &gt;&gt; test&gt; git update-index --add test&gt; git write-treebff0827a0da713487c9fca9235263772db9a3b0e&gt; echo &quot;first commit&quot; | git commit-tree bff0827a0da713487c9fca9235263772db9a3b0ed6fac28b22fffdcd4d54126ec44ec86a712d6fde&gt; echo &quot;second commit&quot; &gt;&gt; test&gt; echo &quot;new file&quot; &gt;&gt; new&gt; git update-index test&gt; git update-index --add new&gt; git write-treebde4f04d1037685b47deeb515984cdb994888d07&gt; echo &quot;second commit&quot; | git commit-tree bde4f04d1037685b47deeb515984cdb994888d07 -p d6fac28b22fffdcd4d54126ec44ec86a712d6fde0f33097c08b7827224083238dc9294f59aa7948a&gt; echo &quot;third commit&quot; &gt;&gt; test&gt; echo &quot;third commit&quot; &gt;&gt; new&gt; git update-index test&gt; git update-index new&gt; git write-treef4c0f72be323c47af0dd2bbddfbaf6f548b11926&gt; echo &quot;third commit&quot; | git commit-tree f4c0f72be323c47af0dd2bbddfbaf6f548b11926 -p 0f33097c08b7827224083238dc9294f59aa7948a25eee6f70d508567abe72969d3524f557bc159d8&gt; git update-ref refs/heads/master 25eee6f70d508567abe72969d3524f557bc159d8&gt; git update-ref refs/heads/test 0f33097c08b7827224083238dc9294f59aa7948a&gt; git log --pretty=onelie --graph --decorate=short&gt; git symbolic-ref HEAD refs/heads/test&gt; git log --pretty=onelie --graph --decorate=short 其它从上述的描述中可以看到，git内部维护了许多对象，包括blob, blob, tree以及tags信息，并且每次更新后重新提交又会创建新的blob对象，这样，随着时间的推移，git内部的对象将越来越多，如果不对这些对象进行一些处理，可以想像，这些对象占据的空间将逐步增大，因此，git内部使用了压缩的方法, 将一批文件压缩将形成pack文件，pack文件还有相应的idx信息，方便外部快速地对pack文件进行读取,这部分内容具体可以git官方文档. 参考文档ProGit Book: ProGit","categories":[],"tags":[{"name":"git internal","slug":"git-internal","permalink":"http://yoursite.com/tags/git-internal/"}]},{"title":"JAVA-IO学习之IO","slug":"IO/java基础/JAVA-IO学习之IO","date":"2016-04-27T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/27/IO/java基础/JAVA-IO学习之IO/","link":"","permalink":"http://yoursite.com/2016/04/27/IO/java基础/JAVA-IO学习之IO/","excerpt":"","text":"JAVA-IO学习之IOJAVA的IO框架可大致分为三个部分：IO(也可以认为是BIO), NIO, NIO2. 这里只介绍IO的部分，其它两部分会在后续的学习中阐述. JAVA的IO部分又可以简单地分为以下几个部分: InputStream/OutputStream: 所有针对二进制字节流的操作都继承于这两个类 Reader/Writer: 这两个类是针对字符的读写操作设计的. Scanner/Formatter: 这两个类分别是用来格式化读取和输出时使用的，可以通过指定相应的格式来获取或输出数据 DataInput/DataOutput: 这两个接口分别是用于读取和输出java基础类型，它可以将基础类型以二进制流的形式输入输出到相应的流中 ObjectInput/ObjectOutput: 这两个接口与上述两个接口类似，不过它输入输出的目标是java对象，使用这两个接口时，要注意的是，输入输出的对象必须实现Serializable接口，否则会抛出异常 关于JAVA基础的IO部分基本上只有这点内容，相对来讲比较简单，但是值得一提的是，在这部分的接口设计中，使用到了装饰器模式，可以结合这部分的源码来理解装饰器模式的原理与应用, 下图是装饰器模式的UML 从上面的UML图中可以看出，装饰器模式的实现关键点有两个： 装饰器与被装饰对象实现了同一个接口 装饰器对象持有被装饰对象的引用 查看InputStream的类图可以发现，有个叫FilterInputStream的实现类，它继承了InputStream，并且在构造函数中持有一个inputStream的实例对象，可以看出，这里这个FilterInputStream的角色就是装饰器，而被持有的inputStream的实例对象就是被装饰对象，它们共同实例了装饰器模式. 进一步查看FilterInputStream的类图可以发现，许多带有“装饰”功能的inputStream类都继承自它，比如GzipInputStream, BufferedInputStream等等. 同样地，对于OutputStream, Reader, Writer等等接口也都可以看到相应的设计思路 练习代码可参见： 练习代码","categories":[],"tags":[]},{"title":"git","slug":"工具/git","date":"2016-04-27T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/27/工具/git/","link":"","permalink":"http://yoursite.com/2016/04/27/工具/git/","excerpt":"","text":"#写在前面 这篇文档不是git命令的学习文档，git的基础命令及相应的语法和使用可以通过git help subcommand很方便地查到. 这里主要是将自己在学习git过程中遇到的一些问题记录下来，以备后续备忘使用. 名词解释 HEAD: git内部使用HEAD来指示当前所在分支的最新提交 master: 从远程仓库拉取代码时，git会默认在本地创建一个master分支，并用它来跟踪远程仓库中origin/master分支的内容 origin: 从远程创建拉取代码时，git会默认将远程仓库的地址设置为origin，也可以通过git remote add手工加入其它的远程仓库地址 Rebase在git内部中使用分支是个很常见的做法，使用分支必然意味着需要将不同的分支内容进行合并. 在git中提供了两种合并的方法，一种是merge， 一种是rebase. merge的使用方法比较简单，这里不做阐述，这是主要是简单记录下rebase的使用方法. 查阅rebase的文档可以发现，它的使用方法有下面三种: &gt; rebase --onto newBase Upstream Branch rebase –onto A B C这是最完整的命令形式，它的作用是切换到branch分支，并找到这个分支中不存在于upstream中的那些提交，将这些提交一一地在newBase中重放. 举个例子，可以看到，在进行rebase操作之前，分支b2是提交是在b1提交的基础上，在执行了rebase操作后，b2分支中的5b9686以及16f966两次被rebase到master分支的f71fe18的提交上, 并且HEAD指针指向b1分支. 1234567891011121314151617181920&gt; git lg* 5b9686c1fb2dbb1ef95fb36b47254bbf66225b83 (HEAD -&gt; b2) 7* 16f9663f77c6c58447e2f7d7f2b4f129fc1f1b05 6* 9947edd2cbafc34cc24d0182a8118e900ee043d9 (b1) 5* 479e44cf3d5e0e20f82ecd84f597d73c47b69919 3| * f71fe18e70ea2e2b2ae04ec405ea2e57b03be496 (master) 4|/ * 88a3b40bea4b9a4c0971ba4e08efb92491c2c4a3 2* 95f16a83315b86a4b0228310626ddcab69aefa96 1&gt; git rebase --onto master b1 b2&gt; git lg* c87c8e21df58e064b5b6e23def4efc9ead57bec6 (HEAD -&gt; b2) 7* aa84807e80971f8d51930a5c6d9dbf055bceff2a 6* f71fe18e70ea2e2b2ae04ec405ea2e57b03be496 (master) 4| * 9947edd2cbafc34cc24d0182a8118e900ee043d9 (b1) 5| * 479e44cf3d5e0e20f82ecd84f597d73c47b69919 3|/ * 88a3b40bea4b9a4c0971ba4e08efb92491c2c4a3 2* 95f16a83315b86a4b0228310626ddcab69aefa96 1 rebase B C这个命令省略了–onto参数，它默认将Upstream分支当作rebase分支, 从下面的例子可以看出，这个命令首先将分支切换到b1，并找到不在b2中的所有提交, 这里即20c108和f6a00b两次提交，然后把这两个提交在b2分支上进行重放. 最后得到一条线性的提交树 12345678&gt; git rebase b2 b1* 20c108c57a31783bdd9b794d9ad9549bbdc9a5e3 (HEAD -&gt; b1) 5* f6a00b0ee7905b937843747ee95ab73b891aef32 3* c87c8e21df58e064b5b6e23def4efc9ead57bec6 (b2) 7* aa84807e80971f8d51930a5c6d9dbf055bceff2a 6* f71fe18e70ea2e2b2ae04ec405ea2e57b03be496 (master) 4* 88a3b40bea4b9a4c0971ba4e08efb92491c2c4a3 2* 95f16a83315b86a4b0228310626ddcab69aefa96 1 rebase B这个命令格式省略了branch参数, 也就是说它在进行rebase操作之前，并不会进行分支切换，而是直接在当前分支进行操作. 最后的结果就是，计算出当前分支中没有在upstream分支中的提交对象，并将它们一一在upstream分支中回放. 使用rebase要注意的事项使用rebase可以使提交历史更加清晰明了，但使用它有个前提，就是不能对已经推到远程仓库的提交信息进行rebase, 否则其它的合作者在重新拉取仓库时会遇到很难搞的一些问题. Git的内部存储机制git除了对外提供简洁友好的用户命令之外，对内部它还有一套底层的接口来实现对象的存储. git内部存储的所有信息都放在.git目录下，目录的结构如下所示, 其中branches在高版本的git中已弃用，config中保存了项目相关的一些配置, description记录了gitWeb需要使用的一些信息，hooks记录了客户端以及服务端的一些hook配置，info中记录了全局配置的忽略跟踪的一些文件(.gitignore),除此之外，就剩下四个比较重要的文件和目录，分别是HEAD, index, objects和refs. 其中HEAD记录了当前分支的最新提交信息，index中记录了暂存区的信息，objects目录中记录了库中所有的对象，具体的存储形式在后续中会提到，而refs中又有heads, tags，以及remotes三个子目录，分别对应记录了分支，标签以及远程仓库的提交信息. object在git中,所有的对象都被存储为blob的形式，具体的存储过程如下： 获取相应的内容(content) 增加相应的头信息(header) 获取内容和头信息的sha1(sha1) 使用zlib压缩内容(zlib_content) 存储 1234567891011121314151617181920212223242526272829#引用库require 'digest/sha1'require 'zlib'require 'fileutils'#blob内容content = \"hello world!\"#blob头信息header = \"blob #&#123;content.length&#125;\\0\"#blob存储的消息store = header + content#blob消息的sha1sha1 = Digest::SHA1.hexdigest(store)#blob消息的zlibzlib_content = Zlib::Deflate.deflate(store)#写到文件中path = '.git/objects/' + sha1[0, 2] + '/' + sha1[2, 38]FileUtils.mkdir_p(File.dirname(path))File.open(path, 'w')&#123;|f|f.write zlib_content&#125;#校验git cat-file -p bc7774a7b18deb1d7bd0212d34246a9b1260ae17 hash-object上面的ruby脚本简单地展示了git内部创建blob对象的过程，事实上，git也提供了hash-object命令用于很方便地创建git节点，在git内部也是使用这个命令创建各个对象的blob 12345&gt; echo &quot;hello world!&quot; &gt;&gt; test.txt&gt; git hash-object -w test.txta0423896973644771497bdc03eb99d5281615b51&gt; git cat-file -p a0423896973644771497bdc03eb99d5281615b51hello world! cat-file这个命令号称是git用来检测内部对象的“瑞士军刀”. 它可以用来查询对象的存储信息，具体的输出根据不同的类型会有不同的信息，当然它也可以用来查询存储对象的类型信息, 在git中存储的对象类型分为四种，分别是blob, tree, commit和tag. 12345&gt; git cat-file -p a0423896973644771497bdc03eb99d5281615b51hello world!&gt; git cat-file -t a0423896973644771497bdc03eb99d5281615b51blob update-index这个命令是将相应的文件增加到暂存区，它还可以更新暂存里的文件内容，在执行完这条命令后，文件的blob对象就已经存储到git的objects中了. 1&gt; git update-index --add test.txt write-tree在将文件加到git的暂存区后，就可以使用write-tree命令了。write-tree命令是将暂存区中存储的对象写成一个树对象，并返回相应的SHA1标识. 同样地，生成的tree对象也存储在.git的objects中 通过cat-file查询树对象可以发现，树对象中存储了相应对象的类型，地址信息，及其文件名和读写权限信息(100644) 12345&gt; git write-tree5d56cf9b9843c20d7b29bf6374501f4f48841210&gt; git cat-file -p 5d56cf9b9843c20d7b29bf6374501f4f48841210100644 blob a0423896973644771497bdc03eb99d5281615b51 test.txt commit-tree在使用write-tree生成相应的树对象之后，就可以使用commit-tree命令来生成相应的commit对象了.顾名思义，这里的commit对象就是使用git commit时会生成的对象. 在使用commit-tree时，必要指定要提交的树对象的标识，即由write-tree命令返回的sha1标识，另外，它还可以通过-p参数指定父提交对象，这样就形成了使用git log时显示的提交历史树. 通过cat-file来查询commit-tree对象，可以看到对象中存储了提交信息，作者信息，提交者信息以及相应的树对象地址. 123456789&gt; echo &apos;first commit&apos; | git commit-tree 5d56cf9b9843c20d7b29bf6374501f4f488412104f69a44b7b55cd5dd4dcb872af5b0ac5e793de9b&gt; git cat-file -p 4f69a44b7b55cd5dd4dcb872af5b0ac5e793de9btree 5d56cf9b9843c20d7b29bf6374501f4f48841210author essviv &lt;514912821@qq.com&gt; 1461726403 +0800committer essviv &lt;514912821@qq.com&gt; 1461726403 +0800first commit update-ref在学习git的过程，经常会提到分支是git有别于其它VCS的“杀手锏”，因为在git中创建分支是个非常简单快速的过程, 而update-ref就是用来完成这个功能的. 在.git/refs目录下可以看到两个子目录，分别是heads和tags, 其中heads目录记录了各个分支的头结点的信息, 而tags则记录了tag信息，以下的例子就通过update-ref很简单地创建了个test分支，可以看到，在git中创建个分支简单到只需要在refs/heads/中创建个相应的文件，并在文件中写入41个字符（40个sha1标识+1个换行符). 1&gt; echo &apos;4f69a44b7b55cd5dd4dcb872af5b0ac5e793de9b&apos; &gt;&gt; test symbolic-ref除了分支信息外，git中还通过HEAD指针来指示当前所在分支的最新提交对象，这个信息就存储在.git/HEAD中，可以从HEAD文件的内容中看到，这个文件里存储的就是到refs/heads中某个文件的引用而已. 可以想像，在git中使用git checkout进行分支切换的时候，只需要将HEAD的中的内容指定相应的refs/heads中的分支结点，然后更新工作区的内容即可. 12&gt; cat HEADref: refs/heads/test All-in-one这里通过上述的命令简单地构造git的提交信息，完成通过git用户命令就可以完成的内容，进一步加深对git内部存储的理解. 创建文件test，并产生一些文件内容使用update-index –add将它加入到暂存区使用write-tree获取相应的树对象使用commit-tree获取相应的提交对象C1修改文件test内容，并增加新的文件new，加上一些内容使用update-index将它们加入到暂存区使用write-tree获取相应的树对象使用commit-tree获取相应的提交对象C2，并将它的父提交对象设置为C1重复前面四个步骤，获取提交对象C3，并将它的父对象设置为C2使用update-ref在refs/heads中创建master分支，并将它指向C1使用symbolic-ref将HEAD对象指定master使用git log来查看刚刚创建的提交记录树 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&gt; echo “first commit” &gt;&gt; test&gt; git update-index --add test&gt; git write-treebff0827a0da713487c9fca9235263772db9a3b0e&gt; echo &quot;first commit&quot; | git commit-tree bff0827a0da713487c9fca9235263772db9a3b0ed6fac28b22fffdcd4d54126ec44ec86a712d6fde&gt; echo &quot;second commit&quot; &gt;&gt; test&gt; echo &quot;new file&quot; &gt;&gt; new&gt; git update-index test&gt; git update-index --add new&gt; git write-treebde4f04d1037685b47deeb515984cdb994888d07&gt; echo &quot;second commit&quot; | git commit-tree bde4f04d1037685b47deeb515984cdb994888d07 -p d6fac28b22fffdcd4d54126ec44ec86a712d6fde0f33097c08b7827224083238dc9294f59aa7948a&gt; echo &quot;third commit&quot; &gt;&gt; test&gt; echo &quot;third commit&quot; &gt;&gt; new&gt; git update-index test&gt; git update-index new&gt; git write-treef4c0f72be323c47af0dd2bbddfbaf6f548b11926&gt; echo &quot;third commit&quot; | git commit-tree f4c0f72be323c47af0dd2bbddfbaf6f548b11926 -p 0f33097c08b7827224083238dc9294f59aa7948a25eee6f70d508567abe72969d3524f557bc159d8&gt; git update-ref refs/heads/master 25eee6f70d508567abe72969d3524f557bc159d8&gt; git update-ref refs/heads/test 0f33097c08b7827224083238dc9294f59aa7948a&gt; git log --pretty=onelie --graph --decorate=short&gt; git symbolic-ref HEAD refs/heads/test&gt; git log --pretty=onelie --graph --decorate=short 其它从上述的描述中可以看到，git内部维护了许多对象，包括blob, blob, tree以及tags信息，并且每次更新后重新提交又会创建新的blob对象，这样，随着时间的推移，git内部的对象将越来越多，如果不对这些对象进行一些处理，可以想像，这些对象占据的空间将逐步增大，因此，git内部使用了压缩的方法, 将一批文件压缩将形成pack文件，pack文件还有相应的idx信息，方便外部快速地对pack文件进行读取,这部分内容具体可以git官方文档. 参考文档ProGit Book: https://progit2.s3.amazonaws.com/en/2016-03-22-f3531/progit-en.1084.pdf","categories":[],"tags":[]},{"title":"java集合学习之源码分析1","slug":"集合/java集合学习之源码分析1","date":"2016-04-20T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/20/集合/java集合学习之源码分析1/","link":"","permalink":"http://yoursite.com/2016/04/20/集合/java集合学习之源码分析1/","excerpt":"","text":"#HashMap 在之前的学习中我们也提到过HashMap的一些特点，这里再简单地总结下： 非线程安全的实现方式 作为一种通用实现，它的key和value都可以是null 迭代器实现了fast-fail机制，即在迭代过程中如果发生了并发修改操作，会抛出异常 数据存储我们都知道map中的数据是以键值对的形式存储的，那么在hashMap中，具体存储的数据格式是怎么样的，当我们执行put或者get操作时，底层到底是如何实现的呢？一起先来看看HashMap的存储结构，如下图所示，hashMap事实上是数组和链表的组合体，每个键值对被封装成entry存储在这个结构中，每个entry除了提供的key和value之外，还有个很重要的元素是hash，它的值是由key经过hash计算得来的. PUT操作put操作的源码如下所示： 首先先根据提供的key值计算相应的hash值, 这个hash值决定了这个键值对会被存储在map中的哪个bucket中，即决定了图中数组的下标;而hash值的计算是根据Key的hashCode方法计算后取其高位16位得到，注意这里如果提供的key为null值，默认得到的哈希值为0，即key为null的键值对会被默认存储于0号桶中 得到hash, key, value后（暂时忽略onlyIfAbsent以及evict参数，它对hashMap的影响不是本质性的），会调用 putVal方法，这个方法首先检查数组的长度,如果为空或者数组长度为0，则进入resize操作(代码块第13行）(resize操作的细节请参见resize一章）.紧接着就会根据提供的hash值计算这个键值对所在的bucket的位置（在代码中为变量i的值)，这里分两种情况 如果数组的当前索引位置上没有元素，那么可以直接把这个元素放到数组的这个索引位置上(代码块第15行） 如果数组的当前索引位置上有元素，说明当前键值对的哈希值和Map中存储的另一键值对的哈希值发生了碰撞，在这种情况下，hashMap引入了链表的结构来进行存储。通过遍历链表上的元素，并通过key.equals()方法来比较当前的键值对和链表上的元素是否相等，如果相等那么直接进行替换，如果直到链表尾部也没有找到相等的元素，那么就在链表尾部插入新的键值对(代码块16~43行) 在完成元素的插入操作后，hashMap还会进行一次判断，比较当前map里存储的元素个数和预先设定的threshold值，这个阈值是由数组初始化长度和loadFactor相乘得来 ，如果超过这个阈值，说明当前Map中的负载已经较高，那么就进行一次resize操作，将数组的长度扩大一倍 除此之外，hashMap还做了一些优化，比如当某个bucket的链表超过一定数量时，它会把链表转化成树来存储，当少于一定数量时，又会转化成链表来存储；另外，通过modCount这个参数来实现了迭代器的fast-fail机制.（代码块第28行） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; ###GET操作 理解了put操作的原理后，再来理解get操作就非常简单了. 首先还是根据提供的key值计算相应的hash，计算的方法和put时使用的方法是一样的，否则可能会造成取不到值了 得到相应的hash值之后，相当于就知道这个元素所在的bucket的位置了，这个bucket在前面讲过，就是个链表结构，所以剩下要做的就是遍历这个链表，取出相应的值即可. 在遍历链表的时候，比较的是提供的key值和链表中的key值是否相等，通过key.equals()方法来判断，如果相等，说明找到了相应的值，直接返回；如果直到链表结尾都没有找到相等的元素，那么直接返回null即可. 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; RESIZE操作resize操作是在map中存储的键值对个数超过预先设置的阈值时对hashMap进行扩容的实现，预设的阈值由capacity和load_factor两个参数共同决定, capacity决定了数组的初始长度，而load_factory决定了当数组的负载达到多少的时候，进入resize操作. 首先判断旧的数组长度，如果长度不为0，则直接将capacity和threshold扩大为原来的两倍 如果旧数组长度为0， 说明这是个初始化操作, 初始化的数组长度保存于threshold中(代码块15行） 如果capacity和threshold都为0，新的数组长度和阈值均采用默认值 在计算好新的数组长度和阈值之后，要做的就是遍历原来的元素并将迁移到现在的数组中（代码块31~69行）. 注意这里的每个数组元素可能都是一个链表，所以每次遍历的是一个链表，而不是一个数组元素。在遍历的时候，还要注意的是这里将hash和原来的数组长度按位并操作，如果得到的结果为0，说明这个元素在新的数组中还是应该存储在原来的索引位置上，如果得到的值不是0，说明这个键值对在新的数组中应该放在另外的位置，这个位置就是原先位置偏移oldCap个索引的位置. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;","categories":[],"tags":[]},{"title":"java集合学习之源码分析","slug":"集合/java-collection-hashmap","date":"2016-04-19T11:22:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/19/集合/java-collection-hashmap/","link":"","permalink":"http://yoursite.com/2016/04/19/集合/java-collection-hashmap/","excerpt":"","text":"HashMap在之前的学习中我们也提到过HashMap的一些特点，这里再简单地总结下： 非线程安全的实现方式 作为一种通用实现，它的key和value都可以是null 迭代器实现了fast-fail机制，即在迭代过程中如果发生了并发修改操作，会抛出异常 数据存储我们都知道map中的数据是以键值对的形式存储的，那么在hashMap中，具体存储的数据格式是怎么样的，当我们执行put或者get操作时，底层到底是如何实现的呢？一起先来看看HashMap的存储结构，如下图所示，hashMap事实上是数组和链表的组合体，每个键值对被封装成entry存储在这个结构中，每个entry除了提供的key和value之外，还有个很重要的元素是hash，它的值是由key经过hash计算得来的. PUT操作put操作的源码如下所示： 首先先根据提供的key值计算相应的hash值, 这个hash值决定了这个键值对会被存储在map中的哪个bucket中，即决定了图中数组的下标;而hash值的计算是根据Key的hashCode方法计算后取其高位16位得到，注意这里如果提供的key为null值，默认得到的哈希值为0，即key为null的键值对会被默认存储于0号桶中 得到hash, key, value后（暂时忽略onlyIfAbsent以及evict参数，它对hashMap的影响不是本质性的），会调用 putVal方法，这个方法首先检查数组的长度,如果为空或者数组长度为0，则进入resize操作(resize操作的细节请参见resize一章）.紧接着就会根据提供的hash值计算这个键值对所在的bucket的位置（在代码中为变量i的值)，这里分两种情况 如果数组的当前索引位置上没有元素，那么可以直接把这个元素放到数组的这个索引位置上 如果数组的当前索引位置上有元素，说明当前键值对的哈希值和Map中存储的另一键值对的哈希值发生了碰撞，在这种情况下，hashMap引入了链表的结构来进行存储。通过遍历链表上的元素，并通过key.equals()方法来比较当前的键值对和链表上的元素是否相等，如果相等那么直接进行替换，如果直到链表尾部也没有找到相等的元素，那么就在链表尾部插入新的键值对 在完成元素的插入操作后，hashMap还会进行一次判断，比较当前map里存储的元素个数和预先设定的threshold值，这个阈值是由数组初始化长度和loadFactor相乘得来 ，如果超过这个阈值，说明当前Map中的负载已经较高，那么就进行一次resize操作，将数组的长度扩大一倍 除此之外，hashMap还做了一些优化，比如当某个bucket的链表超过一定数量时，它会把链表转化成树来存储，当少于一定数量时，又会转化成链表来存储；另外，通过modCount这个参数来实现了迭代器的fast-fail机制. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; GET操作理解了put操作的原理后，再来理解get操作就非常简单了. 首先还是根据提供的key值计算相应的hash，计算的方法和put时使用的方法是一样的，否则可能会造成取不到值了 得到相应的hash值之后，相当于就知道这个元素所在的bucket的位置了，这个bucket在前面讲过，就是个链表结构，所以剩下要做的就是遍历这个链表，取出相应的值即可. 在遍历链表的时候，比较的是提供的key值和链表中的key值是否相等，通过key.equals()方法来判断，如果相等，说明找到了相应的值，直接返回；如果直到链表结尾都没有找到相等的元素，那么直接返回null即可. 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; RESIZE操作resize操作是在map中存储的键值对个数超过预先设置的阈值时对hashMap进行扩容的实现，预设的阈值由capacity和load_factor两个参数共同决定, capacity决定了数组的初始长度，而load_factory决定了当数组的负载达到多少的时候，进入resize操作. 首先判断旧的数组长度，如果长度不为0，则直接将capacity和threshold扩大为原来的两倍 如果旧数组长度为0， 说明这是个初始化操作, 初始化的数组长度保存于threshold中 如果capacity和threshold都为0，新的数组长度和阈值均采用默认值 在计算好新的数组长度和阈值之后，要做的就是遍历原来的元素并将迁移到现在的数组中. 注意这里的每个数组元素可能都是一个链表，所以每次遍历的是一个链表，而不是一个数组元素。在遍历的时候，还要注意的是这里将hash和原来的数组长度按位并操作，如果得到的结果为0，说明这个元素在新的数组中还是应该存储在原来的索引位置上，如果得到的值不是0，说明这个键值对在新的数组中应该放在另外的位置，这个位置就是原先位置偏移oldCap个索引的位置. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;","categories":[],"tags":[{"name":"java collection hashMap","slug":"java-collection-hashMap","permalink":"http://yoursite.com/tags/java-collection-hashMap/"}]},{"title":"java集合学习","slug":"集合/java-collection-concurrent-implements","date":"2016-04-18T13:55:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/18/集合/java-collection-concurrent-implements/","link":"","permalink":"http://yoursite.com/2016/04/18/集合/java-collection-concurrent-implements/","excerpt":"","text":"JAVA的集合框架中提供了很多通用的实现，但这些实现基本上都不是线程安全的，因此，JAVA框架还提供了这些集合类的并发实现，这篇文章专门来讨论这些并发的实现 BlockingQueue接口这个接口定义了线程安全的QUEUE接口，在从队列里读取或者插入操作时，如果队列为空，或者已经到达队列上限，那么操作会被阻塞. 按操作无法立即执行时方法执行的操作可以将BlockingQueue的方法分为四类： 抛出异常: add, remove, element 返回特殊值: offer, poll, peek 阻塞直到可执行: put, take 阻塞一定时间: offer, poll BlockingQueue的实现有五种： ArrayBlockingQueue: BlockingQueue的数组实现，这种实现的元素在创建时就定好了，如果达到数组的上限，那么offer和put操作将不能得到立即实现; LinkedBlockingQueue: 阻塞队列的链表实现. 这种实现默认是是没有元素个数限制的, 当然如果希望有上限的话，也可以设置 DelayQueue: 延迟队列，它的元素必须实现了Delay接口，返回延迟的时间，在这个时间前，元素不能被消费,其底层是通过PriorityQueue来实现的. PriorityBlockingQueue: 这种实现可以是PriorityQueue的并发实现, 它的所有元素必须实现Comparable，或者在构造对象时提供相应的comparator接口的实现，这点和PriorityQueue是一致的. SynchronizedQueue: 这是一种特殊的阻塞队列的实现，它只有一个元素，并且插入的线程一直阻塞到这个元素被消费了为止；同样地，如果一个线程试图从空队列中取元素，那么它也会一直阻塞到有其它线程往这个队列里插入新的元素为止. BlockingDeque接口这个接口是双向队列的阻塞接口，它和BlockingQueue的关系就像Queue和Deque的关系是一样的，所有的BlockingQueue的操作在双向扩展后即是BlockingDeque的方法，这里就不做具体的叙述，实现这个接口的类只有一个LinkedBlockingDeque,从名字可以看出，这是一种链表实现. ConcurrentMap接口这是Map的并发实现接口, 它提供了线程安全的访问Map的方法，它的实现有ConcurrentHashMap, 这个实现和HashTable十分相似，但有几点不同： 在进行读操作时，ConcurrentHashMap不会对map加锁，而hashTable会对所有的操作进行同步 在进行写操作时，concurrentHashMap不会对整个map加锁，它将整个map分为几个部分（默认为16）,每次写操作时只会对一个部分进行加锁，而hashTable会对整个map进行同步 在迭代过程, 如果map的内容发生了变化，concurrentHashMap不会抛出异常，虽然它的迭代器并不是为并发设计的 参考文献Sample代码： 这里 参考文献: 参考文献","categories":[],"tags":[{"name":"java collection implement concurrent","slug":"java-collection-implement-concurrent","permalink":"http://yoursite.com/tags/java-collection-implement-concurrent/"}]},{"title":"java集合学习之并发实现","slug":"集合/java集合学习之并发实现","date":"2016-04-18T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/18/集合/java集合学习之并发实现/","link":"","permalink":"http://yoursite.com/2016/04/18/集合/java集合学习之并发实现/","excerpt":"","text":"JAVA的集合框架中提供了很多通用的实现，但这些实现基本上都不是线程安全的，因此，JAVA框架还提供了这些集合类的并发实现，这篇文章专门来讨论这些并发的实现 BlockingQueue接口这个接口定义了线程安全的QUEUE接口，在从队列里读取或者插入操作时，如果队列为空，或者已经到达队列上限，那么操作会被阻塞. 按操作无法立即执行时方法执行的操作可以将BlockingQueue的方法分为四类： 抛出异常: add, remove, element 返回特殊值: offer, poll, peek 阻塞直到可执行: put, take 阻塞一定时间: offer, poll BlockingQueue的实现有五种： ArrayBlockingQueue: BlockingQueue的数组实现，这种实现的元素在创建时就定好了，如果达到数组的上限，那么offer和put操作将不能得到立即实现; LinkedBlockingQueue: 阻塞队列的链表实现. 这种实现默认是是没有元素个数限制的, 当然如果希望有上限的话，也可以设置 DelayQueue: 延迟队列，它的元素必须实现了Delay接口，返回延迟的时间，在这个时间前，元素不能被消费,其底层是通过PriorityQueue来实现的. PriorityBlockingQueue: 这种实现可以是PriorityQueue的并发实现, 它的所有元素必须实现Comparable，或者在构造对象时提供相应的comparator接口的实现，这点和PriorityQueue是一致的. SynchronizedQueue: 这是一种特殊的阻塞队列的实现，它只有一个元素，并且插入的线程一直阻塞到这个元素被消费了为止；同样地，如果一个线程试图从空队列中取元素，那么它也会一直阻塞到有其它线程往这个队列里插入新的元素为止. BlockingDeque接口这个接口是双向队列的阻塞接口，它和BlockingQueue的关系就像Queue和Deque的关系是一样的，所有的BlockingQueue的操作在双向扩展后即是BlockingDeque的方法，这里就不做具体的叙述，实现这个接口的类只有一个LinkedBlockingDeque,从名字可以看出，这是一种链表实现. ConcurrentMap接口这是Map的并发实现接口, 它提供了线程安全的访问Map的方法，它的实现有ConcurrentHashMap, 这个实现和HashTable十分相似，但有几点不同： 在进行读操作时，ConcurrentHashMap不会对map加锁，而hashTable会对所有的操作进行同步 在进行写操作时，concurrentHashMap不会对整个map加锁，它将整个map分为几个部分（默认为16）,每次写操作时只会对一个部分进行加锁，而hashTable会对整个map进行同步 在迭代过程, 如果map的内容发生了变化，concurrentHashMap不会抛出异常，虽然它的迭代器并不是为并发设计的 参考文献Sample代码： 这里参考文献: 参考文献","categories":[],"tags":[]},{"title":"Java集合学习","slug":"集合/java-collection-implements","date":"2016-04-17T03:14:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/17/集合/java-collection-implements/","link":"","permalink":"http://yoursite.com/2016/04/17/集合/java-collection-implements/","excerpt":"","text":"JAVA集合框架的接口部分定义了各种集合类的功能，具体的实现则在各种具体的实现中完成。按照实现的目的不同，JAVA集合接口的实现可分为以下几种： 通用目的的实现： 这些实现都是日常开发中经常用到的实现，具体的实现类包括： 特殊目的的实现： 这些实现都是为了一些特殊目的而进行的实现，可能会有某些限制 并发实现（也称为线程安全的实现）: 这些实现由java.util.concurret包提供，主要是提供相应接口的高并发实现，在性能上要比相应单线程实现稍差 包装实现：这些实现通常要与通用的实现一起，通过对通用实现的封装，实现或增加某些功能，这是一种装饰器模式的实现，装饰器模式的结构图如下所示： 工具类实现： 这类实现通常是利用静态工厂方法来很方便地提供通用实现的实例 从通用实现的表中可以看到，set, list和map都提供了相应的通用实现，sortedSet和sortedMap都只提供了一种实现，即TreeSet和TreeMap，Queue也提供了LinkedList和PriorityQueue的实现，它们的语义是不同的，LinkedList提供了FIFO的实现，而priorityQueue则是按照元素的值进行排序. 所有通用实现的类都提供了接口所有的可选操作，并且都允许它们的元素，键和值为null，并且它们都不是线程安全的实现，而且它们的迭代器都采用了fast-fail^1机制 Set接口的实现Set接口提供了三种默认的实现: HashSet, TreeSet和LinkedHashSet. HashSet: 这是三种实现中效率最高的实现，基本上大部分的操作可以在常量时间内完成，但它没有对元素的顺序提供任何保证，如果对元素的顺序没有特殊要求，基本上可以考虑使用这种实现注意 HashSet的迭代效率同时取决于它的元素个数和capacity的大小，因此，如果将capacity的值设置得过大，那么将造成时间和空间的浪费，但如果设置得太小，也会导致元素不停地被复制。如果这个值没有被设置，那么默认为16. TreeSet: 如果需要使用SortedSet，或者需要迭代时需要根据元素的值进行排序时，则需要使用这种实现 LinkedHashSet: 这种实现可以认为是介于HashSet和TreeSet的一种实现，它在内部维护了一份双向链表，实现的效率与HashSet相差无几，但遍历的时候会按照元素插入的顺序进行 同时，Java框架也提供了两种特殊目的实现，EnumSet和CopyOnWriteSet EnumSet: 这种set实现了对枚举类型的某些方便操作，比如获取某种枚举类型的所有元素，补集等操作，总得来讲，比较简单. CopyOnWriteSet: 内部是维护了一份CopyOnWriteList对象，它们唯一的区别是CopyOnWriteList允许有重复元素,而CopyOnWriteSet不允许, 事实上, COWSet的所有操作都是通过COWList来完成的(除了add)。这种实现的机制是所有的写操作(add, remove, set等等)都会复制一份原来的数据，然后进行写操作，然后再把数据赋值给原来的引用, 当然在整个写的过程中，需要使用锁机制完成。 另外，它的迭代器不支持写操作，同时在迭代的过程中，由其它线程更新的数据也不会被迭代器看到，也就是说，在迭代器创建的时候，它就维护了那个时刻集合中元素的一个快照，因此它的迭代过程中不会有线程安全问题. CopyOnWrite的实现决定了它只适合于那种读操作远远超过写操作的场合. List接口的实现在JAVA框架中，提供了List接口的两种通用实现，一种是ArrayList， 一种是LinkedList， 顾名思义，这两种实现分别是基于数组和链接的方式实现的，它们的优缺点也比较明显： 数组方式的实现能够在常量时间内提供位置访问，但插入和删除操作需要对元素进行拷贝；而链表方式的实现，插入操作和删除操作不需要进行元素拷贝，只需要修改下元素的前后指标即可，但访问某个元素需要通过遍历的方式进行，需要线性时间来完成。 JAVA框架中还提供了一种特殊的实现，CopyOnWriteArrayList, 这种实现的机制就像COWSet中阐述的那样，是一种线程安全的实现，每次的写操作都会导致内部数据的复制，因此特别适合于大量写少量写的场合，比如用它来维护一个eventHandler的列表 Map接口的实现Map的三种实现是和Set的三种实现一一对应的，分别是HashMap， TreeMap和LinkedHashMap. 使用它们的场景也各不相同： 如果需要执行SortedMap的操作或者需要按照Key值顺序对整个集合进行遍历时，使用TreeMap 如果希望获得最好的运行效率而不关心遍历顺序时，使用HashMap 如果希望按照插入的顺序进行遍历时，使用LinkedHashMap Map的特殊实现还包括: EnumMap, WeakHashMap, IdentityHashMap以及CocurrentMap. 其中CocurrentMap是由JAVA的并发框架提供的map的并发实现. EnuMap: 这种实现底层是通过数组来实现的，是以枚举类的对象为key值，并提供快速访问数组元素的方法，如果希望将枚举类型映射成值，应该考虑使用这种实现 WeakHashMap: 这种实现的key值使用了对象的弱引用（weak reference，具体含义及说明请见这里), 也就是说，当集合中的Key对象不再被外界引用的时候，它会被GC回收，导致相应的entry不存在. IdentityHashMap: 这种类型的实现是使用引用相等性来替代对象相等性，也就是说，它可以允许存在重复的key值，在identityHashMap中，判断两个key值相等的条件是k1 == k2. 注意这里比较的是引用相等， 而在一般的map实现中，Key值的相等条件是(k1==null)?k2==null:k1.equals(k2). CocurrentMap：这是由java的并发框架提供的一种线程安全的map实现，CocurrentHashMap是它的一种实现，和hashtable不同的是，它并不是简单地对所有方法加上synchronized关键字，它是通过将bucket分成几个部分（默认为16）,每次操作的时候只获取相应部分的锁，从而达到并发操作的目的. Queue接口的实现Queue接口提供了两种通用实现： Queue的poll, remove, element以及peek等方法都是取出相应的头元素，而所谓的头元素是指排序上排得最前面的那个元素，具体排序的规则由相应的实现规定. 在遍历Queue的时候，要使用poll方法来获取相应的元素，这些元素才会按照相应的顺序进行排序输出，如果使用iterator， 会直接按照底层的数组顺序进行输出，这点可以从PriorityQueue的测试代码中很明显的看出来。 LinkedList: 这是一种FIFO的队列，它的元素顺序是指插入的时间顺序 PriorityQueue: 这是一种优先级队列.它的顺序是指元素的自然顺序或者是在构建对象时指定的comparator指定的比较顺序. Queue接口还提供了相应的并发实现，通过定义BlockingQueue来完成，它拓展了queue的功能，在获取元素时可以一直等待直到队列非空，在插入元素时会一直等待直接队列可用。BlockingQueue有几下几种实现: ArrayBlockingQueue: 一种FIFO的阻塞队列实现，底层是通过数组来实现 LinkedBlockingQueue: 这是一种通过链表实现的FIFO阻塞队列 PriorityBlockingQueue: 具有优先级的阻塞队列 DelayQueue: 基于定时器的阻塞队列 Deque接口的实现Deque接口定义可以从两端进行存储的容器类，它提供了两种通用实现和一种并发实现： ArrayDeque: 它在队列两端进行增删的效率要高于LinkedList LinkedList: 双向队列的链表实现，它在队列两端进行增删的不如ArrayDeque, 但它在迭代过程中可以删除相应的元素，并且效率要好于ArrayDeque. LinkedBlockingDeque: 这是deque接口的阻塞式链表实现，在获取元素时，如果队列为空，它会一直阻塞直到队列中出现了新的元素才返回 包装实现JAVA的集合框架中提供了相应接口的包装实现，这是一种装饰器模式的应用 ，它可以在原有的接口功能上加上一些特殊功能和限制，比如同步机制，不可修改的限制等等. 这些实现通常不是通过提供公有的类定义来实现，而是通过collections这个类的静态方法来提供，大体上，包装类可分为两大类： 同步实现： 这种实现对于每种接口都有一个相应的方法，把原来通用实现中线程不安全的集合接口封装成线程安全的实现，底层是通过对每个方法都加上synchronized关键字来实现的，可想而知，效率并不高，但在一些场合保证了并发操作的安全性. Collections中所有以synchronized开头的方法都是这种实现. 增加不可变限制： 目前所有的接口实现都不要求它的元素是不可变的，在生成相应的容器类及元素后，可以对容器当中的元素进行任意地修改，通过这种装饰器模式，容器中的元素就具备了只读属性，当然，这里有个前提，在得到包装后的容器类后，就不应该再引用原来的容器类，更不应该对原来的容器类进行修改，从而保证包装后的容器中的元素不会被修改。这种实现是通过重载所有会对容器中元素进行修改操作的方法来完成，它会抛出UnsupportedOperation异常. Collections中所有以unmodifiable开头的方法都是这种实现. 参考文献 参考文献: JAVA官方文档 示例代码：集合实现sample代码","categories":[],"tags":[{"name":"java collection","slug":"java-collection","permalink":"http://yoursite.com/tags/java-collection/"}]},{"title":"java集合学习之实现","slug":"集合/java集合学习之实现","date":"2016-04-17T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/17/集合/java集合学习之实现/","link":"","permalink":"http://yoursite.com/2016/04/17/集合/java集合学习之实现/","excerpt":"","text":"JAVA集合框架的接口部分定义了各种集合类的功能，具体的实现则在各种具体的实现中完成。按照实现的目的不同，JAVA集合接口的实现可分为以下几种： 通用目的的实现： 这些实现都是日常开发中经常用到的实现，具体的实现类包括： 特殊目的的实现： 这些实现都是为了一些特殊目的而进行的实现，可能会有某些限制 并发实现（也称为线程安全的实现）: 这些实现由java.util.concurret包提供，主要是提供相应接口的高并发实现，在性能上要比相应单线程实现稍差 包装实现：这些实现通常要与通用的实现一起，通过对通用实现的封装，实现或增加某些功能，这是一种装饰器模式的实现，装饰器模式的结构图如下所示： 工具类实现： 这类实现通常是利用静态工厂方法来很方便地提供通用实现的实例 从通用实现的表中可以看到，set, list和map都提供了相应的通用实现，sortedSet和sortedMap都只提供了一种实现，即TreeSet和TreeMap，Queue也提供了LinkedList和PriorityQueue的实现，它们的语义是不同的，LinkedList提供了FIFO的实现，而priorityQueue则是按照元素的值进行排序. 所有通用实现的类都提供了接口所有的可选操作，并且都允许它们的元素，键和值为null，并且它们都不是线程安全的实现，而且它们的迭代器都采用了fast-fail^1机制 Set接口的实现Set接口提供了三种默认的实现: HashSet, TreeSet和LinkedHashSet. HashSet: 这是三种实现中效率最高的实现，基本上大部分的操作可以在常量时间内完成，但它没有对元素的顺序提供任何保证，如果对元素的顺序没有特殊要求，基本上可以考虑使用这种实现注意 HashSet的迭代效率同时取决于它的元素个数和capacity的大小，因此，如果将capacity的值设置得过大，那么将造成时间和空间的浪费，但如果设置得太小，也会导致元素不停地被复制。如果这个值没有被设置，那么默认为16. TreeSet: 如果需要使用SortedSet，或者需要迭代时需要根据元素的值进行排序时，则需要使用这种实现 LinkedHashSet: 这种实现可以认为是介于HashSet和TreeSet的一种实现，它在内部维护了一份双向链表，实现的效率与HashSet相差无几，但遍历的时候会按照元素插入的顺序进行 同时，Java框架也提供了两种特殊目的实现，EnumSet和CopyOnWriteSet EnumSet: 这种set实现了对枚举类型的某些方便操作，比如获取某种枚举类型的所有元素，补集等操作，总得来讲，比较简单. CopyOnWriteSet: 内部是维护了一份CopyOnWriteList对象，它们唯一的区别是CopyOnWriteList允许有重复元素,而CopyOnWriteSet不允许, 事实上, COWSet的所有操作都是通过COWList来完成的(除了add)。这种实现的机制是所有的写操作(add, remove, set等等)都会复制一份原来的数据，然后进行写操作，然后再把数据赋值给原来的引用, 当然在整个写的过程中，需要使用锁机制完成。 另外，它的迭代器不支持写操作，同时在迭代的过程中，由其它线程更新的数据也不会被迭代器看到，也就是说，在迭代器创建的时候，它就维护了那个时刻集合中元素的一个快照，因此它的迭代过程中不会有线程安全问题. CopyOnWrite的实现决定了它只适合于那种读操作远远超过写操作的场合. List接口的实现在JAVA框架中，提供了List接口的两种通用实现，一种是ArrayList， 一种是LinkedList， 顾名思义，这两种实现分别是基于数组和链接的方式实现的，它们的优缺点也比较明显： 数组方式的实现能够在常量时间内提供位置访问，但插入和删除操作需要对元素进行拷贝；而链表方式的实现，插入操作和删除操作不需要进行元素拷贝，只需要修改下元素的前后指标即可，但访问某个元素需要通过遍历的方式进行，需要线性时间来完成。 JAVA框架中还提供了一种特殊的实现，CopyOnWriteArrayList, 这种实现的机制就像COWSet中阐述的那样，是一种线程安全的实现，每次的写操作都会导致内部数据的复制，因此特别适合于大量写少量写的场合，比如用它来维护一个eventHandler的列表 Map接口的实现Map的三种实现是和Set的三种实现一一对应的，分别是HashMap， TreeMap和LinkedHashMap. 使用它们的场景也各不相同： 如果需要执行SortedMap的操作或者需要按照Key值顺序对整个集合进行遍历时，使用TreeMap 如果希望获得最好的运行效率而不关心遍历顺序时，使用HashMap 如果希望按照插入的顺序进行遍历时，使用LinkedHashMap Map的特殊实现还包括: EnumMap, WeakHashMap, IdentityHashMap以及CocurrentMap. 其中CocurrentMap是由JAVA的并发框架提供的map的并发实现. EnuMap: 这种实现底层是通过数组来实现的，是以枚举类的对象为key值，并提供快速访问数组元素的方法，如果希望将枚举类型映射成值，应该考虑使用这种实现 WeakHashMap: 这种实现的key值使用了对象的弱引用（weak reference，具体含义及说明请见这里), 也就是说，当集合中的Key对象不再被外界引用的时候，它会被GC回收，导致相应的entry不存在. IdentityHashMap: 这种类型的实现是使用引用相等性来替代对象相等性，也就是说，它可以允许存在重复的key值，在identityHashMap中，判断两个key值相等的条件是k1 == k2. 注意这里比较的是引用相等， 而在一般的map实现中，Key值的相等条件是(k1==null)?k2==null:k1.equals(k2). CocurrentMap：这是由java的并发框架提供的一种线程安全的map实现，CocurrentHashMap是它的一种实现，和hashtable不同的是，它并不是简单地对所有方法加上synchronized关键字，它是通过将bucket分成几个部分（默认为16）,每次操作的时候只获取相应部分的锁，从而达到并发操作的目的. Queue接口的实现Queue接口提供了两种通用实现： Queue的poll, remove, element以及peek等方法都是取出相应的头元素，而所谓的头元素是指排序上排得最前面的那个元素，具体排序的规则由相应的实现规定. 在遍历Queue的时候，要使用poll方法来获取相应的元素，这些元素才会按照相应的顺序进行排序输出，如果使用iterator， 会直接按照底层的数组顺序进行输出，这点可以从PriorityQueue的测试代码中很明显的看出来。 LinkedList: 这是一种FIFO的队列，它的元素顺序是指插入的时间顺序 PriorityQueue: 这是一种优先级队列.它的顺序是指元素的自然顺序或者是在构建对象时指定的comparator指定的比较顺序. Queue接口还提供了相应的并发实现，通过定义BlockingQueue来完成，它拓展了queue的功能，在获取元素时可以一直等待直到队列非空，在插入元素时会一直等待直接队列可用。BlockingQueue有几下几种实现: ArrayBlockingQueue: 一种FIFO的阻塞队列实现，底层是通过数组来实现 LinkedBlockingQueue: 这是一种通过链表实现的FIFO阻塞队列 PriorityBlockingQueue: 具有优先级的阻塞队列 DelayQueue: 基于定时器的阻塞队列 Deque接口的实现Deque接口定义可以从两端进行存储的容器类，它提供了两种通用实现和一种并发实现： ArrayDeque: 它在队列两端进行增删的效率要高于LinkedList LinkedList: 双向队列的链表实现，它在队列两端进行增删的不如ArrayDeque, 但它在迭代过程中可以删除相应的元素，并且效率要好于ArrayDeque. LinkedBlockingDeque: 这是deque接口的阻塞式链表实现，在获取元素时，如果队列为空，它会一直阻塞直到队列中出现了新的元素才返回 包装实现JAVA的集合框架中提供了相应接口的包装实现，这是一种装饰器模式的应用 ，它可以在原有的接口功能上加上一些特殊功能和限制，比如同步机制，不可修改的限制等等. 这些实现通常不是通过提供公有的类定义来实现，而是通过collections这个类的静态方法来提供，大体上，包装类可分为两大类： 同步实现： 这种实现对于每种接口都有一个相应的方法，把原来通用实现中线程不安全的集合接口封装成线程安全的实现，底层是通过对每个方法都加上synchronized关键字来实现的，可想而知，效率并不高，但在一些场合保证了并发操作的安全性. Collections中所有以synchronized开头的方法都是这种实现. 增加不可变限制： 目前所有的接口实现都不要求它的元素是不可变的，在生成相应的容器类及元素后，可以对容器当中的元素进行任意地修改，通过这种装饰器模式，容器中的元素就具备了只读属性，当然，这里有个前提，在得到包装后的容器类后，就不应该再引用原来的容器类，更不应该对原来的容器类进行修改，从而保证包装后的容器中的元素不会被修改。这种实现是通过重载所有会对容器中元素进行修改操作的方法来完成，它会抛出UnsupportedOperation异常. Collections中所有以unmodifiable开头的方法都是这种实现. 参考文献 参考文献: JAVA官方文档 示例代码：集合实现sample代码","categories":[],"tags":[]},{"title":"强引用，软引用，弱引用以及虚引用","slug":"reference-types-in-java","date":"2016-04-16T09:55:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/16/reference-types-in-java/","link":"","permalink":"http://yoursite.com/2016/04/16/reference-types-in-java/","excerpt":"","text":"强引用(Strong Reference)是指平时经常用到的引用类型，如果某个对象存在强引用，那么它将不会被GC回收 软引用(Soft Reference)是指那些有用但不是必需的对象，它经常被用作缓存，当JVM内存充足时，它不会被GC回收，但如果内存不足时，它会被回收；它可以和引用队列(ReferenceQueue)进行关联，当软引用被回收时，它就进入关联的引用队列 弱引用(Weak Reference)是指不是必需的引用，在GC开始的时候，不管内存是否充足，它都将被回收；它可以和引用队列（ReferenceQueue)相关联，当弱引用被回收时，它就被加入到相关联的引用队列中 虚引用(Phantom Reference) 并不影响对象的生命周期，如果一个对象和虚引用关联，那么就跟没有和引用关联一样，它随时可能被GC回收，它必须和引用队列相关联，当GC某个对象时，如果发现它还有虚引用，则会把它加入到相应的引用队列中，可以通过判断虚引用是否出现在这个引用队列中，来确定该对象是否被回收 参考文献：参考文献","categories":[],"tags":[{"name":"引用类型，GC","slug":"引用类型，GC","permalink":"http://yoursite.com/tags/引用类型，GC/"}]},{"title":"JAVA集合学习","slug":"集合/java-collection-interface","date":"2016-04-14T13:47:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/14/集合/java-collection-interface/","link":"","permalink":"http://yoursite.com/2016/04/14/集合/java-collection-interface/","excerpt":"","text":"java集合框架的内容包括三个部分， 分别为接口，实现，算法. 本章只详述接口部分的内容。 接口： 接口可从宏观上分为两类， 分别为map和collection， collection又可细分为set, list, queue, deque.在理解接口的时候，可以从以下几个方面来理解： 接口提供了哪些功能 接口有哪些具体的实现，以及它们之间的区别 接口可以有哪些操作 Collection接口collection接口中包括了集合最基本的操作，比如size, add, remove, iterator, isEmpty, contains等等操作，不同的collection实现类可以通过构造函数很方便地进行类型转换.如下: List&lt;String&gt; strings = new LinkedList&lt;String&gt;(); Set&lt;String&gt; stringSets = new HashSet&lt;String&gt;(strings); 遍历collection的方式 在JDK1.8中，可以通过聚合操作来完成 collection.stream().filter(e –&gt; e.getColor == Colors.RED).forEach(e –&gt; doSth(e)) 使用forEach操作 for(String s : collection){ doSth(s); } 使用iterator操作: 这里的iterator使用了迭代器模式，可以借此机会复习下迭代器模式，在遍历的过程中，使用迭代器的remove方法也是唯一能够安全地操作collection中的元素的方法，如果在遍历的过程中使用其它的方式改变了collection中的元素，其行为是不可预知的. Iterator iter = collection.iterator(); while(iter.hasNext()){ doSth(iter.next()); } Set接口Set接口定义了元素不能重复的集合类，它可以认为是数学意义上的集合，在JAVA的集合框架中有三种不同的实现： HashSet: 底层使用HashMap进行存储，事实上HashMap的keySet就是这个hashSet, 它不保证集合遍历的顺序，但这是效率最好的实现 TreeSet: 底层使用红黑树存储，根据它们的值进行排序，效率比hashSet略慢 LinkedHashSet: 底层使用hashMap以及双向链接进行存储，它能够保证元素遍历的顺序与插入的顺序一致 既然把set接口认为是数学意义上的集合，很显然就可以对它进行交集、并集、求差等操作，事实上set接口中的retailAll和removeAll方法就是用来实现这些功能的 List接口List接口定义了一组有序集合，集合中的元素可以重复，它提供了顺序访问以及搜寻功能，同时也提供了遍历和局部视图功能，可以取出集合中的某部分元素集合进行操作，在JAVA集合框架中，提供了两种实现： ArrayList: 底层使用数组来实现元素的存储，在绝大部分情况下，这种实现的性能是比较好的。 LinkedList: List的链表实现, 底层使用双向链表进行存储，这种实现在增删元素时性能更佳，但顺序访问时性能不好，因为需要遍历整个链表 Queue接口Queue是一系列准备用于处理的元素的集合，除了collection提供的方法之外，它还提供了额外的增改查操作，对于所有的增改查操作，queue接口都提供了两种实现方式，在操作失败的时候，一种是抛出异常，另一种是返回特定的值（如null或者false， 依不同的操作而定), 具体的操作如下： 其中，add， remove和element在操作失败的时候会抛出异常, 而与它们一一对应的offer, poll和peek在操作失败时则会返回false，另外remove/poll和element/peek的区别在于，前者从queue中取到元素后，会把元素从queue中删除，而后者则不会 Deque接口deque接口是可以从头尾进行增删改的队列接口，应该说它是queue接口的扩展，因为它同时实现了queue(FIFO）以及堆(LIFO)的功能，从它的提供的操作来看，也可以很清楚地看到这点，所有在queue中的六个操作(add, offer, remove, poll, element, peek)在deque都有头元素以及尾元素的实现，具体操作如下： 可以看到，所有的六个操作都有了两种针对头元素和尾元素的实现，但语义不变 Map接口map接口提供了将Key映射成value的对象，它可以认为是数学意义上的函数。它提供了基本的增删改查的操作以及相应的视图操作(put, remove, get, contains, size, empty, entrySet, keySet, values)等等 注意在map接口提供的三个视图中，keySet和entrySet都是set类型的，也就是说它们是不能重复的，但是values只是collection类型，这意味着它的值是可以重复的（这也是数学意义上函数的定义). 另外，在视图上的一些操作（如removeAll, retailAll等)都会影响到原来的map的内容,具体可以查阅HashMap的keySet方法的实现源码 在JAVA集合框架中也提供了三种实现： HashMap, TreeMap和LinkedHashMap.它们的语义及特点正如这些名字所指示的那样，和对应的三个Set(HashSet, TreeSet, LinkedHashSet)相同，事实上，对应的set在实现的时候，内部就是借助了Map的key不能重复的特点，直接将map的keySet进行使用 multimap的语义是它的每个Key值可以指向多个value, 在java的集合框架中并没有这种类型，事实上，这种主义的Map完全可以通过将值的类型设置为某种集合来实现，如Map&lt;String, List&lt;String&gt;&gt;. 因此，这种类型的map将不再被特殊讨论和对待. Comparable接口在进一步学习容器接口之前，有必要先了解下Comparable接口，顾名思义，这个接口定义了对象的比较属性，实现了这个接口的类就具备了可比较性，比较的语义由实现决定，在JAVA的实现中有很多类都实现了这个接口，比如String，按照字母顺序进行比较；Date类会按照时间顺序进行比较 Comparator接口这是另一个用来实现对象比较的接口，在一些集合类算法中，如果某些类对象没有实现comparable接口，在使用排序算法时，可以额外提供一个comparator接口来实现排序功能，事实上，comparator接口是一种策略模式的实现，策略模式的结构图如下: SortedSet接口SortedSet是一种set接口，但是它把元素按照升序进行排列，排序的规则由元素本身提供(自然排序)，前提是元素实现了Comparable接口，否则将返回类型转换错误; 如果元素没有实现comparable接口，也可以提供comparator接口，通过使用策略模式来进行排序SortedSet接口提供了几类操作：视图操作，端点操作以及获取内部使用的comparator的接口的操作 视图操作情况下，如果原来的集合中的元素被修改了，视图中的元素也会发生相应的变化，反过来也一样，也就是说，可以把视图当作集合的一个窗口，视图操作获取的元素只不过通过这个窗口能看到的原来的集合中的部分元素 端点操作默认是左闭右开区间，即包含头节点，但不包含尾节点，但可以通过在头节点或者尾节点后增加“\\0”来改变这种行为，如果头节点增加了这个标识，意味着头节点将不被包括在返回的集合中(左开区间），如果尾节点增加了这个标识，意味着它将会被包括在返回的集合中（右闭区间) SortedMap接口这个接口所有的操作和属性都和SortedSet一致，因此这里就略过不讲 在JAVA的集合框架中，提供了TreeSet来实现SortedSet接口. 备注 具体的Sample代码可以参见这里 参考文档： 集合说明文档","categories":[],"tags":[]},{"title":"数据库事务的隔离级别","slug":"数据库/数据库事务的隔离级别","date":"2016-04-12T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/12/数据库/数据库事务的隔离级别/","link":"","permalink":"http://yoursite.com/2016/04/12/数据库/数据库事务的隔离级别/","excerpt":"","text":"数据库事务的隔离级别隔离级别 数据库事务的隔离级别分为四个： 未提交读， 提交读，重复读以及序列化，不同隔离级别能解决的问题以及不能解决的问题如下： 重复读会对读的范围加锁，也就是在第一次读操作开始的时候，事务会对它所读的范围进行加锁，其它的事务就不能对这个范围内的记录进行修改和删除操作，以此来保证它的重复读；但它不能保证选择范围外的记录不被修改或增加，因此无法避免幻读的情况(select) 幻读更多的是针对增加或修改范围外的记录的情况而言的 提交读的读锁是在读完之后就被立即释放，而写锁是在事务提交时释放，当事务A的读锁释放后，这部分数据就可能被其它事务修改，因此 它会导致不可重复读的问题； 重复读获取的也是读锁，但读锁直到事务结束才会被释放， 因此它能够解决重复读的问题，但是因为它没有范围锁，所以无法避免幻读的情况； 隔离级别和锁的联系封锁（Locking）封锁是实现并发控制的一个非常重要的技术。所谓封锁就是事务T在对某个数据对象例如表、记录等操作之前，先向系统发出请求，对其加锁。加锁后事务T就对该 数据对象有了一定的控制，在事务T释放它的锁之前，其它的事务不能更新此数据对象。 基本的封锁类型有两种：排它锁（Exclusive locks 简记为X锁）和共享锁（Share locks 简记为S锁）。 排它锁又称为写锁。若事务T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。这就保证了其它事务在T释放A上的锁之前不能再读取和修改A。 共享锁又称为读锁。若事务T对数据对象A加上S锁，则其它事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这就保证了其它事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。 封锁协议在 运用X锁和S锁这两种基本封锁，对数据对象加锁时，还需要约定一些规则，例如应何时申请X锁或S锁、持锁时间、何时释放等。我们称这些规则为封锁协议 （Locking Protocol）。对封锁方式规定不同的规则，就形成了各种不同的封锁协议。下面介绍三级封锁协议。三级封锁协议分别在不同程度上解决了丢失的修改、不 可重复读和读”脏”数据等不一致性问题，为并发操作的正确调度提供一定的保证。下面只给出三级封锁协议的定义，不再做过多探讨。 1级封锁协议：事务T在修改数据R之前必须先对其加X锁，直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。 1级封锁协议可防止丢失修改，并保证事务T是可恢复的。在1级封锁协议中，如果仅仅是读数据不对其进行修改，是不需要加锁的，所以它不能保证可重复读和不读”脏”数据。 2级封锁协议：1级封锁协议加上事务T在读取数据R之前必须先对其加S锁，读完后即可释放S锁。2级封锁协议除防止了丢失修改，还可进一步防止读”脏”数据。 一旦释放了S锁之后，其它的事务就可以对这部分数据进行修改，因此它无法避免重复读的问题。 3级封锁协议：1级封锁协议加上事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放。3级封锁协议除防止了丢失修改和不读’脏’数据外，还进一步防止了不可重复读。 参考文献 文献1 文献2 隔离级别和锁的联系 数据库并发的五个问题及四级封锁协议","categories":[],"tags":[]},{"title":"Redis","slug":"缓存/Redis","date":"2016-04-10T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/10/缓存/Redis/","link":"","permalink":"http://yoursite.com/2016/04/10/缓存/Redis/","excerpt":"","text":"Redis数据类型 字符串 列表 集合 散列 有序集合 说明: 具体的redis命令可以通过中文网站进行参考, 每个类型的命令均可以按照“CURD”的分组来帮助记忆 键空间事件通知 通知可分为两类 键空间通知：键空间中的键发生变化的时候会发送通知，通知内容为事件的名称 键事件通知：当某些特定的操作被执行时，会触发相应的键事件,通知内容为操作的键名称:123对 0 号数据库的键 mykey 执行 DEL 命令时， 系统将分发两条消息,相当于执行以下两个 PUBLISH 命令： PUBLISH __keyspace@0__:mykey del PUBLISH __keyevent@0__:del mykey 键事件的具体分类可参考键空间通知 可以结合psubscribe的功能实现订阅空间中所有键的通知或所有事件的通知 psubscribe \\_\\_key\\*\\_\\_:\\* 事务中的错误事务中的错误也可以分为两类 事务执行前的错误，例如语法错误、内存不足等错误 事务执行之后的错误，有些操作虽然语法正确，但是操作的内容可能出错，比如把一个列表命令用于操作一个zset类型的键等对于事务执行前的错误，客户端一般会记录这些错误，在事务执行的时候，拒绝执行并取消这个事务；而对于事务执行后发生的错误，redis只是简单地将它们忽略，不影响事务中其它命令的执行 订阅和发布Redis中通过subscribe、unsubscribe、psubscribe, punsubscribe，publish来实现相应的功能，具体的消息格式见消息格式. psubscribe支持glob风格的通配符： *： 0或任意多个字符 ?: 任意单个字符 […]: 方括号中的任意一个字符 [!…]: 不在方括号中的任意一个字符 主从备份集群部署持久化策略管道技术管道技术可以将多个命令批量地发送给服务器进行执行，它可以和事务进行结合使用但管道技术和事务是不一样的，管道技术是在传输层的一种优化，它将多个命令打包成一次命令进行传送，以此来减少网络的回路时间；而事务主要的功能是保证了事务中所有操作的原子性，并且保证这些命令在执行过程中不会有其它的命令被执行 其它 Redis事务中的watch/unwatch关键字，可以用来实现乐观锁（CAS)的功能 事务执行之后，不论事务的执行是成功还是失败，之前watch的内容都会被取消 参考文献 http://redis.io/topics/pipelining http://stackoverflow.com/questions/29327544/pipelining-vs-transaction-in-redis","categories":[],"tags":[]},{"title":"RabbitMQ的集群方案","slug":"消息队列/rabbitMQ/RabbitMQ的集群方案","date":"2016-04-10T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/10/消息队列/rabbitMQ/RabbitMQ的集群方案/","link":"","permalink":"http://yoursite.com/2016/04/10/消息队列/rabbitMQ/RabbitMQ的集群方案/","excerpt":"","text":"RabbitMQ的集群方案1. RMQ的集群组建RMQ集群可以动态的变化，集群中的每个节点可以先单独创建，然后再加入到集群中；也可以随时从集群中退出 在RMQ集群中，所有的数据和状态都是共享的，包括用户，虚拟主机，队列，exchange, 绑定以及运行时参数，这些对象在集群中基本上都是有备份的，除了queue，在默认配置下,queue只存在于被声明的那个节点中，如果需要对它进行镜像，需要参考“RabbitMQ的HA方案”进行配置 通过rabbitmqctl手工创建 通过config file列出所有的集群节点 通过rabbitmq-autocluster插件来组建 通过rabbitmq-clusterer插件来组建 2. 集群模式RMQ的节点可以有两种模式，一种是disk模式，一种是RAM模式。RAM节点具有更高的性能表现，但在处理持久化消息的时候，仍然会把消息持久化到硬盘上 3. RMQ集群的组建步骤 集群中各个节点（包括命令行工具）的通讯是通过cookie文件来实现的，各个节点必须拥有相同的cookie才可以进行通讯。Erlang虚拟机在启动时，会自动生成一个cookie文件，因此，最简单的方式就是让集群中的某个节点先生成cookie文件，然后将这个cookie文件复制给集群中的其它节点即可 在集群中的每个节点上分别启动rabbitmq-server， 此时可以通过rabbitmqctl来分别查看三个节点的集群状态，可以看到，它们现在还是三个独立运行的节点 假设要将A节点加入到B节点中，可以通过在A节点上执行以下的操作来实现: 123rabbitmqctl stop_apprabbitmqctl join_cluster B（这里是指B节点的名字)rabbitmqctl start_app 这时可以查看AB两个节点的集群状态 ，可以看到它们和之前的状态已经是不一样的；另外值得注意的是，将A节点加入到B节点中会导致A节点原来的数据都被重置 如果要将集群中的某个节点下线或者退出集群，可以通过在该节点上执行以下的操作即可： 123rabbitmqctl stop_apprabbitmqctl resetrabbitmqctl start_app 当整个集群下线时，最后下线的节点必须是最先上线的那个节点，否则其它的节点会等待30秒然后报错，如果想从集群中移除这个节点，可以通过设置forget_cluster_node 来完成 如果整个集群由于断电等原因同时下线，就会导致这样的一种情况，所有的节点都认为有其它的节点比自己晚下线，这时可以使用force_boot参数来强制重启集群 集群中所有的节点使用的erlang版本或者rabbitmq版本必须一致，但补丁版本可以不一样(x.y.z中的z) 参考文献 官方文档 参考文献","categories":[],"tags":[]},{"title":"RabbitMQ的基本概念","slug":"消息队列/rabbitMQ/RabbitMQ的基本概念","date":"2016-04-09T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/09/消息队列/rabbitMQ/RabbitMQ的基本概念/","link":"","permalink":"http://yoursite.com/2016/04/09/消息队列/rabbitMQ/RabbitMQ的基本概念/","excerpt":"","text":"RMQ的基本概念： 基本概念 生产者将消息投递给broker中的exchange模块，exchange根据“绑定”规则将这条消息投递给queue， 而queue再根据订阅的情况主动地push给消费者，或者由消费者主动向broker进行pull操作。 queue， exchange以及binding三者一起组成了broker的实体，这是个可编程的模型，应用开发者可以自行定义实体内容，并在需要的时候删除或修改实体的内容。 Exchange的类型 默认的exchange，它是directExchange的一种 ，但它的名字是空的，它有一个很重要的特性，每一个新创建的队列都会自动绑定到它这里，使用的routingKey和名称相同，这在一些简单的程序里很有用，因为它让程序从外部看上去就好像是直接将消息投递到queue中，虽然事实并不是这样。 direct exchange: 它是根据routingKey进行路由的一种exchange， 假如queueA使用routingKey = K绑定到这个exchange，那么所有routingKey = K的消息都将被投递给这个queueA. fanout exchange: 这种exchange将忽略消息中的routingKey, 它会直接将消息发送给和这个exchange绑定的所有queue，因此这种exchange特别适合于广播，比如游戏中的广播或者公告栏等功能 topic exchange: 多播，这种exchange分发消息的策略是根据消息中的routingKey和queue绑定到这个exchange时所使用的routing pattern进行匹配决定的。比如说，如果某个queueA使用stocks.update.*绑定到这种类型的exchange， 那么如果某个消息的routingKey为stocks.update.IBM，那么这条消息将会被投递给这个queueA header exchange: 这种类型的exchange不是根据routingKey来投递消息的，而是根据消息的头信息的匹配来进行投递，如果某个消息的头信息和queue在绑定到exchange时使用的头信息相同，那么消息就会被投递给这个queue，它可以认为是direct exchange的一种补充，因为direct exchange要求routingKey必须是字符串，而header exchange的头信息可以是数字，也可以是其它类型。header类型的exchange不支持通配符匹配。 队列队列的属性包括： 名字，持久化，排它性，自动删除，其它属性 队列的名称：长度不超过255个UTF-8的字符串，也可以使用空字符串，这时broker会自动创建名称，在后续需要使用队列名称的地方，继续传入空字符串即可，因为channel会记住broker为它创建的队列名称 队列的持久化： 持久化支持的队列在broker重启之后会被自动创建，但是持久化的队列并不能保证其中的消息也是持久化的，也就是说，如果broker重启了，那么持久化的队列会被自动创建，但是只能那些持久化的消息才会恢复，而没有设置持久化的消息则会丢失。 排它性是指当创建它的连接(connection)关闭时，RMQ将自动将这个队列删除，因此，当这个属性设置为true时，持久化和自动删除两个参数都将被忽略，此时持久化和自动删除都没有意义 持久化是指当broker重启的时候，这个消息队列是否能继续存活 自动删除是指当这个队列不需要时，将会被自动删除 绑定绑定是将消息从exchange路由到queue的规则，其本质是路由规则。在一些exchange中，可能需要用到routingKey(比如direct exchange, topic exchange, default exchange) 消费者消费者可以消费队列中的消息，有两种方式， 一种是broker主动推送(push)，一种是消费者主动拉取(pull)。每个消费者都有个tag，这个tag可以用在取消订阅的时候。 消费者的回执： 有两种方式，一种是broker在发送消息后自动获得ACK操作并将消息删除，一种是消费者显式地进行ACK确认操作，如果某个消息没有得到相应的ACK回执，那么broker将会择机再发送这条消息 消费者也可以通过拒绝某个消息，使得这条消息被重新放到队列中或者被丢弃。 消息消息通常包括两个部分： 属性和负载，属性部分可以认为是消息的元数据，它描述了消息的特性，比如是否需要持久化，routingKey, 有效期, 优先级等等信息，而负载则代表了消息的内容，broker不会对消息的负载进行任何的修改，它会直接透传这部分内容。 AMQP中的方法在AMQP协议， 方法即是操作，不同的操作按照组别被分成多个组，每个组实现相应的功能。比如， exchange.declare用于客户端向broker进行exchange的声明，如果broker声明并创建了相应的exchange之后，就会调用exchange.declare_ok来进行响应。 连接AMQP中的连接通常是长连接，它使用TCP来保证消息投递的可靠性，也可以使用TLS来进行加密，当客户端不需要再连接到broker时，必须正常地关闭相应的连接，而不是突然间中断连接 通道在RMQ中，通常情况下会需要很多的连接，如果每个连接都开启一个TCP连接的话，对于客户端来讲，系统的资源会承受很大的压力。因此可以通过多路复用的技术，在一个连接中保持多个通道，每个通道维持一个到broker的连接，通过共享连接的方式来减小占用系统的资源。通常情况下，各个通道的处理是通过单独开启相应的线程来处理的，换句话说，通道内的数据处理是线程独立的。","categories":[],"tags":[]},{"title":"RabbitMQ基础教程","slug":"消息队列/rabbitMQ/RabbitMQ基础教程","date":"2016-04-08T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/08/消息队列/rabbitMQ/RabbitMQ基础教程/","link":"","permalink":"http://yoursite.com/2016/04/08/消息队列/rabbitMQ/RabbitMQ基础教程/","excerpt":"","text":"RabbitMQ基础教程 生产者-消费者 生产者的流程：ConnectionFactory —&gt; Connection —&gt; Channel —&gt; ExchangeDeclare –&gt; QueueDeclare —&gt; BasicPublish 消费者的流程: ConnectionFactory –&gt; Connection –&gt; Channel –&gt; ExchangeDeclare –&gt; QueueDeclare –&gt; BasicConsume 注: 每个connection都是个TCP连接， 因此为了节省系统资源， 没必要为每个消费者都创建一个连接，但是可以为每个消费者都创建一个channel， 让这些channel共享这个连接，通过这种多路复用的技术，节省系统在连接上所耗费的资源 工作队列 当有多个消费者时，RMQ将会使用round-robin的方式进行分发(轮询分发) 如果需要设置消息的持久化属性，那么必须满足两个条件，一个是消息分发到的队列是持久化的，另一个则是消息本身必须是持久化的 消息确认回执在RMQ中，消息确认回执有两种方式，一种是自动回执(autoAck = true) ，在这种模式下，消息只要一到达队列，队列就自动返回相应的回执给broker， 还有一种是手动回执，队列可以选择发送回执的时机，可以是刚收到消息的时候，也可以是收到消息并处理完后再发送，这种情况下，如果忘记给broker发送回执，那么broker会再次发送这条消息 消息预获取(prefetch)prefetch是指消费者可以预获取的消息条数，prefetch设置的数值越高，消费者用于等待消息到达的时间就越短，因此就可以获得更高的吞吐值，当消费者的prefetch达到上限时，这个消费者将不会再收到broker发来的消息，直到它对之前的消息进行了ack操作之后。这个参数可以用来做负载均衡，比如，可以把消费者的prefetch的值设置为1，并且让每个消费者手工的发送消息回执，这样当某个消费者的处理任务很重时，它将不会再收到broker发来的消息，而那些处理任务很轻的消费者，就可以处理更多的消息，以此来达到负载均衡的目的。 rabbitmqctl的使用rabbitmqctl是用来管理rabbitmq的后台工具，提供了用户管理，连接管理，集群管理，虚拟主机管理 参考链接 参考文档 RMQ系列教程—网易 在线文档","categories":[],"tags":[]},{"title":"AMQP学习","slug":"消息队列/rabbitMQ/AMQP学习","date":"2016-04-07T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/07/消息队列/rabbitMQ/AMQP学习/","link":"","permalink":"http://yoursite.com/2016/04/07/消息队列/rabbitMQ/AMQP学习/","excerpt":"","text":"AMQP学习Topic Exchange的匹配 *: 匹配一个单词 #: 匹配零或多个单词 1e.g. *.stocks.# 能够匹配usd.stocks以及eur.stocks.db，但不能匹配stocks.nasdaq header exchange的匹配 这种类型的exchange在匹配时会忽略routingKey, 它会使用消息的头信息来进行匹配 在头信息中，x-match是个特殊的头,它的值决定了其它头信息的匹配算法，它可以有两种取值， all: 意味着其它的头信息必须全部匹配(and) any: 意味着只要任意头信息匹配了就可以(or) 头信息中某个属性匹配的判定规则： 在绑定的时候，这个属性没有设置值， 在消息的头信息中存在这个属性 在绑定的时候，这个属性设定了相应的值，在消息的头消息中存在这个属性，并且这个属性的值和绑定值相等 所有以x-（除了x-match）开始的头信息是保留字段，都将会被忽略 注意： headers类型的exchange中的头信息不支持通配符！ vhost虚拟主机在RMQ中起到了命名空间的作用，它将不同的用户进行隔离，因此不同的应用可以使用在同一个broker中的不同虚拟主机","categories":[],"tags":[]},{"title":"activeMQ","slug":"消息队列/activeMQ/activeMQ","date":"2016-04-04T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/04/消息队列/activeMQ/activeMQ/","link":"","permalink":"http://yoursite.com/2016/04/04/消息队列/activeMQ/activeMQ/","excerpt":"","text":"AcitveMQ 多路复用: 每个连接可以创建多个会话，只要保证每个会话之间是线程独立的即可，多个会话共享一个连接， 这样可以节省连接的数量 广播: AMQ自带的根据topic进行广播的机制可以相应的功能 监听消息: 消息监听器能够实现异步的消费，同步的消费者通过receive方法来等待消息的到达，而异步的消费者通过注册监听器，当消息到达的时候进行处理，而不需要进行监听 持久化: 持久化分为两个部分，一个是消息的持久化（persistent)，一个是消费者的持久化(durable) 关于persistent和durable语义的说明和比较可以参考： 文章1 文章2 理解: 消息的persistent属性决定了这条消息在broker重启后还否继续存活，而消费者的durable属性决定了当它能否收到处于inactive状态下发送的消息 对于队列而言，消费者的持久化只有一种，也就是durable， 意思是队列的消费者总能收到所有的消息，不管是在它处于active还是inactive状态下的消息; 而对于主题(topic)而言，如果消费者是durable的，那么它就能收到它处于inactive状态下的消息，如果是non-durable， 那么它就只能收到上线后广播的消息，而之前的消息就收不到 消息默认情况下都是persistent状态的，可以通过生产者设置deliveryMode来设置， 也可以在发送的时候来设置，但是不能通过设置消息本身的deliveryMode来实现 主题广播的消费者默认情况下都是non-durable的，可以通过createDurableSubcriber来创建durable的消费者 重发机制： 重发的条件请见： 重发条件 重发属性 查看当前队列里的状态: 只能对队列里的消息进行监听， 通过创建queueBrowser对象，获取到迭代对象，然后就可以遍历队列中的消息，在创建浏览对象的时候，可以设置相应的选择器 massageSelector的作用: 根据内容来进行消息路由，通过给message设置属性，同时给消费者设置选择器，如果两者匹配，则进行路由 Consumer, noLocal: 如果noLocal设置为true, 并且destination为主题模式，那么由同一个连接（注意这里是连接，不是会话）发布的消息不会被路由到这个消费者 Request-Response模式: 感觉这种模式的运用和MOM的设计理念有冲突，因为MOM要实现的目标有两个，一个是应用间的解耦，一个是异步请求，如果做成请求-应答模式，和这两个都有所违背。应答-响应模式通常不能在一个队列中完成，可能会造成自己生产的数据被自己消费的情况， 不过可以使用消息选择器来进行筛选。 durable consumer： 对于队列而言，它的消费者都是durable的，而对于主题广播来讲，可以通过createConsumer或者createDurableSubscriber来分别创建non-durable和durable的消费者durable消费者的作用是能够接收下线期间的广播消息，而non-durable则不行另外，在activeMQ中，创建durable消费者时，必须指定连接的名字和订阅者的名称，订阅者的标识由连接名字和订阅者标识唯一确定 事务机制: 在创建会话的时候，可以选择事务性会话或者是非事务性会话。 过期: activeMQ中使用DLQ(Dead Letter Queue) 来处理过期或者失败的消息，当一个消息被重发超过六次的时候，就会给broker发送poison ack， 这个信号被认为是poison pill， 然后broker就会把这个消息扔到DLQ中，默认情况下，DLQ只会保存持久化的消息，而不会保存非持久化的消息，但是可以通过配置来修改。 消息确认模式：具体的说明可以参见： 消息确认模式 auto_acknowledge: 自动确认，即当消息到达消费者的时候，会话自动对消息进行确认 client_acknowlege: 手动确认，客户端需要显式地对消息进行确认，注意，这里的确认会对之前所有的消息进行确认，而不仅仅是当前这条消息 dups_ok_acknowledge: 这也是一种自动确认模式，只不过它会存在一定的延迟，如果在这期间provider宕机了，可能会造成某些消息重复发送，因此这种确认模式适用于那些可以接受重复发送消息的场景（duplication is ok) session_acknowleged: 这种模式下，消息的确认是通过事务的提交和回滚来进行的，在事务提交时自动进行消息的确认；在事务回滚时立即重新发送 123456注意： 当会话是事务性会话时(transacted = true)，消息确认模式将被自动设置为session_acknowlege，即事务型确认模式，这点在文档中没有很好的说明，但从源码中可以看到&lt;br&gt;在以下两种情况下，在会话结束前，消息都不会被重新发送，消息的redelivery状态仍然为false，从broker的角度来看，这条消息处于Inflight的状态， 只有当会话结束后，如果消息还未被确认，那么这条消息的redelivery才会被标识为true, 意味着这条消息需要被重新发送。 * 在事务型会话中，没有进行commit也没有进行rollback操作 * 在非事务型会话中，且消息确认模式为client_acknowlege，并且没有对消息进行确认 prefetch: 负载均衡 集群 通配符参阅http://activemq.apache.org/wildcards.html . ： 点号用于分隔路径 * ：冒号用于匹配路径中的一节 > ： 大于号用于匹配任意节的路径 与spring的集成 桥接 自定义分发策略 延迟和定时投递 消费者的特性具体的文档说明参见： 特性说明 异步分发： 默认情况下，AMQ采用的是异步分发的策略，这种策略在有低速消费者的情况下十分有用，因为它不会造成生产者的阻塞；如果想要追求更高的吞吐量，并且出现低速消费者的可能性是比较低的，也可以将broker的分发策略修改成同步分发，从而避免在增加新的队列时所需要的同步以及上下文切换的时间成本 。 设置自启动目标(destination)， 可以通过XML配置文件来进行配置，需要AMQ的版本&gt;=4.1 删除不活跃的目标，当某个目标为空的时间超过配置文件预设的时间长度时，broker将自动将这个目标进行删除。 schedulePeriodForDestinationPurge： broker检查不活跃目标的间隔时间 gcInactiveDestinations： 是否删除不活跃目标的标识 inactiveTimoutBeforeGC： 判断目标是否为不活跃目标的时间长度 优先级： 当某个队列的消费者中有高优先级的消费者时，那么broker会优先将消息分发给高优先级的消费者，直到达到它的prefetch的上限时，才会分发给低优先级的消费者(要通过目标属性进行设置） 持久化的主题订阅者： 当某个主题的订阅者当中有持久化需求时，broker必须保存所有在它们离线过程中发来的消息，如果这个订阅者迟迟没有上线，就会导致broker中存储的消息越来越多，最终超过上限值或者导致系统性能下降，因此，必须有一定的机制能够避免出现这种情况 避免囤积大量的消息： 给每个消息设置一定的有效期，过期后消息自动被删除 超过一定时间长度没有上线的订阅者将会被自动删除，通过设置broker的属性即可实现 消息组: 可以通过设置消息JMSXGroup属性来设置该消息的所属组，对于同一个消息组的消息，总是会发送给同一个消费者进行处理，只要这个消费者处于活跃状态，但是如果这个消费者断线了，那么消息将会被另一个消费者消费。通过消息组的机制，可以很方便地实现负载均衡，错误转移以及顺序处理等功能。 AMQ特性的说明 ： AMQ的特性 虚拟目标和组合目标 不同的持久化策略： 文件， 数据库等","categories":[],"tags":[]},{"title":"First Post","slug":"first-post","date":"2016-04-01T08:00:00.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/04/01/first-post/","link":"","permalink":"http://yoursite.com/2016/04/01/first-post/","excerpt":"","text":"”Congratulations!“","categories":[],"tags":[]},{"title":"Java_Concurrency_In_Practise笔记(3) - Composing objects","slug":"多线程/Java_Concurrency_In_Practise笔记(3) - Composing objects","date":"2016-03-24T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/03/24/多线程/Java_Concurrency_In_Practise笔记(3) - Composing objects/","link":"","permalink":"http://yoursite.com/2016/03/24/多线程/Java_Concurrency_In_Practise笔记(3) - Composing objects/","excerpt":"","text":"Java_Concurrency_In_Practise笔记(3) - Composing objects 设计线程安全的类 明确类的状态 明确类状态之间的限制 明确访问类状态时 每个类的所有成员变量组成了这个类的状态，这个类的所有状态组成了相应的状态空间，在状态空间中，如果存在某些无效的状态，那么就要求类有一定的封装来隐藏这些状态空间，否则外部的代码有可能使这个类对象牌处于无效的状态中；另外，如果几个成员变量间有某些不变量，那么对于这些成员变量的操作就必须被原子化，否则可能会破坏这种隐藏的不变量。例如，如果在某个类中一个自然数以及这个自然数的因子，那么隐含的不变量就是这个自然数必须和这些因子匹配，那么针对这个自然数或者因子的变量的操作就必须是原子化的。 类状态变量之间的不变量以及方法的后置条件（比如操作依赖于当前值等）限制了类状态的转移以及有效状态的范围。同样地，方法的前置条件也增加了某些限制。比如，无法从某个空队列中删除元素。在单线程程序中，如果无法满足程序的某些前置条件，那么只要简单地返回错误就可以了，但是在多线程环境下，线程可以等待这些前置条件被满足（其它线程的某些操作使前置条件成立），因此，在多线程编程中提供了wait和notify关键字来实现等待和通知的功能，但是，在使用这两个关键字时，请优先考虑使用已有的框架。比如，阻塞队列，信息量等 实例绑定是最简单地实现线程安全类的方法，具体的做法是使用封装，将一个非线程安全的对象封装到包装对象中，并通过包装对象来控制非线程安全对象的访问，比如HashMap不是个线程安全的集合类，但可以使用平台提供的Collections.synchronizedMap来封装它，从而得到线程安全的hashMap（具体是使用了装饰器模式），只要保证对hashMap对象的访问都是通过封装对象来完成的，那么线程安全就是可以保证的。","categories":[],"tags":[]},{"title":"Java_Concurrency_In_Practise笔记(2)-Sharing Objects","slug":"多线程/Java_Concurrency_In_Practise笔记(2)-Sharing Objects","date":"2016-03-23T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/03/23/多线程/Java_Concurrency_In_Practise笔记(2)-Sharing Objects/","link":"","permalink":"http://yoursite.com/2016/03/23/多线程/Java_Concurrency_In_Practise笔记(2)-Sharing Objects/","excerpt":"","text":"Java_Concurrency_In_Practise笔记(2)-Sharing Objects 锁机制有两方面的作用， 一个是通过定义临界区，提供原子化操作；另一个则是提供了可见性保证。在单线程中，如果对某个变量进行赋值，随后马上进行读取，并且在上次写操作之后没有再进行写操作，那么可以预见的是，读取到的值就是上次赋给它的值，但是在多线程编程中，这种可见性是不能保证的，除非使用了锁，产生这种情况的原因主要是由于指令的重排序。 在JAVA中，对没有声明成volatile的64位数值型变量来讲，JVM允许将对它们的赋值操作转化成两次32位的读写操作，因此，如果需要保证double或者long类型变量的线程安全，就必须把它们声明成volatile或者使用锁机制 volatile类型的变量提供了可见性保证，所有对它的写操作都立即对其它线程可见。如果线程A对某个volatile变量进行赋值，紧接着线程B对这个变量进行读取，那么这个变量的值以及在为这个变量赋值前的所有操作，对线程B都是可见的，可以认为，volatile变量的写操作与随后对它的读操作之间，有happen-before的关系。volatile类型使用起来比锁要方便，但有它的局限性（不提供锁机制），因此通常被用来当作标志变量进行使用。在java中，锁机制同时提供了原子化和可见性保证，但volatile只提供了可见性保证。 对象的发布，比较重要的就一点，不要在构造函数中发布this指针，因为这可能会导致程序获取到不完整的对象。 在多线程编程中，有一种方式能够很好地避免线程安全问题，即每个链接或者每个请求的处理被限制在一个线程中，即线程绑定，也就是说，在单个请求的生命周期中，只会用到一个线程。这种模式在数据库的连接池以及SWING编程中经常被用到。这种方法最常见的是使用ThreadLocal类型的变量，声明为threadLocal类型的变量后，对于每个线程而言，会保留一份该变量的副本，彼此之间不共享数据ThreadLocal和synchronized提供了两种不同的方法来解决多线程的数据安全问题，synchronized是通过锁机制，保证同一时间只有一个线程能获得相应的对象锁，从而实现数据在线程间的共享，而threadlocal恰好相反，它为每个线程保留了一份数据的副本，彼此独立，也就是说并不存在线程间的数据共享的问题，它通过数据的隔离来解决多线程的数据冲突问题 不可变对象 解决多线程编程中数据安全问题的另一个思路。因为几乎所有的多线程数据安全问题，总会涉及到多个线程同时对某个对象进行读写操作，尤其是写操作，如果一个对象在构造函数之后，它的状态就不会发生变化，那么就不会存在数据的冲突问题。另外，把一个类的所有变量都声明成final，并不能保证这个类就是个不可变对象，比如，当某个变量是个引用类型时就无法保证，如果要声明一个类成不可变对象，那么它必须满足以下几个条件： 所有的成员变量都声明成private final， private是为了防止从外部访问修改，final是为了防止从内部进行修改 不提供任何set方法 对于引用类型，在构造函数时要使用深拷贝技术；同样，当向外部返回引用类型的成员变量时，也应该使用深拷贝技术 将类声明成final, 以防止子类继承后重写某些方法 参考资料 http://www.cnblogs.com/dolphin0520/p/3920407.html","categories":[],"tags":[]},{"title":"Spring security的原理","slug":"安全/Spring security的原理","date":"2016-03-22T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/03/22/安全/Spring security的原理/","link":"","permalink":"http://yoursite.com/2016/03/22/安全/Spring security的原理/","excerpt":"","text":"Spring security的原理在使用SS的时候，需要在web.xml里定义DelegatingFilterProxy，这个对象的作用是将托管在spring容器的对象当成filter来使用，它是个代理，所有对这个代理的调用最终都会调用它所代理的对象; 在SS中，delegatingFilterProxy代理的对象就是容器中和filter-name名称一样的那个对象，默认为springSecurityFilterChain, 这个对象的类型是FilterChainProxy，是一堆过滤器的组合 由此可以看出，SS框架通过DelegatingFilterProxy这个对象引入了整个过滤器链，认证和授权过程中需要用到的所有东西都由这个过滤器链完成，并且，这个过滤器链也是可以自定义的 当访问系统中某个受保护的资源时，会依次通过这个过滤器链，从而引发整个权限操作。 1. 认证认证操作会在两种情况下被触发，一种是直接进入到认证页面，一种是访问受保护的资源但用户本身没有被认证的时候。认证的过程大体上有以下几个步骤： AuthenticationManager —&gt; ProviderManager —&gt; AuthenticationProvider —&gt; DaoAuthenticationProvider(UserDetailsService) —&gt; UserDetailsService —&gt; UserDetails 2. 授权首先通过过滤器链进入到FilterSecurityInterceptor, 在FilterSecurityInterceptor中的整个工作过程可以参考: 这里 过滤器链中默认的过滤器有：这里， 它们的详细说明如下： 另外， 在SS的过滤器链中，过滤器之间的顺序也是很关键的，如下如述： The order that filters are defined in the chain is very important. Irrespective of which filters you are actually using, the order should be as follows: ChannelProcessingFilter, because it might need to redirect to a different protocol SecurityContextPersistenceFilter, so a SecurityContext can be set up in the SecurityContextHolder at the beginning of a web request, and any changes to the SecurityContextcan be copied to the HttpSession when the web request ends (ready for use with the next web request) ConcurrentSessionFilter, because it uses the SecurityContextHolder functionality but needs to update the SessionRegistry to reflect ongoing requests from the principal Authentication processing mechanisms - UsernamePasswordAuthenticationFilter, CasAuthenticationFilter, BasicAuthenticationFilter etc - so that the SecurityContextHolder can be modified to contain a valid Authentication request token The SecurityContextHolderAwareRequestFilter, if you are using it to install a Spring Security aware HttpServletRequestWrapper into your servlet container RememberMeAuthenticationFilter, so that if no earlier authentication processing mechanism updated the SecurityContextHolder, and the request presents a cookie that enables remember-me services to take place, a suitable remembered Authentication object will be put there AnonymousAuthenticationFilter, so that if no earlier authentication processing mechanism updated the SecurityContextHolder, an anonymous Authentication object will be put there ExceptionTranslationFilter, to catch any Spring Security exceptions so that either an HTTP error response can be returned or an appropriate AuthenticationEntryPoint can be launched FilterSecurityInterceptor, to protect web URIs and raise exceptions when access is denied 3. 命名空间的配置 http: 配置URL级别的权限信息 global-method-security: 配置方法级别的权限信息 authentication-manager: 配置认证信息 4. 参考资料 https://docs.spring.io/spring-security/site/docs/3.0.x/reference/el-access.html http://docs.spring.io/spring-security/site/docs/3.0.x/reference/appendix-namespace.html 使用Spring Security实现Resource Based Access Control的方法 URL级别的权限控制是通过标签来控制的，可以通过自定义voter来实现，注意要将http元素的use-expression设置为false(默认为true)，否则系统将使用默认的表达式解析，导致解析失败 方法级别的权限控制通过global-method-security来控制， 需要通过自定义PermissonEvaluator来重新实现hasPermission方法，并将它设置DefaultMethodSecurityExpressionHandler的属性，然后设置到global-method-security中，以此来实现自定义的权限管理 在平台中引入权限控制的时候，需要先定义平台的资源以及能对资源执行的操作，也可以定义一组角色，然后逐一确定每个角色对各个资源的权限项，并将它配置到DB中或者代码中","categories":[],"tags":[]},{"title":"Java_Concurrency_In_Practise笔记(1)-Thread safety","slug":"多线程/Java_Concurrency_In_Practise笔记(1)-Thread safety","date":"2016-03-22T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/03/22/多线程/Java_Concurrency_In_Practise笔记(1)-Thread safety/","link":"","permalink":"http://yoursite.com/2016/03/22/多线程/Java_Concurrency_In_Practise笔记(1)-Thread safety/","excerpt":"","text":"Java_Concurrency_In_Practise笔记(1)-Thread safety使用多线程编程时会遇到的问题 数据一致性问题: nothing bad ever happen Liveness Failure: something good eventually happens, deadlock, starvation, livelock 性能问题：多线程时，CPU需要在不同的上下文之间进行切换，线程间的同步操作等也会耗费一些CPU时间 数据一致性编写线程安全的代码的本质是：管理好对那些可共享，可变状态的读写操作 任何情况下，如果多个线程会同时对某个状态访问，并且其中至少一个线程会对状态进行修改，那么它们就必须通过某些机制来保证数据的一致性，这也是判断某个对象是否是线程安全的依据 1. Race condition出现数据一致性的情况基本上都具备了上述的两个条件：同时有多个线程对对象的状态进行访问，并且其中至少一个线程会对状态进行修改 竞争条件指的是两个或多个线程读写某些共享数据，而最后的结果取决于线程的精确执行时序，这种情况在多线程中非常常见。 check-and-act：执行的操作取决于某个观察到的先决条件，但当开始act(act并不一定是写操作，也可以是读操作）的时候，之前观察到的先决条件已经失效 123e.g. 检查到文件系统中没有文件X，于是开始创建X，但是当开始创建X时，另一个线程已经在文件系统中创建了Xe.g. lazy initialization: 单例模式 read-modify-write: 由于这种操作的结果依赖于之前的操作，当写操作开始的时候，可能之前读取到的状态值已经发生变化 1e.g. i++ 2. 解决办法解决数据的一致性问题也可以通过两个方面来进行：控制同一时间访问状态的线程数量，或者让状态变为只读变量，甚至可以将类实现为无状态类，无状态类天生就是线程安全的 在JAVA中，同步的机制包括：synchronized， volatile，原子化变量，显式锁（这些方法本质上都是限制了同一时间只能有一个线程能操作对象的状态） 2.1 原子化变量对原子化变量的所有操作都是原子化的，从内存的角度来看，基本上同操作volatile变量是一样的（对volatile变量的写操作与随后对该变量的读操作之间有happen-before关系），因此这些操作都是线程安全的 2.2 synchronizedsynchronized由两个部分组成，一个是获取到的锁对象，另一个是锁的代码块 synchronized方法是synchronized代码块的一种简略表达，它包含方法中所有的代码块，锁的对象是调用该方法的那个对象；如果是对static方法加synchronized关键字，那么锁的对象的是该方法所在的类 JAVA中的每个对象都有内置锁，当线程进入synchronized区域时，自动得到某个对象（synchronized后的对象）的内置锁，并在退出synchronized代码块时自动释放该对象锁，不管这种退出是正常的执行结束还是由于代码出现异常 2.3 重入锁当一个线程试图获取某个锁时，如果这个锁已经被其它的线程所占有，那么该线程会阻塞，但如果拥有这个锁的线程就是它本身，那么它可以重复地获取锁，这种机制被称为是重入锁，这种重入锁是通过记录拥有锁的线程对象以及获取锁的次数来实现的。 2.4 利用锁实现状态的统一这里的状态并不一定是指某个变量，也可能是几个变量组合成的状态，在读写这些状态的时候，需要通过锁机制（不管是synchronized关键字还是Lock机制）保证同一时间只有一个线程在对它们进行操作 另外，对某个类中所有的方法加上synchronized关键字并不能保证这个类的使用中就是线程安全的，如 123if(!a.containsElement(b))&#123; a.addElement(b);&#125; 这是个典型的check-and-act代码；在这段代码中，即使这两个方法都是原子操作，也不能保证这两个操作是原子的。 Liveness","categories":[],"tags":[]},{"title":"IO & NIO & NIO2","slug":"IO/java基础/IO & NIO & NIO2","date":"2016-02-04T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/02/04/IO/java基础/IO & NIO & NIO2/","link":"","permalink":"http://yoursite.com/2016/02/04/IO/java基础/IO & NIO & NIO2/","excerpt":"","text":"IO &amp; NIO &amp; NIO2IO Inputstream/OutputStream: 流对象，用于字节读写 Reader/Writer: 用于字符读写 DataInput/DataOutput: 用于二进制读写 ObjectInput/ObjectOutput: 用于对象读写 Scanner/Formatter: 用于读取格式化的字符 NIO Path: 从语法上对系统中的文件和文件夹的抽象 Files: 封装对文件的操作，比如对文件的增删改查，拷贝，重命名，读取文件属性等操作 Paths: 获取path对象的工具类 FileAttribute: 文件属性 WatchService: 监听文件/文件夹增删改查 FileSystem/FileStore: 代表文件系统和磁盘 NIO2 ByteBuffer: 字节缓冲区 Channel: 通道，用于从缓冲区读取数据或者向缓冲区写入数据 Selector: 多路复用选择器 练习代码 git@github.com:Essviv/nio.git","categories":[],"tags":[]},{"title":"memcached","slug":"doc/memcached","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/memcached/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/memcached/","excerpt":"","text":"#memcached ##commandsset, add, replace, append, prepend, cas, get, gets, flush_all, delete, incr, decr, touch ##References官方文档 命令说明 turtorialPoint","categories":[],"tags":[]},{"title":"useful_website","slug":"doc/useful_website","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/useful_website/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/useful_website/","excerpt":"","text":"#Some useful websites www.owasp.org: open web application security project.","categories":[],"tags":[]},{"title":"常见的线程模型","slug":"多线程/常见的线程模型","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/多线程/常见的线程模型/","link":"","permalink":"http://yoursite.com/2016/01/25/多线程/常见的线程模型/","excerpt":"","text":"常见的线程模型参考文献 http://blog.csdn.net/solstice/article/details/5307710","categories":[],"tags":[]},{"title":"Spring resource","slug":"安全/Spring resource","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/安全/Spring resource/","link":"","permalink":"http://yoursite.com/2016/01/25/安全/Spring resource/","excerpt":"","text":"Spring Resource##1. URL与URI的区别 URIs identify and URLs locate. 参考1 参考2 URI是个纯粹的句法结构，用于指定标识Web资源的字符串的各个不同部分。URL是URI的一个特例，它包含了定位Web资源的足够信息。其他URI，比如： mailto: cay@horstman.com 则不属于定位符，因为根据该标识符无法定位任何资源。像这样的URI我们称之为URN(统一资源名称)。 在Java类库中，URI类不包含任何访问资源的方法，它唯一的作用就是解析。相反的是，URL类可以打开一个到达资源的流。因此URL类只能作用于那些Java类库知道该如何处理的模式，例如：http：，https：，ftp:，本地文件系统(file:)，和Jar文件(jar:)。 2. Resource接口的具体实现 URLResource: 用于访问文件系统(file)、http文件(http)以及ftp文件(ftp) ClassPathResource: 用于加载classpath中的文件 FileSystemResource: 用于访问文件系统和url文件 ServletContenxtResource: 访问相对当前servletContext根路径的文件 3. ResourceLoader和ResourceLoaderAware接口4. 加载applicationContext时指定resource的路径的注意事项参考文献链接","categories":[],"tags":[]},{"title":"java_collection","slug":"doc/java_collection","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/java_collection/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/java_collection/","excerpt":"","text":"#Java collection frameworkThe core collection interfaces are the foundation of the Java Collections Framework. The Java Collections Framework hierarchy consists of two distinct interface trees: The first tree starts with the Collection interface, which provides for the basic functionality used by all collections, such as add and remove methods. Its subinterfaces — Set, List, and Queue — provide for more specialized collections. The Set interface does not allow duplicate elements. This can be useful for storing collections such as a deck of cards or student records. The Set interface has a subinterface, SortedSet, that provides for ordering of elements in the set. The List interface provides for an ordered collection, for situations in which you need precise control over where each element is inserted. You can retrieve elements from a List by their exact position. The Queue interface enables additional insertion, extraction, and inspection operations. Elements in a Queue are typically ordered in on a FIFO basis. The Deque interface enables insertion, deletion, and inspection operations at both the ends. Elements in a Deque can be used in both LIFO and FIFO. The second tree starts with the Map interface, which maps keys and values similar to a Hashtable. Map’s subinterface, SortedMap, maintains its key-value pairs in ascending order or in an order specified by a Comparator. These interfaces allow collections to be manipulated independently of the details of their representation. ##Collection ###List ArrayList: 内部使用动态数组来实现，当调用add/remove等方法时，会拷贝数组 LinkedList: 内部使用双向链表实现，当调用set/get等方法时，需要遍历 ###Set HashSet: 内部使用hashMap来实现, 利用其key值不能重复的特点 LinkedHashSet: 内部使用LinkedHashMap来实现，它的特点是可以按插入顺序遍历 TreeSet: 内部使用TreeMap来实现，它保证set处于排序状态 SortedSet: 集合内部的元素可以按照一定的顺序进行排序，内部通常借助sortedMap实现 可以看出，set的实现大多依赖于Map, 不同的set实现主要是由于内部使用的map类型不同 ###Queue BlockingQueue: 阻塞式队列，包括ArrayBlockingQueue和LinkedBlockingQueue Deque: 双向队列，可以用来实现栈, ArrayDeque, LinkedList BlockingDeque: 阻塞式双向队列, LinkedBlockingDeque ##Map HashMap: 使用key-value的值进行存储， 这是非同步的(Hashtable是同步的) LinkedHashMap: 使用链表的方式进行存储，它可以按插入的顺序进行输出 TreeMap: 它可以按照指定的比较器进行排序输出 SortedMap: 按照一定的比较器对结果进行输出，TreeMap是它的一种实现 ConcurrentMap: map的多线程实现，它将map分成多个（默认是16个）hashtable，在每个hashtable中可同时进行操作 ###Arrays asList: 将数组转化成List对象 binarySearch: 二分查找 sort: 排序 fill: 填充 copyOf: 拷贝 ###Collections Sorting shuffling routing data searching composition","categories":[],"tags":[]},{"title":"shiro学习笔记","slug":"安全/shiro学习笔记","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/安全/shiro学习笔记/","link":"","permalink":"http://yoursite.com/2016/01/25/安全/shiro学习笔记/","excerpt":"","text":"Shiro##Terminology参考1 参考2注意realm, principal, credential的理解 ##Architecture ##SecurityManager ###GraphAuthenticator, Authorizator, SessionManagement, SessionDAO, CacheManagement ###Programmic configurationsetter/getter method of securityManager ###INI configurationload file from file, url and classpath with prefix “file”, “url” and “classpath”, respectively. ###AuthenticatorAuthenticationToken, AuthenticationException, RememberMe, AuthencationStrategy, Realm ###Authorization RBAC: implicit or explicit Permission-based: Permission, String Annotation-based: Requires AOP support. @RequiresAuthentication @RequiesGuest @RequirePermissions @RequiresRoles @RequiresUser JSP-based Global permission resolver: convert string to implicit permission RolePermissionResolver: convert role to implicit permission ###Permission syntax Simple usage queryPrinter printPrinter Multipart: domain: action1, action2 printer:query printer:print printer: query, print printer:* instance-level access control: domain, action, instance being acted upon printer:query:lp7200 printer:print:canon printer:*:lp7200 print:query, print: canon missing part: missing parts imply that the user has access to all values corresponding to that part. printer:print &lt;==&gt; printer:print:* printer &lt;==&gt; printer:*:* BUT printer:lp7200 IS NOT EQUIVALENT TO printer:*:lp7200 ###Realm supports getAuthenticationInfo GetAuthenticationInfo的实现逻辑: Inspects the token for the identifying principal (account identifying information) Based on the principal, looks up corresponding account data in the data source Ensures that the token’s supplied credentials matches those stored in the data store If the credentials match, an AuthenticationInfo instance is returned that encapsulates the account data in a format Shiro understands If the credentials DO NOT match, an AuthenticationException is thrown CredentialMatcher SaltedAuthenticationInfo ###Session and SessionManager SessionListener: listen to important session events SessionManager, SessionDAO: session store CacheManager, Cache, Session SessionValidationScheduler ##Web support ###Configuration org.apache.shiro.web.env.EnvironmentLoaderListener &lt;filter&gt; &lt;filter-name&gt;ShiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.shiro.web.servlet.ShiroFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;ShiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;dispatcher&gt;FORWARD&lt;/dispatcher&gt; &lt;dispatcher&gt;INCLUDE&lt;/dispatcher&gt; &lt;dispatcher&gt;ERROR&lt;/dispatcher&gt; &lt;/filter-mapping&gt; ###INI configuration[main], [users], [roles], [urls] [urls] URL_Ant_Path_Expression = Path_Specific_Filter_Chain filter_chain: filter1[optional_config1], filter2[optional_config2] This line below states that &quot;Any request to my application&apos;s path of /account or any of it&apos;s sub paths (/account/foo, /account/bar/baz, etc) will trigger the &apos;ssl, authc&apos; filter chain&quot;. /account/** = ssl, authc ###Integration with SpringRef ##CryptographyHashService, PasswordService, CredentialsMatcher ##权限注解 @ RequiresAuthentication可以用户类/属性/方法，用于表明当前用户需是经过认证的用户。 @ RequiresGuest表明该用户需为”guest”用户 @ RequiresPermissions当前用户需拥有制定权限 @RequiresRoles当前用户需拥有制定角色 @RequiresUser当前用户需为已认证用户或已记住用户 ###过滤器ShiroFilterFactoryBean, filters, filterChainDefinition, FilterChainManager ##网络资源 跟着开源学shiro: 实例教程 Shiro官方: 官方教程， 比较权威 APIdocs 注： shiro的源码比较简洁，架构设计清晰，用到了很多设计模式，可以用来作为源码学习的材料","categories":[],"tags":[]},{"title":"hibernate","slug":"doc/hibernate","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/hibernate/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/hibernate/","excerpt":"","text":"[TOC] #Hibernate ##OverviewHibernate在应用程序和数据库之间增加了一层，用于管理POJO与DB之间的映射关系, 如下图所示 ##Bootstrap progress ###Hibernate native bootstrap ServiceRegistryBuilder –&gt; ServiceRegistry –&gt; MetaSources –&gt; MetadataBuilder –&gt; Metadata –&gt; SessionFactoryBuilder –&gt; SessionFactory –&gt; Session –&gt; Transaction ——&gt; transaction save/commit The native bootstrapping API is quite flexible, but in most cases it makes the most sense to think of it as a 3 step process: Build the StandardServiceRegistry Build the Metadata Use those 2 things to build the SessionFactory ###JPA-compliant bootstrap container-bootstrapping For compliant container-bootstrapping, the container will build an EntityManagerFactory for each persistent-unit defined in the deployment’s META-INF/persistence.xml and make that available to the application for injection via the javax.persistence.PersistenceUnit annotation or via JNDI lookup. application-bootstrapping For compliant application-bootstrapping, rather than the container building the EntityManagerFactory for the application, the application builds the EntityManagerFactory itself using the javax.persistence.Persistence bootstrap class. The application creates an entity manager factory by calling the createEntityManagerFactory method. Persistence contextEntity states transient - the entity has just been instantiated and is not associated with a persistence context. It has no persistent transient - the entity has just been instantiated and is not associated with a persistence context. It has no persistent representation in the database and typically no identifier value has been assigned. managed, or persistent - the entity has an associated identifier and is associated with a persistence context. It may or may not physically exist in the database yet. detached - the entity has an associated identifier, but is no longer associated with a persistence context (usually because the persistence context was closed or the instance was evicted from the context) removed - the entity has an associated identifier and is associated with a persistence context, however it is scheduled for removal from the database. ###Change states save/persist delete/remove getReference, load refresh(database –&gt; context) flush saveOrUpdate merge ##Database Access ###Dialect Although SQL is relatively standardized, each database vendor uses a subset and superset of ANSI SQL defined syntax. This is referred to as the database’s dialect. ##锁机制 ###乐观锁 @Version int, or Integer short, or Short long, or Long java.sql.Timestamp @OptimisticLocking NONE VERSION(default) DIRTY ALL ###悲观锁通过JDBC的锁机制来实现，用户只需要指定锁的级别即可 ##拦截器与事件 ###拦截器Interceptor: 可以在session域，也可以在sessionFactory域，不过在sessionFactory域的拦截器需要考虑线程安全问题 ###事件所有定义的事件都有相应的监听器，业务层通过实现这些监听器接口来实现监听的功能，注意监听器的实现必须是无状态 ###回调暂时没看明白…. ##HQL ###select select_statement :: = [select_clause] from_clause [where_clause] [groupby_clause] [having_clause] [orderby_clause] e.g. from User ###update update_statement ::= update_clause [where_clause] update_clause ::= UPDATE entity_name [[AS] identification_variable] SET update_item {, update_item}* update_item ::= [identification_variable.]{state_field | single_valued_object_field} = new_value new_value ::= scalar_expression | simple_entity_expression | NULL e.g. update Customer c set c.name = &quot;sunyiwei&quot;, c.age = 27 where c.id = 27 update versioned Customer c set c.name = &quot;patrick&quot; where c.id = 27 //version ###delete delete_statement ::= delete_clause [where_clause]delete_clause ::= DELETE FROM entity_name [[AS] identification_variable]e.g. delete from Custom c where c.id = 27 ###insert(HQL only) insert_statement ::= insert_clause select_statementinsert_clause ::= INSERT INTO entity_name (attribute_list)attribute_list ::= state_field[, state_field ]* e.g.insert into Custom c (name, age) select name, age from Custom where id=27 ###from ####1. identification variables(alias) ####2. root entity reference ####3. explicit join: [left join, inner join] fetch sth with someCondition ####4. implicit join e.g.select cfrom Customer cwhere c.chiefExecutive.age &lt; 25 // same asselect cfrom Customer c inner join c.chiefExecutive ceowhere ceo.age &lt; 25 ===========&gt; 13.4 ##类型映射 ###基本类型 @Basic: 基本上可以不用 @Column: 当默认的列名不符合需要时，可以通过这个注解来进行修改 ###枚举类型 @Enumerated ORDINAL: 整型数据，按enum中的ordinal来映射 NAME: 字符串类型，按enum中的name来映射 AttributeConverter + @Converter ###复合类型 @Embeddable @Embedded 多个复合类型时，会遇到类型匹配的问题，此时需要引入@AttributeOverride来解决，具体可以查看AttributeOverride的注解 ###容器类型文档中没有做详细的描述，这块还需要进一步阅读其它文档来补充 ###标识符 简单类型 According to JPA only the following types should be used as identifier attribute types: any Java primitive type any primitive wrapper type java.lang.String java.util.Date (TemporalType#DATE) java.sql.Date java.math.BigDecimal java.math.BigInteger 复杂类型: 说明 @EmbeddedId @IdClass 自动产生ID的策略: GenerationType AUTO (顺序为: SequenctGenerator –&gt; TableGenerator –&gt; GenericGenerator) IDENTITY SEQUENCE TABLE","categories":[],"tags":[]},{"title":"memo","slug":"doc/memo","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/memo/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/memo/","excerpt":"","text":"#Memo 按天查询收入（开始时间-结束时间) 通过手机号查询用户信息 流量充值 创建APP接口 JIRA上的问题 白条","categories":[],"tags":[]},{"title":"id_auto_increment_accross_tables","slug":"doc/id_auto_increment_accross_tables","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/id_auto_increment_accross_tables/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/id_auto_increment_accross_tables/","excerpt":"","text":"#分表情况下的用户ID自增策略 总得来讲，在数据库中记录当前已经生成的用户ID数，缓存启动时，读取这个值并将它增加一定的数量（100，1000),然后在缓存中预先生成相应数量的ID值，当应用层请求生成用户ID时，直接从缓存中取出预先生成的值，若缓存里的值被取完，继续更新数据库，生成新的ID值 ##几点考虑 缓存系统崩溃：此时只需要重新启动即可，缓存会根据数据库中记录的值生成新一批ID，不会出现重复的情况，不过这种情况下，整个系统会丢失缓存崩溃时遗留在缓存系统中的那批ID 效率考虑：由于缓存系统每次总是从数据库里更新并生成一定数量的ID，当应用层请求生成ID时，是从缓存里直接读取预先生成好的ID，比起每次都读取再更新数据库，效率要高出很多 每次生成ID的数量：如果每次生成的数量很多，那么后续取ID时效率会很高，但相应地，如果缓存系统崩溃，丢失大量未使用ID的概率也更大，因此更适合于短时间内生成大量ID的场景;相反，如果每次生成的数量很少，会导致请求数据库的次数增加（极端情况，将每次生成的ID数量设成1，那么就和直接操作数据库没有区别），影响效率，但可以有效地避免丢失ID的情况。 注意： 更新数据库的时候，可以考虑采用乐观锁，防止多线程情况下更新数据库导致相同的ID值出现 Jedis jedis = newJedis(); String value = jedis.spop(KEY); while (StringUtils.isBlank(value)) { updateCacheAndDB(jedis); value = jedis.spop(KEY); } try { return NumberUtils.toLong(value); } finally { if (jedis != null) { jedis.close(); } }","categories":[],"tags":[]},{"title":"css","slug":"doc/css","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/css/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/css/","excerpt":"","text":"#Selector ###简单选择器 元素选择器 h1 类选择器 .className h1.className ID选择器 #idName h1#idName 属性选择器 [propName]: 拥有某个属性的对象 h1[propName][propName]: 同时拥有两个属性 简单选择器分组 h1, p h2, li ###复合选择器 兄弟选择器 p + p li + li 后代选择器(包括多代子元素） p em h1 em 子元素（直接子元素） p &gt; h1 p &gt; em","categories":[],"tags":[]},{"title":"SQL","slug":"doc/SQL","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/SQL/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/SQL/","excerpt":"","text":"#SQL 字符类型的长度的意义 浮点数的精度问题 计算机中浮点数的实现大都遵从 IEEE754 标准，IEEE754 规定了单精度浮点数和双精度 浮点数两种规格，单精度浮点数用4字节（32bit）表示浮点数，格式是： 1位符号位，8位表示指数，23位表示尾数 双精度浮点数8字节（64bit）表示实数，格式是： 1位符号位 11位表示指数 52位表示尾数 同时，IEEE754标准还对尾数的格式做了规范：d.dddddd...，小数点左面只有1位且不能为零，计算机内部是二进制，因此，尾数小数点左面部分总是1。显然，这个1可以省去，以提高尾数的精度。由上可知，单精度浮点数的尾数是用24bit表示的，双精度浮点数的尾数是用53bit表示的，转换成十进制： 2^24 - 1 = 16777215； 2^53 - 1 = 9007199254740991 由上可见，IEEE754单精度浮点数的有效数字二进制是24位，按十进制来说，是8位；双精度浮点数的有效数字二进制是53位，按十进制来说，是16 位。 日期类型: date, time, datetime, timestamp(自动更新时间) 数据库表设计的三范式： 1st NF(原子性) Columns with similar content must be eliminated A table must be created for a group of associated data Each data record must be identifiable by means of a primary key 2nd NF(非主属性非部分依赖于主属性） Whenever the contents of columns repeat themselves, this means that the table must be divided into subtables. These tables must be linked by foreign keys 3rd NF(属性不依赖于其它非主属性） Columns that are not directly related to primary key must be eliminated(that is, must be translated into a table of their own)","categories":[],"tags":[]},{"title":"RESTful Spring","slug":"doc/RESTful Spring","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/doc/RESTful Spring/","link":"","permalink":"http://yoursite.com/2016/01/25/doc/RESTful Spring/","excerpt":"","text":"#Spring中的REST视图 在spring中实现RESTful风格的视图有两种方法： ContentNegotiatingViewResolver: 可以同时支持RESTful风格和视图风格 RequestBody/ResponseBody+HttpMessageConverter： 只能支持RESTful格式 ##ContentNegotiatingViewResolverViewResolver接口的作用就是将返回的视图名称转化成某一个特定的View类(ViewResolver List)，而ContentNegotiatingViewResolver就是其中一种 ContentNegotiatingViewResolver首先通过ContentNegotiationManager来确定请求的mediaType(后者其实也是通过一系列的ContentNegotiationStrategy来确定的), 然后请求每个代理ViewResolver获取View对象，在这个过程中，viewResolver必须支持请求中的mediaType,如果所有viewResolver都没有返回view，可以通过defaultViews来替代代理VR返回的View The ContentNegotiatingViewResolver does not resolve views itself, but delegates to other ViewResolvers. By default, these other view resolvers are picked up automatically from the application context, though they can also be set explicitly by using the viewResolvers property. Note that in order for this view resolver to work properly, the order property needs to be set to a higher precedence than the others (the default is Ordered.HIGHEST_PRECEDENCE). ContentNegotiatingViewResolver -(1)-&gt; ContentNegotiationManager -(2)-&gt; ContentNegotiationStrategy -(3)-&gt; MediaType -(4)-&gt; ViewResolvers -(5)-&gt; View -(6)-&gt; defaultViews &lt;!-- contentNegotiatingViewResolver --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.ContentNegotiatingViewResolver&quot;&gt; &lt;property name=&quot;order&quot; value=&quot;1&quot;/&gt; &lt;!-- default views --&gt; &lt;property name=&quot;defaultViews&quot;&gt; &lt;list&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.xml.MappingJackson2XmlView&quot;/&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.json.MappingJackson2JsonView&quot;/&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- contentNegotiationManager --&gt; &lt;property name=&quot;contentNegotiationManager&quot;&gt; &lt;bean class=&quot;org.springframework.web.accept.ContentNegotiationManagerFactoryBean&quot;&gt; &lt;property name=&quot;mediaTypes&quot;&gt; &lt;map&gt; &lt;entry key=&quot;xml&quot; value=&quot;application/xml&quot;/&gt; &lt;entry key=&quot;json&quot; value=&quot;application/json&quot;/&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- velocity view resolver --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.velocity.VelocityConfigurer&quot;&gt; &lt;property name=&quot;resourceLoaderPath&quot; value=&quot;/WEB-INF/views&quot;/&gt; &lt;property name=&quot;velocityProperties&quot;&gt; &lt;props&gt; &lt;prop key=&quot;input.encoding&quot;&gt;UTF-8&lt;/prop&gt; &lt;prop key=&quot;output.encoding&quot;&gt;UTF-8&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;velocityLayoutVR&quot; class=&quot;org.springframework.web.servlet.view.velocity.VelocityViewResolver&quot;&gt; &lt;property name=&quot;order&quot; value=&quot;2&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;.vm&quot;/&gt; &lt;property name=&quot;cache&quot; value=&quot;false&quot;/&gt; &lt;property name=&quot;contentType&quot; value=&quot;text/html;charset=UTF-8&quot;/&gt; &lt;property name=&quot;requestContextAttribute&quot; value=&quot;rc&quot;/&gt; &lt;property name=&quot;exposeRequestAttributes&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt; (1)CNVR将解析请求的MediaType的操作委托给CNM (2)CNM又将解析请求的MediaType的操作委托给CNS (3)CNS解析MediaType (4)(5)CNVR委托ViewResolver利用方法返回的ViewName和解析得来的MediaType获取View (6)如果所有的ViewResovler都没有解析到view，则使用CNVR中的defaultViews设置（前提是这些views能够支持相应的mediaTypes) ##RequestBody/ResponseBody + HttpMessageConverterRequestBody注解用于说明方法的参数来自请求的信息体，类似地，ResponseBody注解用于说明返回的对象被存放于回复的消息体中，HttpMessageConverter接口是专门设计来将请求信息和回复信息转化成对象的接口 HttpMessageConverter is responsible for converting from the HTTP request message to an object and converting from an object to the HTTP response body The @RequestBody method parameter annotation indicates that a method parameter should be bound to the value of the HTTP request body. The @ResponseBody annotation is similar to @RequestBody. This annotation can be put on a method and indicates that the return type should be written straight to the HTTP response body (and not placed in a Model, or interpreted as a view name). 具体的实现逻辑可以查看RequestResponseBodyMethodProcessor的源码，大体思路如下： request --&gt; requestMediaTypes --&gt; httpConverter supported mediaTypes --&gt; compatible mediaTypes --&gt; selectedMediaTypes --&gt; (第一个支持这种返回类型的)httpMessageConverter.write &lt;!-- marshaller --&gt; &lt;bean id=&quot;marshaller&quot; class=&quot;org.springframework.oxm.jaxb.Jaxb2Marshaller&quot;&gt; &lt;property name=&quot;packagesToScan&quot; value=&quot;com.cmcc.zypt.model&quot;/&gt; &lt;/bean&gt; &lt;!-- httpMessageConverter --&gt; &lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class=&quot;org.springframework.http.converter.json.GsonHttpMessageConverter&quot;/&gt; &lt;bean class=&quot;org.springframework.http.converter.xml.MarshallingHttpMessageConverter&quot;&gt; &lt;property name=&quot;marshaller&quot; ref=&quot;marshaller&quot;/&gt; &lt;property name=&quot;unmarshaller&quot; ref=&quot;marshaller&quot;/&gt; &lt;/bean&gt; &lt;bean class=&quot;org.springframework.http.converter.StringHttpMessageConverter&quot;/&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt; ##说明 使用时，默认支持XML和JSON，前提是必须提供相应的JSON包(jackson)和XML包(jaxb)","categories":[],"tags":[]},{"title":"junit","slug":"测试/junit","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/测试/junit/","link":"","permalink":"http://yoursite.com/2016/01/25/测试/junit/","excerpt":"","text":"JUnit Test(timeout, expected)： 表示该方法为单元测试方法，timeout表示执行的最长时间，expected表示预期方法会抛出的异常 Before: 每个测试方法执行前被执行一次 After: 每个测试方法执行后被执行一次 BeforeClass: 方法必须为static，在类初始化时被执行一次 AfterClass： 方法必须为static, 在所有测试方法执行完后被执行一次 Ignore： 表示忽略该测试方法 parameters: 用于参数化测试， 方法必须返回collection，作为构造函数的参数feeder，每套参数都会被所有的测试方法执行一次 参考资料 http://www.ibm.com/developerworks/cn/java/j-lo-junit4/","categories":[],"tags":[]},{"title":"CXF","slug":"SOA/CXF","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/SOA/CXF/","link":"","permalink":"http://yoursite.com/2016/01/25/SOA/CXF/","excerpt":"","text":"CXF根据WSDL生成客户端的方式有以下几种： wsdl2java自动生成代码 jax-ws代理： 通过service.create来创建相应的客户端代码. CXF与spring的集成 在beans中定义server和client，如下, 其中id为spring中标识，implementor为服务的实现类， address为定义的服务地址 123&lt;jaxws:endpoint id=\"helloWorld\" implementor=\"com.cmcc.syw.cxf.HelloWorldImpl\" address=\"/helloWorld\"/&gt;&lt;jaxws:client id=\"helloWorldClient\" serviceClass=\"com.cmcc.syw.cxf.HelloWorld\" address=\"http://localhost:8080/spring/ws/helloWorld\"/&gt; 在web.xml中定义cxf-servlet，如下： 123456789&lt;servlet&gt; &lt;servlet-name&gt;cxf&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.cxf.transport.servlet.CXFServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;cxf&lt;/servlet-name&gt; &lt;url-pattern&gt;/ws/*&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; HelloWorld服务的类定义为： 12345678910111213@WebService@Features(features = \"org.apache.cxf.feature.LoggingFeature\")public interface HelloWorld &#123; String sayHi(@WebParam(name = \"name\") String name);&#125;@WebService(endpointInterface = \"com.cmcc.syw.cxf.HelloWorld\")public class HelloWorldImpl implements HelloWorld &#123; @Override public String sayHi(String name) &#123; return \"Hi, \" + name; &#125;&#125; ​ 对于只有wsdl文档，或者得不到服务源码的场景，可以通过工具自动生成客户端代码，然后再和spring进行集成. 注解 @Features: 提供了类似于过滤器的功能, CXF框架提供的feature列表参见http://cxf.apache.org/docs/featureslist.html, 包括故障转移、日志等等 @InInterceptors, @OutInterceptors, @InFaultInterceptors, @OutFaultInterceptors: 拦截器功能在进行消息处理时，CXF会自动创建相应的拦截器链，对于从客户端发往服务端的请求，CXF会自动在客户端创建一个输出的拦截器链，同时在服务端创建一个输入的拦截器链. 每个拦截器链又可以进一步分为多个phase(相位）, 每个拦截器属于哪个phase由程序在构造它的时候指定. 输入输出拦截器链的具体phase可以参阅http://cxf.apache.org/docs/interceptors.html.在cxf, 拦截器功能主要是由InterceptorProvider接口提供的. 实现这个接口的组件包括Client, Service, EndPoint, Bus以及Binding. @DataBinding: 指定数据绑定的方法，默认情况下是jaxb @Logging: 打开端点的日志开关，可以设置上限值和输出日志的位置. @GZip: 指定将输入输出的信息进去压缩，可以指定超过一定大小的流进行压缩或者强制压缩. 参考文档 中文文档 官方文档","categories":[],"tags":[]},{"title":"easyMock","slug":"测试/easyMock","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/测试/easyMock/","link":"","permalink":"http://yoursite.com/2016/01/25/测试/easyMock/","excerpt":"","text":"EasyMock参考文献 EasyMock测试入门文章 EasyMock讲解文章 http://www.ibm.com/developerworks/java/library/j-easymock/index.html https://effectivejavatesting.wordpress.com/2008/11/25/beware-easymock/ 官方的user-guide partial class mock EasyMock测试大体分为: record, replay, verify三个步骤","categories":[],"tags":[]},{"title":"mybatis migration","slug":"工具/mybatis migration","date":"2016-01-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2016/01/25/工具/mybatis migration/","link":"","permalink":"http://yoursite.com/2016/01/25/工具/mybatis migration/","excerpt":"","text":"mybatis migrationmybatis migration(MM)的目的也是对数据库升级进行管理， 它的命令主要包括： init: 初始化项目目录，运行完这条命令后，MM会在指定的目录下生成项目所需要的目录结构，包括 drivers: 用于存放数据库驱动 environments: 环境变量参数，默认有development.properties，代表开发环境，可以通过这里设置多个环境 scripts: 这里就是存储sql脚本的地方， 通过new命令会自动在这里生成以时间戳为前缀的脚本文件，每个文件分为两个区域，一个是升级脚本，一个是回退脚本. bootstrap: 初始化脚本，当需要对一个已经存在数据和结构的DB引入MM时，这里就存放着初始化的数据 new: 创建一个新的sql升级脚本. 它会自动在scripts目录下生成一个以时间戳为前缀的sql文件 status: 查看当前scripts目录下所有脚本的情况， 当脚本没有被执行时，状态栏会显示pending， 否则会显示执行的时间 up/down/version: 这三个命令分别代表升级、降级以及恢复到指定版本 up默认升级到最新的版本，但可以通过参数指定升级的版本个数 down默认只回退一个版本，但可以通过参数指定回退的版本个数 version后面跟具体的版本号, 表示需要回退到这个版本 pending: 在多人合作的场景中，可能会出现这样一个情况： A生成了sqlA脚本，B生成了sqlB脚本，sqlA的时间早于sqlB, 但提交时间晚于sqlB, 于是sqlB已经被执行了，但sqlA还处于pending状态，如下所示： 这时候有两种方案可以解决这个问题： 先降级，再升级： 这也是推荐的方式 直接使用pending： 这个命令是强制执行某个脚本，适合于这个升级脚本相对独立的情况 script: 这个命令有两个参数，一个是起始版本，一个是终止版本，输出一个delta脚本，这个脚本的作用是将数据库从起始版本变更到终止版本 如果起始版本低于终止版本，那么生成的delta脚本就是个升级脚本 如果起始版本高于终止版本，那么生成的delta脚本就是个降级脚本.","categories":[],"tags":[]},{"title":"SOAP","slug":"SOA/SOAP","date":"2015-11-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2015/11/25/SOA/SOAP/","link":"","permalink":"http://yoursite.com/2015/11/25/SOA/SOAP/","excerpt":"","text":"SOAPSOAP消息包括以下几个部分： Envelope元素： 标识此XML文档为SOAP消息， 必需 Heaher元素： 头部信息，可选 Body元素： 包含所有的请求和响应信息， 必需 Fault元素： 包含针对此消息出错时的错误信息，可选 例如： 12345678910111213&lt;?xml version=&quot;1.0&quot; ?&gt;&lt;soap:Envelope&gt; &lt;soap: Header /&gt; &lt;soap: Body&gt; &lt;soap:Fault&gt;&lt;/soap:Fault&gt; &lt;/soap:Body&gt;&lt;/soap:Envelope&gt; HTTP+XML=SOAP","categories":[],"tags":[]},{"title":"data_access","slug":"doc/data_access","date":"2015-10-25T02:20:54.000Z","updated":"2017-03-08T08:38:11.000Z","comments":true,"path":"2015/10/25/doc/data_access/","link":"","permalink":"http://yoursite.com/2015/10/25/doc/data_access/","excerpt":"","text":"#Data Access ##Transaction Management ###Concept diagram ###Propagation参考1 参考2 ###Isolation参考1 Read Uncommitted —&gt; Dirty Read —&gt; Read Committed —&gt; Unrepeatable Read —&gt; Repeatable Read —&gt; Phatom Read —&gt; Serialization Dirty Read: a transaction is allowed to read data from a row that has been modified by another running transaction and not yet committed. Unrepeatable Read: during the course of a transaction, a row is retrieved twice and the values within the row differ between reads. During the course of transaction 1, transaction 2 commits successfully, which means that its changes to the row with id 1 should become visible. However, Transaction 1 has already seen a different value for age in that row. Phatom Read: in the course of a transaction, two identical queries are executed, and the collection of rows returned by the second query is different from the first. The phantom reads anomaly is a special case of Non-repeatable reads when Transaction 1 repeats a ranged SELECT … WHERE query and, between both operations, Transaction 2 creates (i.e. INSERT) new rows (in the target table) which fulfill that WHERE clause. ###Transaction abstraction参考1 ###Core interfacePlatformTransactionManager, TransactionException, TransactionStatus, TransactionDefinition, TransactionTemplate ###Declarative transaction management ####XML-Based &lt;!-- other methods use the default transaction settings (see below) --&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- ensure that the above transactional advice runs for any execution of an operation defined by the FooService interface --&gt; &lt;aop:config&gt; &lt;aop:pointcut id=&quot;fooServiceOperation&quot; expression=&quot;execution(* x.y.service.FooService.*(..))&quot;/&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;fooServiceOperation&quot;/&gt; &lt;/aop:config&gt; ####Annotation-Based@Transactional ####Note In proxy mode (which is the default), only external method calls coming in through the proxy are intercepted. This means that self-invocation, in effect, a method within the target object calling another method of the target object, will not lead to an actual transaction at runtime even if the invoked method is marked with @Transactional. Also, the proxy must be fully initialized to provide the expected behaviour so you should not rely on this feature in your initialization code, i.e. @PostConstruct. The @Transactional annotation is simply metadata that can be consumed by some runtime infrastructure that is @Transactional-aware and that can use the metadata to configure the appropriate beans with transactional behavior. In the preceding example, the element switches on the transactional behavior. When using proxies, you should apply the @Transactional annotation only to methods with public visibility. If you do annotate protected, private or package-visible methods with the @Transactional annotation, no error is raised, but the annotated method does not exhibit the configured transactional settings. @EnableTransactionManagement and only looks for @Transactional on beans in the same application context they are defined in. This means that, if you put annotation driven configuration in a WebApplicationContext for a DispatcherServlet, it only checks for @Transactional beans in your controllers, and not your services ##DAO SupportDaoImpl —&gt; JdbcTemplate —&gt; dataSource —&gt; execute SQLNamedParameterJdbcTemplate, MapSqlParameterSource","categories":[],"tags":[]}]}